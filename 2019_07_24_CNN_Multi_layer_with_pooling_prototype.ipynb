{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019-07-24-CNN_Multi_layer_with_pooling-prototype.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sv650s/sb-capstone/blob/master/2019_07_24_CNN_Multi_layer_with_pooling_prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Tb1UaIMch6lf",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sv650s/sb-capstone/blob/master/2019_07_24_CNN_Multi_layer_with_pooling_prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_5AsY93eNFQ",
        "colab_type": "text"
      },
      "source": [
        "# CNN Multi-Layer With Pooling Prototype\n",
        "\n",
        "Based on the [CNN Multi-Layer Prototype](https://github.com/sv650s/sb-capstone/blob/master/2019_07_23_CNN_Multi_layer_prototype.ipynb), we run the following variations so we can compare results\n",
        "\n",
        "Since 3 layer CNN performed slight better in the previous notebook, we will start with that and add:\n",
        "* max pooling in between all CNN layers\n",
        "* instead of using early stop, we will run 15 epochs and compare results\n",
        "\n",
        "We are going to save off the metrics for both models so we can print them out and compare them\n",
        "\n",
        "As before, I am using some utility functions so I don't have copy so much code around. Source code for the modules are here:\n",
        "* [dict_util](https://github.com/sv650s/sb-capstone/blob/master/util/dict_util.py)\n",
        "* [plot_util](https://github.com/sv650s/sb-capstone/blob/master/util/plot_util.py)\n",
        "* [keras_util](https://github.com/sv650s/sb-capstone/blob/master/util/keras_util.py)\n",
        "* [file_util](https://github.com/sv650s/sb-capstone/blob/master/util/file_util.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGy3VGqGdzVA",
        "colab_type": "code",
        "outputId": "9a59e45e-cb63-4a71-ab45-aaf11e8c4c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_DIR = \"drive/My Drive/Springboard/capstone\"\n",
        "\n",
        "# add this to sys patch so we can import utility functions\n",
        "sys.path.append(DRIVE_DIR)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaoGWTxxeosP",
        "colab_type": "code",
        "outputId": "31faeeb2-3ac0-4cdb-d723-e6b9b859c786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "import pandas as pd\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import util.file_util as fu\n",
        "import util.keras_util as ku\n",
        "import util.plot_util as pu\n",
        "import util.dict_util as du\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "DATE_FORMAT = '%Y-%m-%d'\n",
        "TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
        "DATA_FILE = f\"{DRIVE_DIR}/data/amazon_reviews_us_Wireless_v1_00-preprocessed-110k.csv\"\n",
        "LABEL_COLUMN = \"star_rating\"\n",
        "REVIEW_COLUMN = \"review_body\"\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ezZcc-MerzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data file\n",
        "df = pd.read_csv(f\"{DATA_FILE}\")\n",
        "\n",
        "# extract feature and label columns\n",
        "rating = df[LABEL_COLUMN]\n",
        "reviews = df[REVIEW_COLUMN]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCT5uM_Zetox",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Same as previous notebooks but consolidated to one cell to make thing easier to understand\n",
        "\n",
        "Features:\n",
        "* tokenize our review body - this gives us:\n",
        "  * vocab size: 40788 words\n",
        "* then we will pad the sequences to length 186 since this encapsulates 99% of the lenght of our training data\n",
        "\n",
        "Labels:\n",
        "* one hot encode our star rating labels (y)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnM8yh33er5S",
        "colab_type": "code",
        "outputId": "dccecc51-058f-4e90-e608-a84e23c55f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# pre-process our lables\n",
        "# one hot encode our star ratings since Keras/TF requires this for the labels\n",
        "y = OneHotEncoder().fit_transform(rating.values.reshape(len(rating), 1)).toarray()\n",
        "\n",
        "\n",
        "# split our data into train and test sets\n",
        "reviews_train, reviews_test, y_train, y_test = train_test_split(reviews, y, random_state=1)\n",
        "\n",
        "\n",
        "# Pre-process our features (review body)\n",
        "t = Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(reviews_train)\n",
        "# tokenize both our training and test data\n",
        "train_sequences = t.texts_to_sequences(reviews_train)\n",
        "test_sequences = t.texts_to_sequences(reviews_test)\n",
        "\n",
        "print(\"Vocabulary size={}\".format(len(t.word_counts)))\n",
        "print(\"Number of Documents={}\".format(t.document_count))\n",
        "\n",
        "# figure out 99% percentile for our max sequence length\n",
        "df[\"review_length\"] = df.review_body.apply(lambda x: len(x.split()))\n",
        "MAX_SEQUENCE_LENGTH = int(df.review_length.quantile([0.99]).values[0])\n",
        "print(f'Max Sequence Length: {MAX_SEQUENCE_LENGTH}')\n",
        "\n",
        "# pad our reviews to the max sequence length\n",
        "X_train = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_test = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size=40788\n",
            "Number of Documents=84032\n",
            "Max Sequence Length: 186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDWUQkr8e6q0",
        "colab_type": "text"
      },
      "source": [
        "# Build Our 3 Layer Model With Pooling In Between Layers\n",
        "\n",
        "* we will use embedding size of 300 since this gave us slight improvement from previous notebook for class 1 and 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZO-xLrRe146",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME3 = \"CNN_3layer_maxpooling_earlystop\"\n",
        "EMBED_SIZE = 300\n",
        "EPOCHS  = 15\n",
        "BATCH_SIZE = 128\n",
        "VOCAB_SIZE = len(t.word_counts)+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZwoKs5Ke17z",
        "colab_type": "code",
        "outputId": "04cc6e96-6676-422e-d5b9-3cc3231afe17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "model3 = Sequential()\n",
        "model3.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model3.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "model3.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "model3.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(250, activation='relu'))\n",
        "model3.add(Dense(5, activation='softmax'))\n",
        "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 06:32:33.598369 140626585520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0730 06:32:33.621417 140626585520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0730 06:32:33.625489 140626585520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0730 06:32:33.667556 140626585520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0730 06:32:33.759943 140626585520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0730 06:32:33.788854 140626585520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elohie4Je1-9",
        "colab_type": "code",
        "outputId": "fe2e736e-03f2-422f-a436-3615d83a0938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(model3.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 186, 300)          12236700  \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 186, 100)          90100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 93, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 93, 100)           30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 46, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 46, 100)           30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 23, 100)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2300)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               575250    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 12,963,505\n",
            "Trainable params: 12,963,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWc965qVer_G",
        "colab_type": "code",
        "outputId": "f7a8b65b-3606-40a3-da89-9aca16729e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "# this is ame as before\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1, restore_best_weights=True)\n",
        "\n",
        "# use our model wrapper the wrap the model so we can save things for later\n",
        "mw = ku.ModelWrapper(model=model3, \n",
        "                     name=MODEL_NAME3, \n",
        "                     label_name=LABEL_COLUMN, \n",
        "                     data_file=DATA_FILE,\n",
        "                     tokenizer=t,\n",
        "                     embedding=EMBED_SIZE)\n",
        "\n",
        "network_history3 = mw.fit(X_train, y_train,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      epochs=EPOCHS,\n",
        "                      verbose=1,\n",
        "                      validation_split=0.2,\n",
        "                      callbacks=[early_stop])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0730 06:32:33.954223 140626585520000 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0730 06:32:34.113301 140626585520000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 67225 samples, validate on 16807 samples\n",
            "Epoch 1/15\n",
            "39168/67225 [================>.............] - ETA: 2:25 - loss: 1.0022 - acc: 0.6156"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-6f2da46b84e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                       callbacks=[early_stop])\n\u001b[0m",
            "\u001b[0;32m/content/drive/My Drive/Springboard/capstone/util/keras_util.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, batch_size, epochs, validation_split, verbose, callbacks)\u001b[0m\n\u001b[1;32m    173\u001b[0m                                               \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                                               \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                                               verbose=verbose)\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_time_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MoXcC8Vfqav",
        "colab_type": "text"
      },
      "source": [
        "## Get Metrics for our 3 Layer Model with Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haQ-0EA7esCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get scores\n",
        "mw.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (mw.scores3[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ug3hOApfxdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mw.confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFW9FToUgAyc",
        "colab_type": "text"
      },
      "source": [
        "## Save our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcqmos5gfxoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mw.save(DRIVE_DIR, append_report=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBlcP6QBgUfb",
        "colab_type": "text"
      },
      "source": [
        "# Build Our 3 Layer Model With Pooling In Between Layers - Do not use early stop this time\n",
        "\n",
        "* we will use embedding size of 300 since this gave us slight improvement from previous notebook for class 1 and 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20yc6gH0gElW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = \"CNN_3layer_maxpooling_15epoch\"\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# use our model wrapper the wrap the model so we can save things for later\n",
        "mw15 = ku.ModelWrapper(model=model, \n",
        "                     name=MODEL_NAME, \n",
        "                     label_name=LABEL_COLUMN, \n",
        "                     data_file=DATA_FILE, \n",
        "                     tokenizer=t,\n",
        "                     embedding=EMBED_SIZE)\n",
        "\n",
        "\n",
        "network_history = mw15.fit(X_train, y_train,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      epochs=EPOCHS,\n",
        "                      verbose=1,\n",
        "                      validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3qi55Ibg8C4",
        "colab_type": "text"
      },
      "source": [
        "## Get Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf9kelp2gaJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get scores\n",
        "mw15.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfZloqSFh9dX",
        "colab_type": "text"
      },
      "source": [
        "## Save off our model files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WZTS31wgaU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mw15.save(DRIVE_DIR, append_report=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQsXCHbXiI14",
        "colab_type": "text"
      },
      "source": [
        "# Print metrics for the 2 models and compare\n",
        "\n",
        "\n",
        "* look at accuracy scores\n",
        "* epoch vs loss and accuarcy\n",
        "* confusion matrix\n",
        "* ROC/AUC plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qe5NnpQvgabu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Accuracy - {mw.name}: %.2f%%\" % (mw.scores[1]*100))\n",
        "print(f\"Accuracy - {mw15.name}: %.2f%%\" % (mw15.scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9uXbDVkgaTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(mw.name)\n",
        "pu.plot_network_history(mw.network_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx4X0osjgEjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(mw15.name)\n",
        "pu.plot_network_history(mw15.network_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_gdQj11fxqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Confusion matrix - {mw.name}\")\n",
        "print(mw.confusion_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6_ivRA8jGCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Confusion matrix - {mw15.name}\")\n",
        "print(mw15.confusion_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXv8CRJm7ljy",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix Analysis\n",
        "\n",
        "Overall, we identified less correctly in Star rating 1, 3, 4, and 5. However, we were able to correctly identify more samples in Star ratings 2. Number of star ratings 2's that were identified as star rating 1 or 3 decrease where was Star rating 2's that were identified as 4 or 5 increased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAtBX62MjGOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Classification Report - {mw.name}\")\n",
        "print(mw.classification_report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v9G20UTjGLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Classification Report - {mw15.name}\")\n",
        "print(mw15.classification_report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__AffT4L8GPb",
        "colab_type": "text"
      },
      "source": [
        "### Classification Report Analysis\n",
        "\n",
        "Precision, Recall, and F1 score for all classes decreased without early stopping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYcWOtLAjGJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "gs = gridspec.GridSpec(1, 2, figure=fig)\n",
        "fig.add_subplot(gs[0, 0])\n",
        "pu.plot_roc_auc(mw.name, mw.roc_auc, mw.fpr, mw.tpr)\n",
        "\n",
        "fig.add_subplot(gs[0, 1])\n",
        "pu.plot_roc_auc(mw15.name, mw15.roc_auc, mw15.fpr, mw15.tpr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exvlgkP38O_K",
        "colab_type": "text"
      },
      "source": [
        "### AUC analysis\n",
        "\n",
        "AUC for all classes decreased without early stopping. Both Micro and Macro average AUC decreased as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bklrae0S8dRg",
        "colab_type": "text"
      },
      "source": [
        "# Summary\n",
        "\n",
        "Overall, early stopping performed better than the model without early stopping\n",
        "\n",
        "Model without early stopping was more likely to identify something as Star Rating 2 vs non-early stopping model. Based on sheer volume of prediected Star Rating 2, it was able to identify more Star Rating 2's correctly. However, because the majority of predict Star Rating 2's were mid-classified the precision of this prediction is lower."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugKkNdBIfxiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi5ZAzVWesE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}