{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook outlines pre-processing of Amazong Reviews\n",
    "\n",
    "Most of the work is done in clases that I wrote, but I'll outline what I did for pre-processing in this notebook. Running pre-processing in the notebook took a lot longer so running it via command line seems to be quicker so I can iterate\n",
    "\n",
    "Code is located in util folder:\n",
    "* preprocess_amazon.py - python program that calls TextProcessor with parameters set to handle the amazon review file\n",
    "* TextProcessor.py - processor class that uses various utilities to pre-process the file\n",
    "* text_util.py - has functions to do text processing\n",
    "* file_util.py - functiont to handle files (ie, covert tsv to csv)\n",
    "* df_util.py - utility to handle pandas DataFrames\n",
    "\n",
    "\n",
    "Unit Tests:\n",
    "* TestTextUtil.py - tests text_util.py\n",
    "\n",
    "To Be Implemented:\n",
    "* unit tests for file_util.py\n",
    "* unit tests for pd_util.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we pre-process, I had to convert tsv to CSV because Pandas was not reading the columns correctly and was putting multiple rows into a column resulting in headline columns that had over 30k words\n",
    "\n",
    "Original Amazon file had 9mil reviews. I added sampling parameter to reduce the size of the file. Currently, the sampling is pretty dumb. It just grabs every nth line in the file and put it in the final csv file. Will probably rewrite this so it's based on random.rand later\n",
    "\n",
    "I already ran this via command line because it was faster. So the commented out lines are how we would generate the other sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sibling utilities\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from util.file_util import convert_tsv_to_csv\n",
    "import pandas as pd\n",
    "\n",
    "# only need to run this one time\n",
    "CONVERT_FILE=False\n",
    "\n",
    "# full 9mil Wireless reviews - not enough memory locally to do this\n",
    "ORIG_FILE_WIRELESS=\"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00.tsv\"\n",
    "\n",
    "# about 22k reviews\n",
    "DATA_FILE_TEST = \"dataset/amazon_reviews_us_Wireless_v1_00-50k-preprocessed.csv\"\n",
    "# about 100023 reviews\n",
    "DATA_FILE_50K = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-50k.csv\"\n",
    "# about 300068 reviews\n",
    "DATA_FILE_100K = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-100k.csv\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we have to convert Amazon files to csv format\n",
    "\n",
    "Pandas had issues with original tsv format and would merge multiple lines together. Had to convert the file to csv format\n",
    "\n",
    "I wrote the following function to fix this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONVERT_FILE:\n",
    "    convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_100K, SimpleSampler(90))\n",
    "    convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_50K, SimpleSampler(180))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocssing Amazon Review File\n",
    "\n",
    "To do pre-processing. Run the following:\n",
    "```\n",
    "cd ../tools\n",
    "python amazon_review_preprocessor.py -l INFO -o ../dataset/amazon_reviews ../dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-100k.csv\n",
    "```\n",
    "\n",
    "I'm using a file that has only 25k entires so I can run it in the notebook quickly\n",
    "\n",
    "Notice final output is 19889 because after steming and removing stop words some of the review headlines are now blank\n",
    "\n",
    "Pre-processing entails the following (in order):\n",
    "* make everything lowercase\n",
    "* remove newlines\n",
    "* remove amazon tags - amazon embeds these [[VIDDEO:dsfljlsjf]] and [[ASIN:sdfjlsjdfl]] tags that need to be removed\n",
    "* remove html tags - line breaks, etc are represented in reviews as HTML tags\n",
    "* remove accent characters\n",
    "* expand contractions - expands contractions like he's but needs to be done before special charaters because we want to expand don't into do not for our text processing\n",
    "* remove special characters - anything that is not alphanumeric or spaces\n",
    "* remove stop words - see text_util.py for stop words that I removed from nltk stop words because I think they will be important for sentiment analysis\n",
    "* lemmatize words - stem using wordnet\n",
    "\n",
    "Columns that it drops right off the bat: marketplace, vine, verified_purchase\n",
    "Columns that it is pre-processing: product_title, review_headline, review_body\n",
    "\n",
    "Also, for convenience, there is a flag to retain the original column so we can see the orignal text next to the pre-processed text so we can look for errors. Will not be using this flag for final data files\n",
    "\n",
    "\n",
    "Here is the list of default stop words from nltk:\n",
    "\n",
    "\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at our Pre-processed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PREPROCESSED_CSV = \"../dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-100k-preprocessed.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the output file back in to look at some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99567 entries, 0 to 99566\n",
      "Data columns (total 6 columns):\n",
      "star_rating        99567 non-null int64\n",
      "helpful_votes      99567 non-null int64\n",
      "total_votes        99567 non-null int64\n",
      "review_headline    99567 non-null object\n",
      "review_body        99567 non-null object\n",
      "review_date        99567 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(3), object(2)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "review_df = pd.read_csv(PREPROCESSED_CSV, parse_dates=[\"review_date\"])\n",
    "review_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9018</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>five star</td>\n",
       "      <td>essential equipment ditch bag</td>\n",
       "      <td>2015-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67099</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>illegal artwork stolen</td>\n",
       "      <td>please remove item others artwork stole sellin...</td>\n",
       "      <td>2013-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79379</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>screen blue hue not sharp</td>\n",
       "      <td>replaced quite screen small electronics shop f...</td>\n",
       "      <td>2013-03-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98600</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>far good</td>\n",
       "      <td>purchased product day ago very ampressed great...</td>\n",
       "      <td>2007-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95730</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nice little case</td>\n",
       "      <td>quality case top notch zen fit perfectly leath...</td>\n",
       "      <td>2010-09-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>useful case</td>\n",
       "      <td>person like go swi amming everything wet want ...</td>\n",
       "      <td>2015-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86589</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>very nice screen portector</td>\n",
       "      <td>ordered screen protector wife iphone got first...</td>\n",
       "      <td>2012-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6647</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>five star</td>\n",
       "      <td>fit perfect love</td>\n",
       "      <td>2015-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83575</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tinny sound</td>\n",
       "      <td>read review product decided try price not bad ...</td>\n",
       "      <td>2013-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34398</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>five star</td>\n",
       "      <td>great product</td>\n",
       "      <td>2014-12-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       star_rating  helpful_votes  total_votes             review_headline  \\\n",
       "9018             5              0            0                   five star   \n",
       "67099            1              0            0      illegal artwork stolen   \n",
       "79379            2              0            0   screen blue hue not sharp   \n",
       "98600            5              0            0                    far good   \n",
       "95730            5              0            0            nice little case   \n",
       "4348             5              0            0                 useful case   \n",
       "86589            5              0            0  very nice screen portector   \n",
       "6647             5              0            0                   five star   \n",
       "83575            3              0            0                 tinny sound   \n",
       "34398            5              0            1                   five star   \n",
       "\n",
       "                                             review_body review_date  \n",
       "9018                       essential equipment ditch bag  2015-06-26  \n",
       "67099  please remove item others artwork stole sellin...  2013-11-14  \n",
       "79379  replaced quite screen small electronics shop f...  2013-03-21  \n",
       "98600  purchased product day ago very ampressed great...  2007-12-14  \n",
       "95730  quality case top notch zen fit perfectly leath...  2010-09-10  \n",
       "4348   person like go swi amming everything wet want ...  2015-07-31  \n",
       "86589  ordered screen protector wife iphone got first...  2012-10-31  \n",
       "6647                                    fit perfect love  2015-07-14  \n",
       "83575  read review product decided try price not bad ...  2013-01-06  \n",
       "34398                                      great product  2014-12-22  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's sample the dataframe so we can look at some of the data\n",
    "sample_df = review_df.sample(n=10)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
