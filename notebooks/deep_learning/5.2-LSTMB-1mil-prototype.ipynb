{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sv650s/amazon-review-classification/blob/master/notebooks/deep_learning/3.3-LSTMB-1mil-prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W7_sb1roJXhx"
   },
   "source": [
    "# LSTM Prototype (Balanced Weights) - 1 million samples\n",
    "\n",
    "LSTM is generally doing pretty good in our deep learning models. In our last notebook, we ran LSTM network with default weights - ie, penalty for mis-classification is the same across all classes.\n",
    "\n",
    "In this notebook, we will use 'balanced' weights calculated by sklearn's compute_class_weight with 1 million training examples to see how this affects our performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "pF_xRedK9O1Q",
    "outputId": "d6f24109-d289-4471-f25e-73f3480cef14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "TensorFlow 2.x selected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "DRIVE_DIR = \"drive/My Drive/Springboard/capstone\"\n",
    "sys.path.append(DRIVE_DIR)\n",
    "\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "# checl to make sure we are using GPU here\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAHGtniuJXhy"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, \\\n",
    "    SpatialDropout1D, Flatten, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import SVG\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "import util.dict_util as du\n",
    "import util.plot_util as pu\n",
    "import util.file_util as fu\n",
    "import util.keras_util as ku\n",
    "import util.report_util as ru\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "LABEL_COLUMN = \"star_rating\"\n",
    "REVIEW_COLUMN = \"review_body\"\n",
    "\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "MODEL_NAME = \"LSTMB\"\n",
    "LSTM_DIM = 64 # total LSTM units\n",
    "ARCHITECTURE = f\"1x{LSTM_DIM}\"\n",
    "DESCRIPTION = f\"1 Layer {LSTM_DIM} LSTM Units and 20% 1D Spatial Dropout - Balanced Weights\"\n",
    "FEATURE_SET_NAME = \"random_embedding\"\n",
    "PATIENCE = 8\n",
    "\n",
    "if DEBUG:\n",
    "  DATA_FILE = f'{DRIVE_DIR}/data/amazon_reviews_us_Wireless_v1_00-test-preprocessed.csv'\n",
    "  MODEL_NAME = f'test-{MODEL_NAME}'\n",
    "else:\n",
    "  DATA_FILE = f\"{DRIVE_DIR}/data/amazon_reviews_us_Wireless_v1_00-1m-preprocessed.csv\"\n",
    "\n",
    "\n",
    "# first layer filter\n",
    "FILTER1 = 32\n",
    "# Network Settings\n",
    "KERNEL_SIZE=3\n",
    "\n",
    "\n",
    "\n",
    "# length of our embedding - 300 is standard\n",
    "EMBED_SIZE = 300\n",
    "EPOCHS  = 50\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# From EDA, we know that 90% of review bodies have 100 words or less, \n",
    "# we will use this as our sequence length\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hide_input": false,
    "id": "k6fwJp9OJXh5"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "rating = df[LABEL_COLUMN]\n",
    "reviews = df[REVIEW_COLUMN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBQR0ZpoOiQk"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_g2Wm80MCgGZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "lytdvF4neJ4r",
    "outputId": "5af40a24-ea13-4ac4-f4da-5c12c66df812"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=121775\n",
      "Number of Documents=896119\n",
      "Train review vectors shape: (896119, 100)  Test review vectors shape: (99569, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# pre-process our lables\n",
    "# one hot encode our star ratings since Keras/TF requires this for the labels\n",
    "y = OneHotEncoder().fit_transform(rating.values.reshape(len(rating), 1)).toarray()\n",
    "\n",
    "\n",
    "# split our data into train and test sets\n",
    "reviews_train, reviews_test, y_train, y_test = train_test_split(reviews, y, random_state=1, test_size=0.1)\n",
    "\n",
    "\n",
    "# Pre-process our features (review body)\n",
    "t = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(reviews_train)\n",
    "# tokenize both our training and test data\n",
    "train_sequences = t.texts_to_sequences(reviews_train)\n",
    "test_sequences = t.texts_to_sequences(reviews_test)\n",
    "\n",
    "print(\"Vocabulary size={}\".format(len(t.word_counts)))\n",
    "print(\"Number of Documents={}\".format(t.document_count))\n",
    "\n",
    "\n",
    "# pad our reviews to the max sequence length\n",
    "X_train = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print('Train review vectors shape:', X_train.shape, ' Test review vectors shape:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6hWLBCjqucDJ"
   },
   "source": [
    "**Build LSTM Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "653DtCuBJXiF"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_counts)+1\n",
    "\n",
    "# building our network\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(LSTM_DIM, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",\n",
    "              metrics=[\"categorical_accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "iZitdxXPJXiI",
    "outputId": "837e796d-2744-4459-a3f0-a7c7af658472"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          36532800  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 36,626,565\n",
      "Trainable params: 36,626,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "60eC_0fRJXiQ",
    "outputId": "ae64c5bb-ebe1-476a-dda7-d84a0e4a283c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights: [1.42284845 3.02709736 2.2103805  1.20013018 0.37296994]\n",
      "Number of training examples: 896119\n",
      "Train on 716895 samples, validate on 179224 samples\n",
      "Epoch 1/50\n",
      "716895/716895 [==============================] - 3033s 4ms/sample - loss: 0.8156 - categorical_accuracy: 0.6828 - val_loss: 0.7542 - val_categorical_accuracy: 0.7042\n",
      "Epoch 2/50\n",
      "716895/716895 [==============================] - 2964s 4ms/sample - loss: 0.7259 - categorical_accuracy: 0.7152 - val_loss: 0.7396 - val_categorical_accuracy: 0.7111\n",
      "Epoch 3/50\n",
      "716895/716895 [==============================] - 3017s 4ms/sample - loss: 0.6838 - categorical_accuracy: 0.7330 - val_loss: 0.7434 - val_categorical_accuracy: 0.7098\n",
      "Epoch 4/50\n",
      "716895/716895 [==============================] - 2999s 4ms/sample - loss: 0.6467 - categorical_accuracy: 0.7492 - val_loss: 0.7575 - val_categorical_accuracy: 0.7069\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# reduce learning rate if we sense a plateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.4,\n",
    "                              patience=PATIENCE, \n",
    "                              min_lr=0.00001,\n",
    "                             mode='auto')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "weights = compute_class_weight('balanced', np.arange(1, 6), rating)\n",
    "print(f'class weights: {weights}')\n",
    "\n",
    "\n",
    "mw = ku.ModelWrapper(model, \n",
    "                     MODEL_NAME, \n",
    "                     ARCHITECTURE,\n",
    "                     FEATURE_SET_NAME,\n",
    "                     LABEL_COLUMN, \n",
    "                     DATA_FILE, \n",
    "                     embed_size=EMBED_SIZE,\n",
    "                     tokenizer=t,\n",
    "                     description=DESCRIPTION)\n",
    "\n",
    "network_history = mw.fit(X_train, y_train,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      verbose=1,\n",
    "                      validation_split=0.2,\n",
    "                      class_weight=weights,\n",
    "                      callbacks=[early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VHBrsPjJXiS"
   },
   "outputs": [],
   "source": [
    "\n",
    "scores = mw.evaluate(X_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (mw.scores[1]*100))\n",
    "\n",
    "pu.plot_network_history(mw.network_history, \"categorical_accuracy\", \"val_categorical_accuracy\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(mw.confusion_matrix)\n",
    "\n",
    "print(\"\\nClassification Report\")\n",
    "print(mw.classification_report)\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "pu.plot_roc_auc(mw.model_name, mw.roc_auc, mw.fpr, mw.tpr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YOA18O7wN63j",
    "outputId": "49197dea-898f-4993-f77a-7d1b860acf35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3941243821725579\n"
     ]
    }
   ],
   "source": [
    "print(f'Score: {ru.calculate_metric(mw.crd)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2ot_Nqg1U4w"
   },
   "source": [
    "**Save off various files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "Al3bCFrI1P5m",
    "outputId": "84e00c77-af04-48f9-dfa5-3cb81a34c09b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description: LSTMB-1x64-random_embedding-sampling_none-995688-100-star_rating\n",
      "Saving model file: drive/My Drive/Springboard/capstone/models/LSTMB-1x64-random_embedding-sampling_none-995688-100-star_rating-model.h5\n",
      "Saving json config file: drive/My Drive/Springboard/capstone/models/LSTMB-1x64-random_embedding-sampling_none-995688-100-star_rating-model.json\n",
      "Saving weights file: drive/My Drive/Springboard/capstone/models/LSTMB-1x64-random_embedding-sampling_none-995688-100-star_rating-weights.h5\n",
      "Saving to report file: drive/My Drive/Springboard/capstone/reports/2019-11-dl_prototype-report.csv\n",
      "Loading to append to: drive/My Drive/Springboard/capstone/reports/2019-11-dl_prototype-report.csv\n",
      "{'model_name': 'LSTMB', 'architecture': '1x64', 'description': '1 Layer 64 LSTM Units and 20% 1D Spatial Dropout - Balanced Weights', 'classification_report': '{\"1\": {\"precision\": 0.7047972802820448, \"recall\": 0.7886024232178078, \"f1-score\": 0.7443484042553191, \"support\": 14196}, \"2\": {\"precision\": 0.35711050724637683, \"recall\": 0.23897560236399454, \"f1-score\": 0.2863368134362233, \"support\": 6599}, \"3\": {\"precision\": 0.42007959943510076, \"recall\": 0.36278966626011755, \"f1-score\": 0.38933841028081867, \"support\": 9019}, \"4\": {\"precision\": 0.4985391507596416, \"recall\": 0.3095295682670214, \"f1-score\": 0.3819294187868387, \"support\": 16538}, \"5\": {\"precision\": 0.8021629745801477, \"recall\": 0.92267508502922, \"f1-score\": 0.8582090204406225, \"support\": 53217}, \"accuracy\": 0.7056915304964396, \"macro avg\": {\"precision\": 0.5565379024606624, \"recall\": 0.5245144690276323, \"f1-score\": 0.5320324134399644, \"support\": 99569}, \"weighted avg\": {\"precision\": 0.6737450394098825, \"recall\": 0.7056915304964396, \"f1-score\": 0.6824956348831684, \"support\": 99569}}', 'roc_auc': '{\"auc_1\": 0.9632273632036211, \"auc_2\": 0.8910334115212616, \"auc_3\": 0.8657766936467458, \"auc_4\": 0.7857529397461829, \"auc_5\": 0.9100764975309764, \"auc_micro\": 0.9280009780921855, \"auc_macro\": 0.8831790509741004}', 'loss': 0.7596036878973448, 'accuracy': 0.7056915, 'confusion_matrix': '[[11195, 1402, 803, 192, 604], [2668, 1577, 1440, 370, 544], [1221, 1015, 3272, 1759, 1752], [325, 284, 1600, 5119, 9210], [475, 138, 674, 2828, 49102]]', 'file': 'drive/My Drive/Springboard/capstone/data/amazon_reviews_us_Wireless_v1_00-1m-preprocessed.csv', 'tokenizer_file': 'drive/My Drive/Springboard/capstone/models/dl-tokenizer.pkl', 'max_sequence_length': 100, 'batch_size': 128, 'epochs': 4, 'feature_set_name': 'random_embedding', 'class_weights': '[1.4228484463085092, 3.0270973626206583, 2.2103804999334016, 1.200130175375158, 0.3729699357961058]', 'sampling_type': 'none', 'embedding': 300, 'model_file': 'drive/My Drive/Springboard/capstone/models/LSTMB-1x64-random_embedding-sampling_none-995688-100-star_rating-model.h5', 'model_json_file': 'drive/My Drive/Springboard/capstone/models/LSTMB-1x64-random_embedding-sampling_none-995688-100-star_rating-model.json', 'weights_file': 'drive/My Drive/Springboard/capstone/models/LSTMB-1x64-random_embedding-sampling_none-995688-100-star_rating-weights.h5', 'test_examples': 99569, 'test_features': 100, 'train_examples': 896119, 'train_features': 100, 'train_time_min': 240.28, 'evaluate_time_min': 6.06, 'predict_time_min': 6.14, 'status': 'success', 'status_date': '2019-11-09 03:43:19'}\n",
      "Saving report file...\n"
     ]
    }
   ],
   "source": [
    "mw.save(DRIVE_DIR, append_report=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "96A-A5CBJXiy",
    "outputId": "a0aac572-80cc-46a8-b14e-db8557273d95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-09 03:43:19.743688\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "3.3-LSTMB-1mil-prototype.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
