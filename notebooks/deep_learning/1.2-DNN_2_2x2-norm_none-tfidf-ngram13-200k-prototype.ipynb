{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbCz80nowIiZ"
   },
   "source": [
    "# 2 Layer DNN TFIDF Prototype\n",
    "\n",
    "Trying out a 2 layer network using TFIDF with max features of 4k - each feature will represent either a unigram, bigram, or trigram.\n",
    "\n",
    "Recommendation that I read for NN is the number of neurons should not exceed 2/3 of the number of features which would be around 340 for 512 features\n",
    "\n",
    "\n",
    "\n",
    "Number of hidden layers guidelines:\n",
    "\n",
    "* none - Only capable of representing linear separable functions or decisions.\n",
    "* 1\t- Can approximate any function that contains a continuous mapping from one finite space to another.\n",
    "* 2\t- Can represent an arbitrary decision boundary to arbitrary accuracy with rational activation functions and can approximate any smooth mapping to any accuracy.\n",
    "* 2+ - Additional layers can learn complex representations (sort of automatic feature engineering) for layer layers.\n",
    "\n",
    "\n",
    "Hidden units guidelines:\n",
    "\n",
    "* The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
    "* The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
    "* The number of hidden neurons should be less than twice the size of the input layer.\n",
    "\n",
    "https://www.heatonresearch.com/2017/06/01/hidden-layers.html\n",
    "\n",
    "\n",
    "Since our decision boundaries do not look linear, I have chosen to use 2 hidden layers. For each layer, there is the same number of hiddent units (10k) as input features.\n",
    "\n",
    "Number of samples: 50k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 40190,
     "status": "ok",
     "timestamp": 1572980813068,
     "user": {
      "displayName": "Vince Luk",
      "photoUrl": "",
      "userId": "16057681301960694126"
     },
     "user_tz": 480
    },
    "id": "Dh6ie2wHy64N",
    "outputId": "cfa51cdc-37c4-4dce-a1d5-afc7cd73f55b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "TensorFlow 2.x selected.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "DRIVE_DIR = \"drive/My Drive/Springboard/capstone\"\n",
    "sys.path.append(DRIVE_DIR)\n",
    "\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "# checl to make sure we are using GPU here\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43264,
     "status": "ok",
     "timestamp": 1572980816150,
     "user": {
      "displayName": "Vince Luk",
      "photoUrl": "",
      "userId": "16057681301960694126"
     },
     "user_tz": 480
    },
    "id": "wCgiR6gSwIic",
    "outputId": "4b0c5ada-7eb8-46f0-d106-2301fce5f1bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import tensorflow.keras as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from util import dict_util as du\n",
    "from util import file_util as fu\n",
    "from util import plot_util as pu\n",
    "from util import keras_util as ku\n",
    "import util.report_util as ru\n",
    "\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cu2OWgeVwIig"
   },
   "outputs": [],
   "source": [
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "DATA_DIR = f\"{DRIVE_DIR}/data\"\n",
    "LABEL_COLUMN = \"star_rating\"\n",
    "FEATURE_COLUMN = \"review_body\"\n",
    "RSTATE = 1\n",
    "EPOCH=200\n",
    "BATCH_SIZE = 128\n",
    "EMBED_SIZE = 0\n",
    "PATIENCE=8\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "MODEL_NAME = \"DNN\"\n",
    "ARCHITECTURE = \"2_.5x.5\"\n",
    "if DEBUG:\n",
    "  DATA_FILE = f'{DATA_DIR}/review_body-word2vec-df_none-ngram_none-89-100-nolda.csv'\n",
    "else:\n",
    "  # DATA_FILE = f'{DATA_DIR}/review_body-word2vec-df_none-ngram_none-47523-1000-nolda.csv'\n",
    "  DATA_FILE = f'{DATA_DIR}/review_body-tfidf-df_none-ngram13-199134-4000-nolda.csv'\n",
    "\n",
    "directory, INBASENAME = fu.get_dir_basename(DATA_FILE)\n",
    "DESCRIPTION = f\"{MODEL_NAME}-{ARCHITECTURE}-nobatch-{INBASENAME}-sampling_none-{FEATURE_COLUMN}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hide_input": false,
    "id": "EsSlqc4DwIij"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{DATA_FILE}\")\n",
    "rating = df[LABEL_COLUMN]\n",
    "df = df.drop(columns=[\"helpful_votes\", \"total_votes\", \"helpful_product\", \"star_rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 203990,
     "status": "ok",
     "timestamp": 1572980976896,
     "user": {
      "displayName": "Vince Luk",
      "photoUrl": "",
      "userId": "16057681301960694126"
     },
     "user_tz": 480
    },
    "id": "bLSHSo2mwIil",
    "outputId": "c1369114-1fce-49e5-eb7d-acbea551a516"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able charge</th>\n",
       "      <th>able get</th>\n",
       "      <th>able use</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutely love</th>\n",
       "      <th>absolutely love case</th>\n",
       "      <th>absolutely no</th>\n",
       "      <th>abuse</th>\n",
       "      <th>ac</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>accessible</th>\n",
       "      <th>accessory</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accurate</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activate</th>\n",
       "      <th>activated</th>\n",
       "      <th>active</th>\n",
       "      <th>activity</th>\n",
       "      <th>actual</th>\n",
       "      <th>actually</th>\n",
       "      <th>actually work</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapter</th>\n",
       "      <th>adaptor</th>\n",
       "      <th>add</th>\n",
       "      <th>add bulk</th>\n",
       "      <th>add much</th>\n",
       "      <th>added</th>\n",
       "      <th>...</th>\n",
       "      <th>would probably</th>\n",
       "      <th>would purchase</th>\n",
       "      <th>would rather</th>\n",
       "      <th>would recommend</th>\n",
       "      <th>would recommend anyone</th>\n",
       "      <th>would recommend case</th>\n",
       "      <th>would recommend product</th>\n",
       "      <th>would say</th>\n",
       "      <th>would still</th>\n",
       "      <th>would suggest</th>\n",
       "      <th>would take</th>\n",
       "      <th>would think</th>\n",
       "      <th>would work</th>\n",
       "      <th>wouldnt</th>\n",
       "      <th>wow</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrap around</th>\n",
       "      <th>wrist</th>\n",
       "      <th>write</th>\n",
       "      <th>write review</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>xm</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>year ago</th>\n",
       "      <th>year old</th>\n",
       "      <th>year still</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youtube video</th>\n",
       "      <th>yr</th>\n",
       "      <th>zagg</th>\n",
       "      <th>zero</th>\n",
       "      <th>zune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  able charge  able get  ...   yr  zagg  zero  zune\n",
       "0      0.0  0.00          0.0       0.0  ...  0.0   0.0   0.0   0.0\n",
       "1      0.0  0.00          0.0       0.0  ...  0.0   0.0   0.0   0.0\n",
       "2      0.0  0.00          0.0       0.0  ...  0.0   0.0   0.0   0.0\n",
       "3      0.0  0.22          0.0       0.0  ...  0.0   0.0   0.0   0.0\n",
       "4      0.0  0.00          0.0       0.0  ...  0.0   0.0   0.0   0.0\n",
       "\n",
       "[5 rows x 4000 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 203984,
     "status": "ok",
     "timestamp": 1572980976897,
     "user": {
      "displayName": "Vince Luk",
      "photoUrl": "",
      "userId": "16057681301960694126"
     },
     "user_tz": 480
    },
    "id": "2CKvu2yZwIin",
    "outputId": "6ece6196-ddc9-4824-c364-162958e79a42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    5\n",
       "2    5\n",
       "3    5\n",
       "4    1\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4f4vuyP6wIis"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(0.5 * df.shape[1], input_shape=(df.shape[1],), kernel_initializer='glorot_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(0.5 * df.shape[1], kernel_initializer='glorot_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Activation('softmax'))\n",
    "# model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=[custom_metric])\n",
    "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 207223,
     "status": "ok",
     "timestamp": 1572980980149,
     "user": {
      "displayName": "Vince Luk",
      "photoUrl": "",
      "userId": "16057681301960694126"
     },
     "user_tz": 480
    },
    "id": "n7tm341LwIiu",
    "outputId": "3d337d00-e3f8-4008-f394-62a86027b0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2000)              8002000   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 10005     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 12,014,005\n",
      "Trainable params: 12,014,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 207212,
     "status": "ok",
     "timestamp": 1572980980149,
     "user": {
      "displayName": "Vince Luk",
      "photoUrl": "",
      "userId": "16057681301960694126"
     },
     "user_tz": 480
    },
    "id": "Q5BCqturwIiy",
    "outputId": "7dd06fad-41d8-4755-c24b-b31640e34ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199134,)\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode rating\n",
    "print(rating.shape)\n",
    "print(type(rating))\n",
    "y = OneHotEncoder().fit_transform(rating.values.reshape(len(rating), 1)).toarray()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GrqdTqPzwIi0"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpZQI3H8_PW0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "colab_type": "code",
    "id": "HhPZ42fMwIi2",
    "outputId": "67bbee7d-c69e-4bb7-925b-f73c432bcb23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class weights: [1.43633872 3.07851898 2.18840596 1.19528211 0.3723871 ]\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 119480 samples, validate on 29870 samples\n",
      "Epoch 1/200\n",
      "119480/119480 [==============================] - 28s 234us/sample - loss: 1.3543 - categorical_accuracy: 0.5299 - val_loss: 1.3026 - val_categorical_accuracy: 0.5383\n",
      "Epoch 2/200\n",
      "119480/119480 [==============================] - 27s 223us/sample - loss: 1.2944 - categorical_accuracy: 0.5368 - val_loss: 1.2859 - val_categorical_accuracy: 0.5383\n",
      "Epoch 3/200\n",
      "119480/119480 [==============================] - 27s 224us/sample - loss: 1.2764 - categorical_accuracy: 0.5368 - val_loss: 1.2629 - val_categorical_accuracy: 0.5383\n",
      "Epoch 4/200\n",
      "119480/119480 [==============================] - 27s 223us/sample - loss: 1.2441 - categorical_accuracy: 0.5368 - val_loss: 1.2185 - val_categorical_accuracy: 0.5384\n",
      "Epoch 5/200\n",
      "119480/119480 [==============================] - 26s 221us/sample - loss: 1.1876 - categorical_accuracy: 0.5449 - val_loss: 1.1494 - val_categorical_accuracy: 0.5650\n",
      "Epoch 6/200\n",
      "119480/119480 [==============================] - 27s 223us/sample - loss: 1.1184 - categorical_accuracy: 0.5829 - val_loss: 1.0837 - val_categorical_accuracy: 0.5971\n",
      "Epoch 7/200\n",
      "119480/119480 [==============================] - 26s 221us/sample - loss: 1.0614 - categorical_accuracy: 0.6059 - val_loss: 1.0343 - val_categorical_accuracy: 0.6184\n",
      "Epoch 8/200\n",
      "119480/119480 [==============================] - 26s 221us/sample - loss: 1.0178 - categorical_accuracy: 0.6176 - val_loss: 0.9961 - val_categorical_accuracy: 0.6252\n",
      "Epoch 9/200\n",
      "119480/119480 [==============================] - 27s 222us/sample - loss: 0.9836 - categorical_accuracy: 0.6256 - val_loss: 0.9653 - val_categorical_accuracy: 0.6341\n",
      "Epoch 10/200\n",
      "119480/119480 [==============================] - 26s 221us/sample - loss: 0.9561 - categorical_accuracy: 0.6320 - val_loss: 0.9415 - val_categorical_accuracy: 0.6388\n",
      "Epoch 11/200\n",
      "119480/119480 [==============================] - 27s 224us/sample - loss: 0.9342 - categorical_accuracy: 0.6374 - val_loss: 0.9255 - val_categorical_accuracy: 0.6474\n",
      "Epoch 12/200\n",
      "119480/119480 [==============================] - 27s 224us/sample - loss: 0.9161 - categorical_accuracy: 0.6423 - val_loss: 0.9083 - val_categorical_accuracy: 0.6475\n",
      "Epoch 13/200\n",
      "119480/119480 [==============================] - 27s 224us/sample - loss: 0.9017 - categorical_accuracy: 0.6462 - val_loss: 0.8961 - val_categorical_accuracy: 0.6504\n",
      "Epoch 14/200\n",
      "119480/119480 [==============================] - 27s 225us/sample - loss: 0.8892 - categorical_accuracy: 0.6503 - val_loss: 0.8850 - val_categorical_accuracy: 0.6535\n",
      "Epoch 15/200\n",
      "119480/119480 [==============================] - 27s 225us/sample - loss: 0.8787 - categorical_accuracy: 0.6553 - val_loss: 0.8761 - val_categorical_accuracy: 0.6583\n",
      "Epoch 16/200\n",
      "119480/119480 [==============================] - 27s 223us/sample - loss: 0.8682 - categorical_accuracy: 0.6593 - val_loss: 0.8701 - val_categorical_accuracy: 0.6639\n",
      "Epoch 17/200\n",
      "119480/119480 [==============================] - 27s 223us/sample - loss: 0.8595 - categorical_accuracy: 0.6628 - val_loss: 0.8603 - val_categorical_accuracy: 0.6636\n",
      "Epoch 18/200\n",
      "119480/119480 [==============================] - 27s 223us/sample - loss: 0.8519 - categorical_accuracy: 0.6655 - val_loss: 0.8556 - val_categorical_accuracy: 0.6642\n",
      "Epoch 19/200\n",
      "119480/119480 [==============================] - 27s 224us/sample - loss: 0.8450 - categorical_accuracy: 0.6677 - val_loss: 0.8486 - val_categorical_accuracy: 0.6679\n",
      "Epoch 20/200\n",
      " 51968/119480 [============>.................] - ETA: 12s - loss: 0.8417 - categorical_accuracy: 0.6700"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "\n",
    "\n",
    "# reduce learning rate if we sense a plateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.4,\n",
    "                              patience=PATIENCE, \n",
    "                              min_lr=0.00001,\n",
    "                             mode='auto')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=PATIENCE, verbose=1)\n",
    "\n",
    "# metric = Metrics()\n",
    "\n",
    "mw = ku.ModelWrapper(model, MODEL_NAME, LABEL_COLUMN, DATA_FILE, \n",
    "                     embedding=EMBED_SIZE,\n",
    "                     tokenizer=None,\n",
    "                     description=\"2 Layer NN 5k x 5k\")\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight('balanced', np.arange(1, 6), rating)\n",
    "print(f'class weights: {weights}')\n",
    "\n",
    "network_history = mw.fit(x_train, y_train,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCH,\n",
    "                      verbose=1,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AFkPh27wIi4"
   },
   "outputs": [],
   "source": [
    "scores = mw.evaluate(x_test, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (mw.scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sy0qCyklwIi7"
   },
   "outputs": [],
   "source": [
    "\n",
    "importlib.reload(pu)\n",
    "pu.plot_network_history(mw.network_history, \"categorical_accuracy\", \"val_categorical_accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWzmvCIPwIjB"
   },
   "outputs": [],
   "source": [
    "\n",
    "mw.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3FJ8vqTwIjJ"
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y_test_unencoded, y_predict_unencoded))\n",
    "print(mw.classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdsmH8xEx3Fa"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "pu.plot_roc_auc(mw.name, mw.roc_auc, mw.fpr, mw.tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0ehuHKKwIjL"
   },
   "source": [
    "# Save off various files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2YCQbVn812o"
   },
   "outputs": [],
   "source": [
    "importlib.reload(ku)\n",
    "\n",
    "mw.save(DRIVE_DIR, append_report=True)\n",
    "report = mw.get_report().to_df()\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cNV7AMkwIjY"
   },
   "outputs": [],
   "source": [
    "cr = json.loads(report.classification_report.values[0])\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OhwKwJYvAWOv"
   },
   "outputs": [],
   "source": [
    "importlib.reload(ru)\n",
    "print(f'Overall metric: {ru.calculate_metric(cr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBxher6CKfPN"
   },
   "outputs": [],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbMyu7wDL-7B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "1.1-DNN_2_2k_2k-nobatch-tfidf-ngram13-200k-prototype.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/sv650s/amazon-review-classification/blob/master/notebooks/deep_learning/2019-06-23-DNN_128_128-nobatch-word2vec5-prototype.ipynb",
     "timestamp": 1572911693689
    }
   ]
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
