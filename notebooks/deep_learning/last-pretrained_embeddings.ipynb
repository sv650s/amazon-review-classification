{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"last-pretrained_embeddings.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0LuXEa7txF9u","colab_type":"text"},"source":["# Pre-trained Embeddings notebook\n","\n","\n","In the previous notebook [2019-07-30_deep_learning_summary](https://github.com/sv650s/sb-capstone/blob/master/2019_07_30_deep_learning_summary.ipynb) we looked at the results for various deep learning models. There were 2 models that came back with the best results:\n","\n","* 1 layer bi direcitonal GRU with attention\n","* 3 layer CNN with maxpooling - we train this with 15 epoch without early stopping\n","\n","Overall, GRU model offered better precision however poor recall\n","\n","CNN had a good balance for F1 (precision and recall) scores for class 2, 3, 4 - our problem classes, but did poorly for our class 1 and 5\n","\n","In this notebook, we will use pre-trained word embeddings for both models. Idea is that in our previous notebooks, embeddings were random to start with and as we train the model as well as embeddings.\n","\n","With pre-trained embeddings, we should see improvements in our model in term of training time since the embedding vectors are pre-trained\n","\n","\n","Pre-trained word vectors will come from Google's Word2Vec model pre-trained on Google News: https://github.com/mmihaltz/word2vec-GoogleNews-vectors"]},{"cell_type":"code","metadata":{"id":"JnVhbl5Mw8eB","colab_type":"code","outputId":"cb5216a0-57a1-4cc8-8a9b-27e7491382ca","executionInfo":{"status":"ok","timestamp":1564645361217,"user_tz":420,"elapsed":501,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","import sys\n","drive.mount('/content/drive')\n","DRIVE_DIR = \"drive/My Drive/Springboard/capstone\"\n","\n","# add this to sys patch so we can import utility functions\n","sys.path.append(DRIVE_DIR)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z5ahyjedytpD","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout, GRU, SpatialDropout1D, Bidirectional\n","from keras.layers.normalization import BatchNormalization\n","from keras.callbacks import EarlyStopping\n","from keras.models import load_model\n","from sklearn.model_selection import train_test_split\n","from keras.optimizers import SGD\n","from sklearn.preprocessing import OneHotEncoder\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","from keras.layers.embeddings import Embedding\n","import pandas as pd\n","from IPython.display import SVG\n","from keras.utils.vis_utils import model_to_dot\n","import pickle\n","from datetime import datetime\n","from sklearn.metrics import confusion_matrix, classification_report\n","import os\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","\n","# custom utility functions\n","import util.dict_util as du\n","import util.plot_util as pu\n","import util.file_util as fu\n","import util.keras_util as ku\n","\n","\n","sns.set()\n","\n","import logging\n","logging.basicConfig(level=logging.INFO)\n","\n","DATE_FORMAT = '%Y-%m-%d'\n","TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n","DATA_FILE = f\"{DRIVE_DIR}/data/amazon_reviews_us_Wireless_v1_00-preprocessed-110k.csv\"\n","LABEL_COLUMN = \"star_rating\"\n","REVIEW_COLUMN = \"review_body\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gjGINhPJz73a","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zrDqbbyp0AlH","colab_type":"code","outputId":"e42d21dc-1db0-4687-e187-6a25e9a87dc4","executionInfo":{"status":"ok","timestamp":1564645361221,"user_tz":420,"elapsed":466,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","# checl to make sure we are using GPU here\n","tf.test.gpu_device_name()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["''"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"e7eDc4zE0DAI","colab_type":"code","colab":{}},"source":["df = pd.read_csv(f\"{DATA_FILE}\")\n","ratings = df[LABEL_COLUMN]\n","reviews = df[REVIEW_COLUMN]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vjf2Cy7N0i8W","colab_type":"text"},"source":["## Preprocessing our Data"]},{"cell_type":"code","metadata":{"id":"iaI2Gt8P0kar","colab_type":"code","outputId":"3f9c841d-f5b1-42c0-929c-2f60c178c531","executionInfo":{"status":"ok","timestamp":1564645740263,"user_tz":420,"elapsed":7931,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["from  keras.preprocessing.text import Tokenizer\n","from keras.preprocessing import sequence\n","\n","\n","# one hot encode our lables so we can pass it to our model later\n","print(\"One hot enocde label data...\")\n","y = OneHotEncoder().fit_transform(rating.values.reshape(len(ratings), 1)).toarray()\n","\n","# split our data into train and test sets\n","print(\"Splitting data into training and test sets...\")\n","X_train, X_test, y_train, y_test = train_test_split(reviews, y, random_state=1)\n","\n","# Pre-process our features (review body)\n","t = Tokenizer()\n","# fit the tokenizer on the documents so that we can get word index dict - key = word, value = index of tokenizer\n","t.fit_on_texts(features_train)\n","\n","# tokenize both our training and test data\n","train_sequences = t.texts_to_sequences(features_train)\n","test_sequences = t.texts_to_sequences(features_test)\n","\n","print(\"Vocabulary size={}\".format(len(t.word_counts)))\n","print(\"Number of Documents={}\".format(t.document_count))\n","\n","# figure out 99% percentile for our max sequence length\n","df[\"feature_length\"] = df.review_body.apply(lambda x: len(x.split()))\n","max_sequence_length = int(df.feature_length.quantile([0.99]).values[0])\n","print(f'Max Sequence Length: {max_sequence_length}')\n","\n","# pad our reviews to the max sequence length\n","X_train = sequence.pad_sequences(train_sequences, maxlen=max_sequence_length)\n","X_test = sequence.pad_sequences(test_sequences, maxlen=max_sequence_length)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["One hot enocde label data...\n","Splitting data into training and test sets...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n","If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n","In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n","  warnings.warn(msg, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Vocabulary size=40788\n","Number of Documents=84032\n","Max Sequence Length: 186\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Md9uSVflBDeL","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def load_pretrained_embeddings(word_to_index, max_features, embedding_size, embedding_file_path):    \n","    \n","    def get_coefs(word,*arr): \n","        return word, np.asarray(arr, dtype='float32')\n","\n","    # turns the embedding file into a dictionary key = word, value = word vector\n","    embeddings_index = dict(get_coefs(*row.split(\" \")) \n","                                for row in open(embedding_file_path, encoding=\"utf8\", errors='ignore') \n","                                    if len(row)>100)\n","\n","    # convert the values into a array of word arrays\n","    all_embs = np.stack(embeddings_index.values())\n","    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n","    embed_size = all_embs.shape[1]\n","\n","    nb_words = min(max_features, len(word_to_index))\n","    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embedding_size))\n","    \n","    for word, idx in word_to_index.items():\n","        if idx >= max_features: \n","            continue\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None: \n","            embedding_matrix[idx] = embedding_vector\n","\n","    return embedding_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pPLgA1lwE-sF","colab_type":"code","outputId":"92d33f68-2bbf-45be-ef3c-49847b46441f","executionInfo":{"status":"ok","timestamp":1564646262094,"user_tz":420,"elapsed":184694,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# keep number of \n","MAX_FEATURES = len(t.word_index)\n","EMBED_SIZE = 300\n","pg_embeddings = load_pretrained_embeddings(word_to_index=t.word_index, max_features=MAX_FEATURES, \n","                                            embedding_size=EMBED_SIZE, \n","                                            embedding_file_path=f'{DRIVE_DIR}/data/paragram_300_sl999.txt')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"OEn498IGMgND","colab_type":"code","outputId":"68f4f9f0-b3ef-42c5-9854-5e25d13a927a","executionInfo":{"status":"ok","timestamp":1564646445934,"user_tz":420,"elapsed":337,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["MAX_FEATURES"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40788"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"CJNAX3FoMlgF","colab_type":"code","outputId":"83224110-dc46-48fb-91d3-9bd489f24c79","executionInfo":{"status":"ok","timestamp":1564646467634,"user_tz":420,"elapsed":273,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["max_sequence_length"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["186"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"1tUKqR8y9jb7","colab_type":"code","colab":{}},"source":["from keras.engine.topology import Layer\n","from keras import backend as K\n","import keras\n","\n","\n","class AttentionLayer(Layer):\n","    \n","    def __init__(self, step_dim,\n","                 W_regularizer=None, b_regularizer=None,\n","                 W_constraint=None, b_constraint=None,\n","                 bias=True, **kwargs):\n","        \n","        \"\"\"\n","        Keras Layer that implements an Attention mechanism for temporal data.\n","        Supports Masking.\n","        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n","        # Input shape\n","            3D tensor with shape: `(samples, steps, features)`.\n","        # Output shape\n","            2D tensor with shape: `(samples, features)`.\n","        :param kwargs:\n","        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n","        The dimensions are inferred based on the output shape of the RNN.\n","        \"\"\"\n","        \n","        self.supports_masking = True\n","        self.init = keras.initializers.get('glorot_uniform')\n","\n","        self.W_regularizer = keras.regularizers.get(W_regularizer)\n","        self.b_regularizer = keras.regularizers.get(b_regularizer)\n","\n","        self.W_constraint = keras.constraints.get(W_constraint)\n","        self.b_constraint = keras.constraints.get(b_constraint)\n","\n","        self.bias = bias\n","        self.step_dim = step_dim\n","        self.features_dim = 0\n","        super(AttentionLayer, self).__init__(**kwargs)\n","        \n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 3\n","\n","        self.W = self.add_weight((input_shape[-1],),\n","                                 initializer=self.init,\n","                                 name='{}_W'.format(self.name),\n","                                 regularizer=self.W_regularizer,\n","                                 constraint=self.W_constraint)\n","        self.features_dim = input_shape[-1]\n","\n","        if self.bias:\n","            self.b = self.add_weight((input_shape[1],),\n","                                     initializer='zero',\n","                                     name='{}_b'.format(self.name),\n","                                     regularizer=self.b_regularizer,\n","                                     constraint=self.b_constraint)\n","        else:\n","            self.b = None\n","\n","        self.built = True\n","        \n","\n","    def compute_mask(self, input, input_mask=None):\n","        # do not pass the mask to the next layers\n","        return None\n","\n","    \n","    def call(self, x, mask=None):\n","        # TF backend doesn't support it\n","        # eij = K.dot(x, self.W) \n","        # features_dim = self.W.shape[0]\n","        # step_dim = x._keras_shape[1]\n","\n","        features_dim = self.features_dim\n","        step_dim = self.step_dim\n","\n","        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), \n","                              K.reshape(self.W, (features_dim, 1))),\n","                        (-1, step_dim))\n","\n","        if self.bias:\n","            eij += self.b\n","\n","        eij = K.tanh(eij)\n","\n","        a = K.exp(eij)\n","\n","        # apply mask after the exp. will be re-normalized next\n","        if mask is not None:\n","            # Cast the mask to floatX to avoid float64 upcasting in theano\n","            a *= K.cast(mask, K.floatx())\n","\n","        # in some cases especially in the early stages of training the sum may be almost zero\n","        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","        a = K.expand_dims(a)\n","        weighted_input = x * a\n","        \n","        return K.sum(weighted_input, axis=1)\n","\n","    \n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0],  self.features_dim\n","    \n","    \n","    def get_config(self):\n","        config = {'step_dim': self.step_dim}\n","        base_config = super(AttentionLayer, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xn0PsCM_G_GF","colab_type":"code","colab":{}},"source":["MODEL_NAME = \"biGRU_1layer_attention-paragram\"\n","EPOCHS  = 50\n","BATCH_SIZE = 128\n","VOCAB_SIZE = len(t.word_counts)\n","GRU_DIM = 250 # total GRU units\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EkXJplHZNzRZ","colab_type":"code","outputId":"cf55bd4c-46e0-41b9-b265-ed896128c6f1","executionInfo":{"status":"ok","timestamp":1564646789783,"user_tz":420,"elapsed":447,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["max_sequence_length"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["186"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"DSSULNf_N10f","colab_type":"code","outputId":"11ce20cf-817e-4c46-962e-d050a3479ae3","executionInfo":{"status":"ok","timestamp":1564646797954,"user_tz":420,"elapsed":376,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pg_embeddings.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(40788, 300)"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"0lWSyKHDN5Wb","colab_type":"code","outputId":"975a59c5-50cf-41f1-d895-e5d3d0125b83","executionInfo":{"status":"ok","timestamp":1564646811152,"user_tz":420,"elapsed":305,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["VOCAB_SIZE"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40789"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"XghUdGAPN7kL","colab_type":"code","outputId":"2ea62227-d31b-4277-848b-789fab441367","executionInfo":{"status":"ok","timestamp":1564646822257,"user_tz":420,"elapsed":417,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["EMBED_SIZE"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["300"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"3bFyJk_BHG1Z","colab_type":"code","outputId":"6fbc3320-d84d-4625-a402-027c58b6f319","executionInfo":{"status":"error","timestamp":1564647738689,"user_tz":420,"elapsed":353,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.layers import CuDNNGRU\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n","                              factor=0.4,\n","                              patience=2, \n","                              min_lr=0.00001,\n","                             mode='auto')\n","\n","early_stop = EarlyStopping(monitor='val_loss', \n","                           patience=2, \n","                           mode='auto', \n","                           verbose=1,\n","                          restore_best_weights=True)\n","\n","\n","# model = Sequential()\n","# model.add(Embedding(VOCAB_SIZE, \n","#                     EMBED_SIZE, \n","#                     input_length=max_sequence_length, \n","#                     weights=[pg_embeddings], Trainable=True))\n","# model.add(Bidirectional(CuDNNGRU(GRU_DIM*2, return_sequences=True)))\n","# model.add(AttentionLayer(max_sequence_length))\n","# model.add(Dense(GRU_DIM*2, activation='relu'))\n","# model.add(Dropout(0.2))\n","# model.add(Dense(GRU_DIM, activation='relu'))\n","# model.add(Dense(5, activation='softmax'))\n","# model.compile(loss='categorical_crossentropy', \n","#               optimizer='adam', \n","#               metrics=['accuracy'])\n","\n","inp = keras.layers.Input(shape=(max_sequence_length,))\n","x = keras.layers.Embedding(VOCAB_SIZE, \n","                    EMBED_SIZE, \n","                    input_length=max_sequence_length, \n","                    weights=[pg_embeddings], trainable=True)(inp)\n","x = AttentionLayer(max_len)(x)\n","x = keras.layers.Dense(gru_units*2, activation='relu')(x)\n","x = keras.layers.Dropout(rate=0.2)(x)\n","x = keras.layers.Dense(gru_units, activation='relu')(x)\n","x = keras.layers.Dropout(rate=0.2)(x)\n","\n","outp = keras.layers.Dense(1, activation='sigmoid')(x)\n","# initialize the model\n","model = keras.models.Model(inputs=inp, outputs=outp)\n","model.compile(loss='categorical_crossentropy', \n","              optimizer='adam', \n","              metrics=['accuracy'])\n","\n","\n","mw = ku.ModelWrapper(model, MODEL_NAME, LABEL_COLUMN, DATA_FILE,\n","                     embedding=EMBED_SIZE,\n","                     tokenizer=t, description=\"Pre-trained Embedding - paragram\")\n","\n","\n","network_history = mw.fit(X_train, y_train,\n","                      batch_size=BATCH_SIZE,\n","                      epochs=EPOCHS,\n","                      verbose=1,\n","                      validation_split=0.2,\n","                      callbacks=[reduce_lr, early_stop])\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by {{node bidirectional_1/CudnnRNN}}with these attrs: [seed=87654321, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"gru\", is_training=true, seed2=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[bidirectional_1/CudnnRNN]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-9099c247ae46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mEMBED_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     weights=[pg_embeddings], trainable=True)(inp)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttentionLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_units\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;31m# Load weights that were specified at layer instantiation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mparam_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(ops)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \"\"\"\n\u001b[1;32m   2419\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by node bidirectional_1/CudnnRNN (defined at /usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py:297) with these attrs: [seed=87654321, dropout=0, T=DT_FLOAT, input_mode=\"linear_input\", direction=\"unidirectional\", rnn_mode=\"gru\", is_training=true, seed2=0]\nRegistered devices: [CPU, XLA_CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[bidirectional_1/CudnnRNN]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node bidirectional_1/CudnnRNN:\n bidirectional_1/ExpandDims_1 (defined at /usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py:273)\t\n bidirectional_1/concat (defined at /usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py:60)\t\n bidirectional_1/transpose (defined at /usr/local/lib/python3.6/dist-packages/keras/layers/cudnn_recurrent.py:271)"]}]},{"cell_type":"code","metadata":{"id":"zXi8fOwOLuSY","colab_type":"code","outputId":"245ab0d8-8c71-4708-80b0-e4fbb0740f28","executionInfo":{"status":"ok","timestamp":1564646635002,"user_tz":420,"elapsed":353,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-2.37248142e-01, -1.22240219e-01, -2.24036211e-01,\n","        -1.18400449e-01, -8.95509420e-02,  4.07487098e-01,\n","        -5.83458725e-01, -5.35285833e-01,  4.05001557e-01,\n","        -3.92891890e-01, -9.62554805e-01,  1.14978469e-01,\n","        -2.67563920e-01,  7.76065163e-02, -2.71578070e-01,\n","         6.45317581e-01, -1.67960207e-01, -2.55414393e-02,\n","        -3.92467597e-02,  8.91531022e-01, -1.18249568e+00,\n","        -5.25316941e-01, -5.67054779e-01,  1.28508804e-01,\n","         6.21470361e-01, -3.26528030e-01, -1.00567880e-01,\n","         2.32459440e-01,  6.88036270e-01, -6.28223759e-01,\n","        -2.47412930e-01,  2.31602231e-01,  6.48537292e-02,\n","         1.95445532e-01, -2.57372761e-01, -1.76315115e-01,\n","        -6.01665050e-03, -6.25397357e-01,  6.67910767e-01,\n","        -1.50553274e-01,  5.52504054e-01, -1.02782965e-01,\n","         2.15866674e-01, -9.64930139e-01,  2.38529526e-01,\n","        -5.82853130e-01,  1.08787729e+00, -1.50640432e-01,\n","         7.29183877e-02,  1.18933724e-03, -1.98510079e-01,\n","        -4.08458696e-01, -9.41780795e-01, -9.30904961e-02,\n","        -3.92764731e-01, -2.18663836e-01, -5.04839587e-01,\n","         6.58868838e-01,  3.10410650e-01, -7.52634029e-01,\n","         3.20381948e-01,  1.84255914e-01, -3.69808643e-01,\n","         2.78445133e-01, -1.77109389e-01,  2.05360446e-01,\n","         2.52846312e-01,  4.44138150e-02,  4.73274614e-01,\n","         1.87692449e-01, -1.23438070e+00,  5.77509420e-01,\n","         2.25687309e-01,  5.26701451e-01,  3.34305744e-01,\n","        -7.61771844e-01, -2.54779560e-01,  2.47766073e-01,\n","        -7.38616202e-01, -9.05690020e-02, -5.29796810e-01,\n","         2.24853803e-01,  1.77513883e-01,  7.22923510e-02,\n","         1.11563317e+00, -5.72927508e-02,  9.25595247e-02,\n","         1.46655480e-01,  5.77666953e-01, -4.38176888e-01,\n","         3.58509154e-01, -8.48617922e-01, -2.48193451e-01,\n","        -1.02569277e+00,  6.04560334e-01,  9.88916846e-02,\n","        -5.29272510e-01,  2.98126167e-01,  4.15908713e-03,\n","        -7.43626092e-02, -1.26748346e-03, -9.00069579e-01,\n","         7.72874929e-01,  4.97529043e-01,  8.57940972e-01,\n","         2.54749622e-01, -2.14108704e-01, -3.08783708e-01,\n","         1.52287810e+00, -3.82293930e-02,  2.41648072e-01,\n","        -6.22968232e-01,  1.22999658e-01, -1.84333010e-01,\n","        -6.91512441e-01,  9.13243238e-01,  1.09878012e+00,\n","        -1.26603096e-01,  9.07729766e-01,  5.59682429e-01,\n","         4.23972588e-02,  1.96629075e-01,  1.94288690e-01,\n","         8.14054344e-01,  2.18511729e-01, -4.37969376e-01,\n","         8.07814893e-01,  3.22207163e-02,  1.75779382e-01,\n","         2.22574710e-01, -1.03120659e-01,  5.59117246e-01,\n","         6.86294918e-01,  8.08866155e-01,  4.69779639e-01,\n","         4.62467083e-02, -2.00260368e-01, -3.82016483e-01,\n","        -8.16424868e-01, -6.24449557e-01,  2.16336565e-01,\n","        -6.27393066e-01, -3.76887771e-01,  7.96847258e-01,\n","        -4.87426310e-01, -3.92679737e-01,  3.60676711e-01,\n","         4.93559008e-01,  4.77655371e-01,  3.19101094e-01,\n","         4.87066025e-02,  7.37809951e-02, -6.84085315e-01,\n","        -7.28993544e-01, -4.99038780e-01, -4.06862891e-01,\n","        -2.55407929e-02, -6.00308506e-01, -3.30369983e-01,\n","        -1.74591763e-01, -1.28613067e-01,  2.62782389e-01,\n","         2.65048338e-01,  6.77419501e-01, -3.67638584e-01,\n","         3.18775788e-01,  1.33725768e+00, -1.02369281e-01,\n","         2.55561449e-01,  1.88499689e-01,  5.37832584e-01,\n","         5.14515478e-02,  7.17769798e-01,  5.80612525e-01,\n","         6.06438813e-01,  9.42307169e-01, -1.30828827e-01,\n","        -5.13116282e-01, -1.33606231e-01, -1.86855557e-02,\n","        -4.05960572e-02, -7.59388006e-03,  2.27079485e-02,\n","        -2.31757268e-02,  3.65314064e-01, -8.66454211e-01,\n","         7.56183821e-01,  5.13361512e-01,  1.68829695e-01,\n","         7.13526925e-01,  1.82052044e-01,  2.13676544e-01,\n","        -1.30867860e-01, -7.94718433e-02,  5.80174053e-01,\n","         3.99935921e-01,  4.70733162e-01, -1.79451435e-02,\n","         4.81492250e-02,  5.01706796e-01,  1.18990028e-01,\n","        -4.84384837e-01,  4.93595309e-01,  6.10646843e-01,\n","         1.20717936e-01,  2.28601354e-01, -2.94723889e-01,\n","         3.07219494e-02, -4.10200180e-01,  1.79652935e-02,\n","         2.66784220e-01, -3.89973642e-01,  7.45494019e-01,\n","         1.57816133e-01, -5.70691433e-01,  8.21571506e-01,\n","         4.04211673e-02, -3.43052568e-01, -7.60907722e-01,\n","         3.62339945e-01,  1.35685972e-01, -2.15240138e-03,\n","        -1.08709925e-01,  8.65179463e-02,  3.74390111e-01,\n","        -7.64128312e-01, -1.66782057e-01,  1.96756086e-02,\n","        -4.52907868e-01,  2.05101265e-01, -9.42256302e-01,\n","        -2.72602865e-01, -5.97777320e-03, -3.50176779e-01,\n","         1.40320066e-01, -4.51213457e-02, -3.28909588e-01,\n","         1.00824743e+00,  4.96165502e-01,  2.94949075e-01,\n","        -3.08121396e-01, -3.78395580e-02,  1.59933805e-01,\n","        -3.72201311e-01, -1.81144504e-01, -3.10814987e-01,\n","        -2.40254286e-01, -6.91561974e-01, -4.20905325e-01,\n","         1.05197068e-01,  2.69323760e-01, -2.58903496e-01,\n","         2.77646502e-01,  9.32815087e-02, -1.20617645e+00,\n","        -5.93332952e-01,  5.19648803e-03, -2.87371811e-01,\n","        -2.26185785e-01,  3.23897906e-02, -4.19461536e-01,\n","        -5.57066542e-01,  2.33908725e-01,  4.06764374e-02,\n","        -6.52612144e-01,  3.83700452e-01, -2.78907600e-01,\n","         1.73436379e-01,  5.12965866e-01,  1.75633800e-01,\n","        -3.13406616e-03, -7.40627358e-01,  7.24589376e-02,\n","        -7.95156549e-01, -4.24634005e-01,  1.61960025e-01,\n","         1.95087540e-01, -6.39946667e-01, -3.09862980e-01,\n","         3.01992540e-01, -2.16150370e-02, -8.37978766e-01,\n","        -3.84565366e-01,  3.33721202e-01,  6.31272093e-01,\n","         1.52278928e-01, -8.48239214e-01, -7.31522497e-01,\n","        -3.20273143e-02, -3.88320200e-01, -2.17459578e-01,\n","         2.97054217e-01,  1.38795799e-01,  6.11518093e-01,\n","         1.32554397e-01,  9.44918459e-01,  1.12966689e-01,\n","         3.94588419e-01, -4.77118771e-01,  1.41622038e-01],\n","       [-2.84508139e-01, -6.48900792e-02, -1.31111726e-01,\n","        -1.43762872e-01, -2.27645457e-01, -1.85010508e-01,\n","         7.49797761e-01, -2.73510545e-01,  2.75032252e-01,\n","         1.61416960e+00,  1.44688770e-01, -4.83499700e-03,\n","         2.87035972e-01, -4.96524632e-01, -1.28722370e-01,\n","         1.03337419e+00,  8.19466352e-01,  9.07721996e-01,\n","         6.11647964e-02,  1.09486294e+00,  4.51895930e-02,\n","        -4.02880520e-01,  1.19834833e-01, -2.96125233e-01,\n","        -2.92547047e-01, -1.50551945e-01, -5.52187502e-01,\n","        -3.69164884e-01,  1.42752075e+00, -1.20810971e-01,\n","        -2.55043864e-01, -1.32000104e-01,  1.58482010e-03,\n","        -5.33563137e-01, -5.36092967e-02,  1.78402424e-01,\n","         6.32178068e-01,  4.84596282e-01,  5.38084172e-02,\n","        -1.72294065e-01,  5.13741113e-02,  6.01684749e-01,\n","         1.26238540e-01,  1.53092653e-01,  3.03112596e-01,\n","         9.50348154e-02,  2.71596074e-01,  1.14446178e-01,\n","         2.75264800e-01,  6.63308799e-01, -3.73087645e-01,\n","        -1.58166811e-01,  1.40546426e-01, -2.89850950e-01,\n","         1.95566863e-01,  9.31078494e-02,  4.84914064e-01,\n","        -8.60296190e-01,  6.14391863e-02, -2.00773746e-01,\n","         1.51942208e-01,  3.03565443e-01, -1.22438751e-01,\n","         3.17366272e-01, -2.08512470e-01,  1.93145409e-01,\n","        -4.52676356e-01, -5.24925888e-01,  1.20094046e-01,\n","         2.61657923e-01, -1.47447055e-02,  9.82075572e-01,\n","        -7.95397386e-02, -1.53346375e-01, -3.27326685e-01,\n","         6.86599612e-02, -1.42349594e-03,  3.35223943e-01,\n","         9.07306969e-01,  6.21722400e-01, -2.57424653e-01,\n","        -3.39506298e-01, -5.48642159e-01,  5.42614400e-01,\n","        -1.13228631e+00, -4.49766546e-01,  1.14114702e+00,\n","        -1.13687015e+00,  4.17849779e-01, -3.41129184e-01,\n","        -5.13229251e-01,  3.02813172e-01, -5.91645598e-01,\n","         2.15869352e-01, -1.78163588e-01,  1.66918427e-01,\n","         3.16651762e-02,  5.12313187e-01,  1.64731324e-01,\n","        -9.26753804e-02, -3.25435698e-01,  9.13407981e-01,\n","        -1.58387199e-01, -1.19698703e-01, -3.32329646e-02,\n","        -3.81153785e-02, -8.81723046e-01, -3.46975833e-01,\n","         1.06024936e-01,  1.10771120e+00, -8.03478062e-02,\n","        -3.92677009e-01, -3.40915918e-01, -6.38101459e-01,\n","         1.53428182e-01, -5.22626519e-01,  3.52796942e-01,\n","        -6.09992504e-01, -3.27922851e-01, -3.02222371e-01,\n","        -1.95519015e-01, -3.88767198e-02,  4.13042456e-01,\n","        -5.44121683e-01, -4.40493494e-01, -5.54264665e-01,\n","        -1.13367096e-01, -3.79627377e-01,  7.55692244e-01,\n","        -8.67000759e-01,  4.48873669e-01, -2.11087510e-01,\n","         2.12030858e-01,  2.89324913e-02,  5.96968532e-01,\n","        -2.20397130e-01,  4.94076163e-01, -1.79056227e-01,\n","        -3.65709037e-01, -6.51415408e-01, -1.81668341e+00,\n","         3.27316411e-02,  7.20256329e-01, -6.36020660e-01,\n","         4.35185492e-01, -1.33032769e-01, -2.55871080e-02,\n","         3.08184177e-01,  1.72573198e-02,  3.69418174e-01,\n","         7.63182700e-01, -1.30665258e-01,  5.31143785e-01,\n","         5.00940263e-01,  5.30084334e-02, -8.65030229e-01,\n","        -4.29166585e-01, -2.88512260e-01,  2.44222403e-01,\n","         2.02827677e-01, -2.21138522e-01, -4.53585953e-01,\n","         1.40210409e-02,  4.32380557e-01, -1.36415288e-01,\n","         4.15305883e-01, -5.32700479e-01, -4.10388738e-01,\n","         1.59332812e-01,  9.78510231e-02, -7.30845571e-01,\n","        -7.34437823e-01, -2.16096759e-01, -2.47164920e-01,\n","        -2.22133085e-01,  6.97325945e-01, -5.19130528e-02,\n","         2.86616474e-01, -8.20949435e-01, -7.45484471e-01,\n","         1.00656539e-01, -1.47518098e-01, -6.63776416e-03,\n","        -7.70568967e-01, -8.17588389e-01,  3.62020247e-02,\n","         1.78137645e-01,  3.14717107e-02,  6.71751678e-01,\n","        -3.09715152e-01,  6.26236260e-01,  2.91498238e-03,\n","        -3.63654375e-01,  8.19839001e-01,  4.30520117e-01,\n","        -3.77721310e-01, -1.57275841e-01, -3.72978002e-01,\n","         6.14054680e-01,  8.84044528e-01, -3.98029864e-01,\n","         2.76913375e-01, -1.87495813e-01, -3.59678954e-01,\n","        -2.49330759e-01,  2.17562452e-01, -1.83112919e-01,\n","        -2.24176973e-01,  5.28810203e-01,  7.93688223e-02,\n","        -1.49418086e-01, -1.36368200e-01,  3.92888069e-01,\n","        -2.06635565e-01,  5.40643096e-01, -4.09929663e-01,\n","        -3.77173871e-01,  6.92189932e-01, -2.48830929e-01,\n","         2.51958549e-01, -3.51255059e-01,  5.82702041e-01,\n","        -1.66536570e-01, -2.31084555e-01, -2.54349168e-02,\n","         4.48421985e-01,  4.24950160e-02, -6.35832429e-01,\n","        -1.37207329e-01,  3.97755429e-02, -3.55315089e-01,\n","        -4.59643066e-01,  1.02835011e+00, -3.51422131e-02,\n","        -2.67223060e-01,  2.23968685e-01,  7.87085831e-01,\n","        -3.98864359e-01, -6.82681561e-01, -1.47500977e-01,\n","         1.10016540e-01,  6.38878107e-01,  1.09829620e-01,\n","         7.85196841e-01, -3.03134620e-01, -8.40882659e-01,\n","         3.42374533e-01,  1.27346694e-01,  3.56275737e-01,\n","         5.36242843e-01,  3.75795931e-01, -8.92832875e-02,\n","        -7.98177600e-01, -6.33803189e-01,  7.40146399e-01,\n","         4.49999683e-02, -9.36913371e-01, -9.68485028e-02,\n","         4.95700449e-01, -6.80054724e-02,  6.78270042e-01,\n","        -2.23564312e-01,  2.31021523e-01,  6.32725477e-01,\n","        -5.92916846e-01, -3.72819543e-01,  6.34493887e-01,\n","        -2.53144085e-01,  3.37149739e-01,  5.25310216e-03,\n","         2.34888047e-01,  5.69348872e-01,  1.34776890e-01,\n","         2.73899406e-01,  4.32851106e-01,  5.38787663e-01,\n","        -6.27147108e-02, -1.30086631e-01,  1.29076168e-01,\n","         3.22885603e-01, -1.76341441e-02, -1.45363569e-01,\n","         5.84996343e-01, -2.78634548e-01, -4.67867911e-01,\n","        -3.23144197e-01, -3.14450473e-01, -4.72807251e-02,\n","        -7.86228478e-03, -1.62552327e-01, -1.07342765e-01,\n","         2.48789787e-02,  1.57055900e-01, -3.29392403e-01,\n","         5.11998713e-01, -1.62352890e-01,  3.87607694e-01,\n","        -7.24126577e-01, -3.55806530e-01,  1.53972879e-01]])"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"vrkfnfuaM4lK","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}