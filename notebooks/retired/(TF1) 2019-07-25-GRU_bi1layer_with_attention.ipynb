{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"(TF1) 2019-07-25-GRU_bi1layer_with_attention.ipynb","provenance":[{"file_id":"https://github.com/sv650s/sb-capstone/blob/master/2019-07-22-GRU_prototype.ipynb","timestamp":1564105983299}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W7_sb1roJXhx"},"source":["# GRU Prototype With Attention\n","\n","Previous notebook we implemented a [single layer GRU](https://github.com/sv650s/sb-capstone/blob/master/2019-07-22-GRU_prototype.ipynb) without attention\n","\n","For this notebook, we will implement a 1 layer bidirectional GRU network with attention and 3 dense layer architecture\n","\n","\n","As before, I am using some utility functions so I don't have copy so much code around. Source code for the modules are here:\n","* [dict_util](https://github.com/sv650s/sb-capstone/blob/master/util/dict_util.py)\n","* [plot_util](https://github.com/sv650s/sb-capstone/blob/master/util/plot_util.py)\n","* [keras_util](https://github.com/sv650s/sb-capstone/blob/master/util/keras_util.py)\n","* [file_util](https://github.com/sv650s/sb-capstone/blob/master/util/file_util.py)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gwrIhSxpG--S","outputId":"376e4d58-ca3a-4dac-ee9f-cd7bf6ae658b","executionInfo":{"status":"ok","timestamp":1564378178976,"user_tz":420,"elapsed":1531,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","import sys\n","drive.mount('/content/drive')\n","# add this to sys patch so we can import utility functions\n","DRIVE_DIR = 'drive/My Drive/Springboard/capstone'\n","sys.path.append(DRIVE_DIR)\n","\n","\n","%tensorflow_version 2.x\n","\n","\n","import tensorflow as tf\n","# checl to make sure we are using GPU here\n","tf.test.gpu_device_name()\n","\n","try:\n","  %tensorflow_version 2.x  # Colab only.\n","except Exception:\n","  pass\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pAHGtniuJXhy","outputId":"4b143d6c-03d2-4210-dde2-98656a4a5bd3","executionInfo":{"status":"ok","timestamp":1564378181423,"user_tz":420,"elapsed":3965,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, Dropout\n","from tensorflow.keras.layers.normalization import BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers.convolutional import Conv1D, MaxPooling1D\n","from tensorflow.keras.layers.embeddings import Embedding\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing import sequence\n","from tensorlfow.keras.layers import CuDNNGRU\n","\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","\n","import pandas as pd\n","from IPython.display import SVG\n","from keras.utils.vis_utils import model_to_dot\n","import pickle\n","from datetime import datetime\n","from sklearn.metrics import confusion_matrix, classification_report\n","import os\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import logging\n","\n","\n","import util.dict_util as du\n","import util.plot_util as pu\n","import util.file_util as fu\n","import util.keras_util as ku\n","import util.report_util as ru\n","\n","\n","\n","logging.basicConfig(level=logging.ERROR)\n","\n","%matplotlib inline\n","sns.set()\n","\n","\n","DATE_FORMAT = '%Y-%m-%d'\n","TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n","# DATA_DIR = \"dataset/feature_files\"\n","MODEL_NAME = \"LSTM\"\n","FEATURE_COLUMN = \"star_rating\"\n","REVIEW_COLUMN = \"review_body\"\n","\n","\n","if DEBUG:\n","  DATA_FILE = f'{DRIVE_DIR}/review_body-word2vec-df_none-ngram_none-89-100-nolda.csv'\n","else:\n","  DATA_FILE = f\"{DRIVE_DIR}/amazon_reviews_us_Wireless_v1_00-200k-preprocessed.csv\"\n","  # DATA_FILE = f\"{DRIVE_DIR}/amazon_reviews_us_Wireless_v1_00-preprocessed-110k.csv\"\n","\n","MODEL_NAME = \"GRUbi\"\n","ARCHITECTURE = \"1_attention\"\n","\n","\n","GRU_DIM = 250 # total GRU units\n","\n","\n","# length of our embedding - 300 is standard\n","EMBED_SIZE = 300\n","EPOCHS  = 50\n","BATCH_SIZE = 128\n","PATIENCE = 4\n","\n","\n","# From EDA, we know that 90% of review bodies have 100 words or less, \n","# we will use this as our sequence length\n","MAX_SEQUENCE_LENGTH = 100\n","\n","\n","directory, INBASENAME = fu.get_dir_basename(DATA_FILE)\n","DESCRIPTION = f\"{MODEL_NAME}-{ARCHITECTURE}-nobatch-{INBASENAME}-sampling_none-{FEATURE_COLUMN}\"\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","hide_input":false,"id":"k6fwJp9OJXh5","colab":{}},"source":["df = pd.read_csv(f\"{DATA_FILE}\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EBQR0ZpoOiQk"},"source":["## Preprocessing\n","\n","*  Preprocessing data file and create the right inputs for Keras models\n","     *   Features:\n","        * tokenize\n","        * pad features into sequence\n","     *   Labels:\n","       *  one hot encoder\n","* split between training and testing\n","\n","See [keras_util](https://github.com/sv650s/sb-capstone/blob/master/util/keras_util.py) for souce code"]},{"cell_type":"code","metadata":{"id":"PzGwNuPXAzNa","colab_type":"code","outputId":"b523f884-e67a-4f78-c389-2e424f571b62","executionInfo":{"status":"ok","timestamp":1564378188898,"user_tz":420,"elapsed":11418,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["X_train, X_test, y_train, y_test, tokenizer = \\\n","                                  ku.preprocess_file(data_df=df, \n","                                                      feature_column=FEATURE_COLUMN, \n","                                                      label_column=LABEL_COLUMN, \n","                                                      max_sequence_length=MAX_SEQUENCE_LENGTH)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["One hot enocde label data...\n","Splitting data into training and test sets...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n","If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n","In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n","  warnings.warn(msg, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Vocabulary size=40788\n","Number of Documents=84032\n","Max Sequence Length: 186\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qd8t1zSvBzgh","colab_type":"text"},"source":["# Building Our GRU Model"]},{"cell_type":"code","metadata":{"id":"xulwNtQpGF6J","colab_type":"code","colab":{}},"source":["# from keras.engine.topology import Layer\n","# from keras import backend as K\n","# import keras\n","\n","\n","# class AttentionLayer(Layer):\n","    \n","#     def __init__(self, step_dim,\n","#                  W_regularizer=None, b_regularizer=None,\n","#                  W_constraint=None, b_constraint=None,\n","#                  bias=True, **kwargs):\n","        \n","#         \"\"\"\n","#         Keras Layer that implements an Attention mechanism for temporal data.\n","#         Supports Masking.\n","#         Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n","#         # Input shape\n","#             3D tensor with shape: `(samples, steps, features)`.\n","#         # Output shape\n","#             2D tensor with shape: `(samples, features)`.\n","#         :param kwargs:\n","#         Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n","#         The dimensions are inferred based on the output shape of the RNN.\n","#         \"\"\"\n","        \n","#         self.supports_masking = True\n","#         self.init = keras.initializers.get('glorot_uniform')\n","\n","#         self.W_regularizer = keras.regularizers.get(W_regularizer)\n","#         self.b_regularizer = keras.regularizers.get(b_regularizer)\n","\n","#         self.W_constraint = keras.constraints.get(W_constraint)\n","#         self.b_constraint = keras.constraints.get(b_constraint)\n","\n","#         self.bias = bias\n","#         self.step_dim = step_dim\n","#         self.features_dim = 0\n","#         super(AttentionLayer, self).__init__(**kwargs)\n","        \n","\n","#     def build(self, input_shape):\n","#         assert len(input_shape) == 3\n","\n","#         self.W = self.add_weight((input_shape[-1],),\n","#                                  initializer=self.init,\n","#                                  name='{}_W'.format(self.name),\n","#                                  regularizer=self.W_regularizer,\n","#                                  constraint=self.W_constraint)\n","#         self.features_dim = input_shape[-1]\n","\n","#         if self.bias:\n","#             self.b = self.add_weight((input_shape[1],),\n","#                                      initializer='zero',\n","#                                      name='{}_b'.format(self.name),\n","#                                      regularizer=self.b_regularizer,\n","#                                      constraint=self.b_constraint)\n","#         else:\n","#             self.b = None\n","\n","#         self.built = True\n","        \n","\n","#     def compute_mask(self, input, input_mask=None):\n","#         # do not pass the mask to the next layers\n","#         return None\n","\n","    \n","#     def call(self, x, mask=None):\n","#         # TF backend doesn't support it\n","#         # eij = K.dot(x, self.W) \n","#         # features_dim = self.W.shape[0]\n","#         # step_dim = x._keras_shape[1]\n","\n","#         features_dim = self.features_dim\n","#         step_dim = self.step_dim\n","\n","#         eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), \n","#                               K.reshape(self.W, (features_dim, 1))),\n","#                         (-1, step_dim))\n","\n","#         if self.bias:\n","#             eij += self.b\n","\n","#         eij = K.tanh(eij)\n","\n","#         a = K.exp(eij)\n","\n","#         # apply mask after the exp. will be re-normalized next\n","#         if mask is not None:\n","#             # Cast the mask to floatX to avoid float64 upcasting in theano\n","#             a *= K.cast(mask, K.floatx())\n","\n","#         # in some cases especially in the early stages of training the sum may be almost zero\n","#         a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n","#         a = K.expand_dims(a)\n","#         weighted_input = x * a\n","        \n","#         return K.sum(weighted_input, axis=1)\n","\n","    \n","#     def compute_output_shape(self, input_shape):\n","#         return input_shape[0],  self.features_dim\n","    \n","    \n","#     def get_config(self):\n","#         config = {'step_dim': self.step_dim}\n","#         base_config = super(AttentionLayer, self).get_config()\n","#         return dict(list(base_config.items()) + list(config.items()))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LxDcAouddq88","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"653DtCuBJXiF","outputId":"a8d127fc-8299-4d22-af95-be436dcc2541","executionInfo":{"status":"ok","timestamp":1564378191266,"user_tz":420,"elapsed":13776,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":309}},"source":["vocab_size = len(tokenizer.word_counts)+1\n","\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, EMBED_SIZE, input_length=max_sequence_length))\n","model.add(Bidirectional(CuDNNGRU(GRU_DIM*2, return_sequences=True)))\n","model.add(AttentionLayer(MAX_SEQUENCE_LENGTH))\n","model.add(Dense(GRU_DIM*2, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(GRU_DIM, activation='relu'))\n","model.add(Dense(5, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', \n","              optimizer='adam', \n","              metrics=['categorical_accuracy'])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0729 05:29:48.871664 139623069144960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0729 05:29:48.877236 139623069144960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0729 05:29:48.881768 139623069144960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0729 05:29:50.668831 139623069144960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0729 05:29:50.681504 139623069144960 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0729 05:29:50.728600 139623069144960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0729 05:29:50.758916 139623069144960 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iZitdxXPJXiI","outputId":"f1a24489-943c-43ee-cedd-51242b681379","executionInfo":{"status":"ok","timestamp":1564378191268,"user_tz":420,"elapsed":13770,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":391}},"source":["print(model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 186, 300)          12236700  \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 186, 1000)         2406000   \n","_________________________________________________________________\n","attention_layer_1 (Attention (None, 1000)              1186      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 500)               500500    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 500)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 250)               125250    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 5)                 1255      \n","=================================================================\n","Total params: 15,270,891\n","Trainable params: 15,270,891\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"60eC_0fRJXiQ","outputId":"396a6541-809d-4b94-94bf-7bf799cb9015","executionInfo":{"status":"error","timestamp":1564378208348,"user_tz":420,"elapsed":30841,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}},"colab":{"base_uri":"https://localhost:8080/","height":463}},"source":["# reduce learning rate if we sense a plateau\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n","                              factor=0.4,\n","                              patience=PATIENCE, \n","                              min_lr=0.00001,\n","                             mode='auto')\n","early_stop = EarlyStopping(monitor='val_loss', \n","                           patience=2, \n","                           mode='auto', \n","                           verbose=1,\n","                          restore_best_weights=True)\n","\n","mw = ku.ModelWrapper(model, MODEL_NAME, LABEL_COLUMN, DATA_FILE, \n","                     embedding=EMBED_SIZE,\n","                     tokenizer=tokenizer,\n","                     description=DESCRIPTION)\n","\n","\n","network_history = mw.fit(X_train, y_train,\n","                      batch_size=BATCH_SIZE,\n","                      epochs=EPOCHS,\n","                      verbose=1,\n","                      validation_split=0.2,\n","                      callbacks=[reduce_lr, early_stop])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["W0729 05:29:50.922225 139623069144960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 67225 samples, validate on 16807 samples\n","Epoch 1/50\n"," 4992/67225 [=>............................] - ETA: 3:09 - loss: 1.2816 - acc: 0.5445"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-642b10f65da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m                       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                       \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                       callbacks=[reduce_lr, early_stop])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"I9-JeeLQDoFm","colab_type":"text"},"source":["## Evaluating the Model"]},{"cell_type":"code","metadata":{"id":"kkYmBlpADrKV","colab_type":"code","colab":{}},"source":["importlib.reload(pu)\n","\n","scores = mw.evaluate(x_test, y_test)\n","print(\"Accuracy: %.2f%%\" % (mw.scores[1]*100))\n","\n","\n","\n","pu.plot_network_history(mw.network_history, \"categorical_accuracy\", \"val_categorical_accuracy\")\n","plt.show()\n","\n","print(\"\\nConfusion Matrix\")\n","print(mw.confusion_matrix)\n","\n","print(\"\\nClassification Report\")\n","print(mw.classification_report)\n","\n","fig = plt.figure(figsize=(5,5))\n","pu.plot_roc_auc(mw.name, mw.roc_auc, mw.fpr, mw.tpr)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cISHAzDmSo73","colab_type":"text"},"source":["## Save off filees"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VjW8V1MR61kJ","colab":{}},"source":["importlib.reload(ku)\n","importlib.reload(ru)\n","\n","mw.save(DRIVE_DIR, append_report=True)\n","report = mw.get_report().to_df()\n","print(report.tail())\n","\n","cr = json.loads(report.classification_report.values[0])\n","print(f'\\n\\nOverall score: {ru.calculate_metric(cr)}')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GjVjezXPJXin","colab":{}},"source":["print(datetime.now())"],"execution_count":0,"outputs":[]}]}