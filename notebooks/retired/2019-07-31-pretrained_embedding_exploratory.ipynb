{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2019-07-31-pretrained_embedding_exploratory.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"CQhfRIBf1YNB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"90fa6414-ac55-4ca6-c618-5021003b5818","executionInfo":{"status":"ok","timestamp":1564640439030,"user_tz":420,"elapsed":27401,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}}},"source":["from google.colab import drive\n","import sys\n","drive.mount('/content/drive')\n","DRIVE_DIR = \"drive/My Drive/Springboard/capstone\"\n","\n","# add this to sys patch so we can import utility functions\n","sys.path.append(DRIVE_DIR)\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pgaygfq23StT","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout, GRU, SpatialDropout1D, Bidirectional\n","from keras.layers.normalization import BatchNormalization\n","from keras.preprocessing.text import Tokenizer\n","from keras.callbacks import EarlyStopping\n","from keras.models import load_model\n","from sklearn.model_selection import train_test_split\n","from keras.optimizers import SGD\n","from sklearn.preprocessing import OneHotEncoder\n","from keras.layers import Flatten\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","from keras.layers.embeddings import Embedding\n","import pandas as pd\n","from IPython.display import SVG\n","from keras.utils.vis_utils import model_to_dot\n","import pickle\n","from datetime import datetime\n","from sklearn.metrics import confusion_matrix, classification_report\n","import os\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import dill\n","\n","\n","# custom utility functions\n","import util.dict_util as du\n","import util.plot_util as pu\n","import util.file_util as fu\n","import util.keras_util as ku\n","\n","\n","sns.set()\n","\n","import logging\n","logging.basicConfig(level=logging.INFO)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p-DtUZzU4AQ0","colab_type":"code","colab":{}},"source":["MAX_FEATURES = 100000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gemr9v-01fSW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":334},"outputId":"e3e30bf3-8e8b-4522-fb20-f76f6266ad63","executionInfo":{"status":"error","timestamp":1564641140874,"user_tz":420,"elapsed":792,"user":{"displayName":"Vince Luk","photoUrl":"","userId":"16057681301960694126"}}},"source":["GOOGLE_WORD2VEC_FILE = f\"{DRIVE_DIR}/data/GoogleNews-vectors-negative300.bin\"\n","tokenizer = Tokenizer(oov_token='<UNK>', num_words=MAX_FEATURES+1)\n","with open(GOOGLE_WORD2VEC_FILE, 'rb') as f:\n","    word2idx = dill.load(f)\n","tokenizer.word_index = word2idx"],"execution_count":13,"outputs":[{"output_type":"error","ename":"UnpicklingError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-e79a157372ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moov_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'<UNK>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_FEATURES\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGOOGLE_WORD2VEC_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mword2idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/dill/_dill.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, ignore)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;31m# apply kwd settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0mpik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ignore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_main_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '3'."]}]},{"cell_type":"code","metadata":{"id":"iFxZ2W-y3P7s","colab_type":"code","colab":{}},"source":["def load_pretrained_embeddings(word_to_index, max_features, embedding_size, embedding_file_path):    \n","    \n","    def get_coefs(word,*arr): \n","        return word, np.asarray(arr, dtype='float32')\n","\n","    # turns the embedding file into a dictionary key = word, value = word vector\n","    embeddings_index = dict(get_coefs(*row.split(\" \")) \n","                                for row in open(embedding_file_path, encoding=\"utf8\", errors='ignore') \n","                                    if len(row)>100)\n","\n","    # convert the values into a array of word arrays\n","    all_embs = np.stack(embeddings_index.values())\n","    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n","    embed_size = all_embs.shape[1]\n","\n","    nb_words = min(max_features, len(word_to_index))\n","    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embedding_size))\n","    \n","    for word, idx in word_to_index.items():\n","        if idx >= max_features: \n","            continue\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None: \n","            embedding_matrix[idx] = embedding_vector\n","\n","    return embedding_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YAhd5EVc7KMQ","colab_type":"code","colab":{}},"source":["EMBED_SIZE = 300 # how big is each word vector\n","MAX_FEATURES = 800000 # how many unique words to use (i.e num rows in embedding vector)\n","MAX_LEN = 200 # max number of words in a doc to use\n","\n","PARAGRAM_INIT_EMBEDDINGS_FILE = f'{DRIVE_DIR}/data/cve_model_paragram_init_embeddings.pkl'\n","\n","if not os.path.isfile(PARAGRAM_INIT_EMBEDDINGS_FILE):\n","    PARAGRAM_EMBEDDINGS_PATH = f'{DRIVE_DIR}/data/paragram_300_sl999/paragram_300_sl999.txt'\n","    pg_embeddings = load_pretrained_embeddings(word_to_index=word2idx, max_features=MAX_FEATURES, \n","                                               embedding_size=EMBED_SIZE, \n","                                               embedding_file_path=PARAGRAM_EMBEDDINGS_PATH)\n","    with open(PARAGRAM_INIT_EMBEDDINGS_FILE, 'wb') as f:\n","        dill.dump(pg_embeddings, f)\n","else:\n","    with open(PARAGRAM_INIT_EMBEDDINGS_FILE, 'rb') as f:\n","        pg_embeddings = dill.load(f)\n","        \n","pg_embeddings.shape "],"execution_count":0,"outputs":[]}]}