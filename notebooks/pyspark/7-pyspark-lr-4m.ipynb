{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Logistic Regression\n",
    "\n",
    "Our full dataset file has around 9 million samples. When trying to run feature_generator.\n",
    "\n",
    "Machine:\n",
    "* 2018 Mac Mini - 6 core\n",
    "\n",
    "Docker Configuration:\n",
    "* 9 CPUs\n",
    "* 24 GB Ram\n",
    "* 3 GB swap\n",
    "\n",
    "\n",
    "# References:\n",
    "\n",
    "* https://spark.apache.org/docs/2.2.0/mllib-feature-extraction.html\n",
    "* https://towardsdatascience.com/countvectorizer-hashingtf-e66f169e2d4e\n",
    "* https://medium.com/@dhiraj.p.rai/logistic-regression-in-spark-ml-8a95b5f5434c\n",
    "* packaging spark job - https://developerzen.com/best-practices-writing-production-grade-pyspark-jobs-cb688ac4d20f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkFiles\n",
    "from pyspark.sql import SparkSession, DataFrameReader, SQLContext\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import NGram, CountVectorizer, VectorAssembler, Tokenizer, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import when, lit, col\n",
    "from pyspark.sql.types import NumericType\n",
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import logging\n",
    "\n",
    "import util.pyspark_util as pyu\n",
    "import util.model_wrapper as mw\n",
    "\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# allow DEBUG to be set by command line\n",
    "DEBUG = bool(os.environ.get(\"IPYNB_DEBUG\", False))\n",
    "\n",
    "N_CLASSES = 5\n",
    "FEATURE_COLUMN = \"review_body\"\n",
    "\n",
    "if DEBUG:\n",
    "    MIN_DF = 1\n",
    "    DF_PERCENTAGE = 0.001\n",
    "    DATA_FILE = \"/home/jupyter/dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-test1k-preprocessed.csv\"\n",
    "    TEST_STR=\"-test\"\n",
    "else:\n",
    "    DF_PERCENTAGE = 0.001\n",
    "    DATA_FILE = \"/home/jupyter/dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-4m-preprocessed.csv\"\n",
    "    TEST_STR=\"\"\n",
    "\n",
    "REPORT_FILE = f\"../../reports/201911-pyspark-report{TEST_STR}.csv\"\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .appName(\"Pyspark Wrapper Test (local)\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Timer(object):\n",
    "    \n",
    "    def __init__(self, description: str):\n",
    "        self.start_time = datetime.now()\n",
    "        self.description = description\n",
    "        \n",
    "    def stop(self):\n",
    "        self.end_time = datetime.now()\n",
    "        self.print_duration_min()\n",
    "        \n",
    "    def print_duration_min(self):\n",
    "        self.duration = int((self.end_time - self.start_time).total_seconds() / 60)\n",
    "        print(f\"{self.description} duration: {self.duration} minutes\")\n",
    "        \n",
    "    def get_duraction_min(self):\n",
    "        return self.duration\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file load time duration: 0 minutes\n"
     ]
    }
   ],
   "source": [
    "file_timer = Timer(\"file load time\")\n",
    "df = spark.read.csv(SparkFiles.get(DATA_FILE), \n",
    "                    header=True, \n",
    "                    inferSchema= True)\n",
    "df.collect()\n",
    "file_timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Creating TFIDF using min_df: 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline time duration: 6 minutes\n"
     ]
    }
   ],
   "source": [
    "def build_ngrams(inputCol, min_df, n=3):\n",
    "    log.info(f'Creating TFIDF using min_df: {min_df}')\n",
    "    \n",
    "    tokenizer = [Tokenizer(inputCol = inputCol, outputCol = \"words\")]\n",
    "    \n",
    "    ngrams = [\n",
    "        NGram(n=i, inputCol=\"words\", outputCol=\"{0}_grams\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "\n",
    "    vectorizers = [\n",
    "        CountVectorizer(minDF=min_df, inputCol=\"{0}_grams\".format(i),\n",
    "            outputCol=\"{0}_counts\".format(i))\n",
    "        for i in range(1, n + 1)\n",
    "    ]\n",
    "\n",
    "    assembler = [VectorAssembler(\n",
    "        inputCols=[\"{0}_counts\".format(i) for i in range(1, n + 1)],\n",
    "        outputCol=\"raw_features\"\n",
    "    )]\n",
    "    \n",
    "    idf = [IDF().setInputCol(\"raw_features\").setOutputCol(\"features\")]\n",
    "#     idf = [IDF(minDocFreq=min_df).setInputCol(\"raw_features\").setOutputCol(\"features\")]\n",
    "\n",
    "    return Pipeline(stages=tokenizer + ngrams + vectorizers + assembler + idf)\n",
    "\n",
    "\n",
    "\n",
    "pipeline_timer = Timer(\"pipeline time\")\n",
    "# calculate a reasonable min_df\n",
    "min_df = max(int(df.count() * DF_PERCENTAGE), 1)\n",
    "\n",
    "pipeline = build_ngrams(FEATURE_COLUMN, min_df)\n",
    "df = pipeline.fit(df).transform(df)\n",
    "pipeline_timer.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: timestamp (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 1_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- 2_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- 3_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- 1_counts: vector (nullable = true)\n",
      " |-- 2_counts: vector (nullable = true)\n",
      " |-- 3_counts: vector (nullable = true)\n",
      " |-- raw_features: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|star_rating|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|4          |(4062,[20,37,119,153,403,469,1026,3439],[2.074543806417613,2.8400244856100536,3.380836336920255,3.623457198805495,4.5301093467661815,4.652340662964539,5.6180409032112495,6.702368699257155])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|5          |(4062,[6,62,2587],[1.6798110034983487,2.9077582769387726,5.907307489101227])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "|5          |(4062,[1,2,5,98,204,225,316,787,2194,2254,3062],[1.1912444083491804,1.38573876563059,1.768447082757103,3.259405143545389,3.8233944372020825,3.9847418086561253,4.262432157788201,5.2847106131417885,3.6775244200757706,4.730847044076062,6.4573170552312105])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|1          |(4062,[1,16,61,72,84,102,347,434,2250,2576,2674],[1.1912444083491804,2.11537782530421,3.4040466863668737,3.044560438435941,3.3909107237939886,3.2448222853841835,4.32810704268442,4.608049576738904,4.699755878477928,5.8930684752517575,6.070291577653922])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "|5          |(4062,[20,25,321],[2.074543806417613,2.4211380497712383,4.312426197944014])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|3          |(4062,[1,2,16,118,121,137,236,329,362,453,3744],[1.1912444083491804,1.38573876563059,2.11537782530421,3.377117401661653,3.420135832682375,3.5312949275523646,3.926578673437313,4.307420465336997,4.421682892554136,4.676156363721347,6.858489287679188])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "|3          |(4062,[2,3,4,19,42,53,63,65,94,96,115,160,167,171,202,219,225,313,396,431,454,461,558,587,596,688,713,1143,1633,1696,2500,2697,2710,2918,3618,3780],[1.38573876563059,1.4686245992928681,1.595054603566807,2.1368781264891497,2.7034435790514912,2.9271303950637777,3.029191069922708,3.0588161036317776,3.2669771015473974,3.2454575013950198,3.4154309464103494,3.7190502934590217,3.6855751701056043,3.6037576106970826,3.981922787807864,3.924804589792848,3.9847418086561253,4.2192789813925735,4.5205535902681815,4.643183878186276,4.741820973806451,9.667406969173417,4.909625729025672,4.975618364964341,5.023037126813968,5.095254331067988,5.439075054264268,5.804487428777802,6.515375660422597,6.435410892034397,5.729562177643658,6.076151605275145,6.092058912343654,6.373311039617481,6.803846065591594,6.891390174895841])                                                                                                                                                                                                                                                                                                                                                                                                           |\n",
      "|5          |(4062,[8,103,171,2407],[1.7774012965211257,3.2778898853630407,3.6037576106970826,5.518341040525971])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|5          |(4062,[6,1316],[1.6798110034983487,5.990565201865115])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "|2          |(4062,[4,10,11,14,21,28,30,34,41,45,48,63,73,77,83,104,122,133,142,144,168,175,186,209,257,272,294,306,322,392,484,544,590,622,657,726,840,860,905,906,942,958,988,1002,1104,1112,1446,1519,1720,2187,2281,2331,2508,3169],[1.595054603566807,5.74436622311816,2.036966764171714,4.700722293601827,2.2248121317573277,2.5810302100933136,2.6024513389107695,2.6913334618472993,3.049687251151886,2.8046701129039393,2.8142529878269325,3.029191069922708,3.090889715061591,3.122311000954738,3.1814839556511068,3.3100871674215764,3.4128477313041086,3.525307829157816,3.536433332938771,3.6702051638490967,3.676348548041151,3.9175510053254334,3.999216467130492,3.9710702161565323,8.300021621712087,4.054696305969921,4.190250169109141,4.3635388465617195,4.565469069136508,4.524904676269404,4.735962726238084,15.077666356677115,5.161909116768457,5.011335789210618,5.054352349541498,5.369384064981865,5.774983388667291,5.388844255747563,5.590543329049659,11.04554905988949,5.612822903043662,11.249896878276722,5.575191640283195,5.627168966037857,5.71353007611105,5.9282083474729355,6.17755344047115,6.246486087320183,6.491515347705983,3.242144701807524,5.164661231735332,5.188566752588886,5.78290710412216,6.5569226165270065])|\n",
      "+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "pyu.show_df(df, [\"star_rating\", \"features\"], truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test split duration: 0 minutes\n",
      "Training size: 3599433 Test size: 400567\n"
     ]
    }
   ],
   "source": [
    "split_timer = Timer(\"train test split\")\n",
    "train, test = df.randomSplit([0.9, 0.1], seed=1)\n",
    "split_timer.stop()\n",
    "\n",
    "\n",
    "train_size = train.count()\n",
    "test_size = test.count()\n",
    "\n",
    "print(f'Training size: {train_size} Test size: {test_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4062"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train.select(\"features\").limit(1).toPandas().features.values[0])\n",
    "train.select(\"features\").limit(1).toPandas().features.values[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign class weights to handle imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn class weights: [1.42502984 3.00140338 2.21772426 1.19866428 0.37314711]\n",
      "skelarn class weight duration: 4 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# only do this for small files - takes too long for large datasets - we will custom compute this\n",
    "# if DEBUG:\n",
    "cw_timer = Timer(\"skelarn class weight\")\n",
    "labels = train.select(\"star_rating\").toPandas().astype({\"star_rating\": np.int8})\n",
    "class_weights = compute_class_weight('balanced', \n",
    "                                                  np.arange(1, N_CLASSES+1), \n",
    "                                                  labels.star_rating.tolist())\n",
    "print(f'sklearn class weights: {class_weights}')\n",
    "cw_timer.stop()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:util.pyspark_util:sampling percentage: 5.556430693389764e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+--------------------+\n",
      "|star_rating|     class_weights|            features|\n",
      "+-----------+------------------+--------------------+\n",
      "|          5|0.3731471105052275|(4062,[249],[4.00...|\n",
      "|          4|1.1986642778408656|(4062,[3,4,8,23,1...|\n",
      "|          5|0.3731471105052275|        (4062,[],[])|\n",
      "|          3|2.2177242564832444|(4062,[0,3,4,8,15...|\n",
      "|          5|0.3731471105052275|(4062,[45],[2.804...|\n",
      "|          5|0.3731471105052275|(4062,[6,18,21,14...|\n",
      "|          5|0.3731471105052275|(4062,[3,6,19,183...|\n",
      "|          5|0.3731471105052275|(4062,[4,17,236,7...|\n",
      "|          1|1.4250298412623001|(4062,[0,1,4,5,6,...|\n",
      "|          3|2.2177242564832444|(4062,[0,1,2,3,5,...|\n",
      "|          5|0.3731471105052275|(4062,[4,9,16,21,...|\n",
      "|          5|0.3731471105052275|(4062,[236],[3.92...|\n",
      "|          5|0.3731471105052275|(4062,[4,8,593,21...|\n",
      "|          5|0.3731471105052275|(4062,[2,3,5,7,10...|\n",
      "|          1|1.4250298412623001|(4062,[0,5,6,15,1...|\n",
      "|          5|0.3731471105052275|(4062,[4,6,18,136...|\n",
      "|          1|1.4250298412623001|(4062,[0,11,53,89...|\n",
      "|          5|0.3731471105052275|(4062,[3,16,21,25...|\n",
      "|          5|0.3731471105052275|(4062,[9,194],[1....|\n",
      "+-----------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = train.withColumn(\"class_weights\", lit(0))\n",
    "train = train.withColumn(\"class_weights\", when(train.star_rating == 1, class_weights[0]).otherwise(train.class_weights))\n",
    "train = train.withColumn(\"class_weights\", when(train.star_rating == 2, class_weights[1]).otherwise(train.class_weights))\n",
    "train = train.withColumn(\"class_weights\", when(train.star_rating == 3, class_weights[2]).otherwise(train.class_weights))\n",
    "train = train.withColumn(\"class_weights\", when(train.star_rating == 4, class_weights[3]).otherwise(train.class_weights))\n",
    "train = train.withColumn(\"class_weights\", when(train.star_rating == 5, class_weights[4]).otherwise(train.class_weights))\n",
    "\n",
    "\n",
    "pyu.show_df(train, [\"star_rating\", \"class_weights\", \"features\"], 20, sample=True, truncate=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:util.model_wrapper:derived name: LogisticRegression\n",
      "INFO:util.model_wrapper:########################################\n",
      "INFO:util.model_wrapper:Running model: name: LogisticRegression\n",
      "\twith file: /home/jupyter/dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-4m-preprocessed.csv\n",
      "\twith description: review_body-tfidf-df_none-ngram13-4000000-4062-nolda-sampling_none-LogisticRegression-star_rating\n",
      "\tstatus: new\n",
      "INFO:util.model_wrapper:########################################\n",
      "INFO:util.time_util:Start timer for: train_time_min\n",
      "INFO:util.time_util:End timer for: train_time_min\n",
      "INFO:util.time_util:Total time for train_time_min: 9.24\n",
      "INFO:util.time_util:Start timer for: model_save_time_min\n",
      "INFO:util.pyspark_util:Saving model to file: ../../models/review_body-tfidf-df_none-ngram13-4000000-4062-nolda-sampling_none-LogisticRegression-star_rating.pyspark\n",
      "INFO:util.pyspark_util:Saving pipeline to file: ../../models/review_body-tfidf-df_none-ngram13-4000000-4062-nolda-sampling_none-LogisticRegression-star_rating.pipeline\n",
      "INFO:util.time_util:End timer for: model_save_time_min\n",
      "INFO:util.time_util:Total time for model_save_time_min: 0.06\n",
      "INFO:util.time_util:Start timer for: predict_time_min\n",
      "INFO:util.time_util:End timer for: predict_time_min\n",
      "INFO:util.time_util:Total time for predict_time_min: 0.0\n",
      "INFO:util.model_wrapper:Finished running model: name: LogisticRegression\n",
      "\twith file: /home/jupyter/dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-4m-preprocessed.csv\n",
      "\twith description: review_body-tfidf-df_none-ngram13-4000000-4062-nolda-sampling_none-LogisticRegression-star_rating\n",
      "\tstatus: new\n",
      "INFO:util.model_wrapper:calculating classification report...\n",
      "INFO:util.time_util:Start timer for: cr_time_min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: timestamp (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 1_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- 2_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- 3_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- 1_counts: vector (nullable = true)\n",
      " |-- 2_counts: vector (nullable = true)\n",
      " |-- 3_counts: vector (nullable = true)\n",
      " |-- raw_features: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:util.time_util:End timer for: cr_time_min\n",
      "INFO:util.time_util:Total time for cr_time_min: 22.4\n",
      "INFO:util.model_wrapper:calculating confusion matrix...\n",
      "INFO:util.time_util:Start timer for: cm_time_min\n",
      "INFO:util.time_util:End timer for: cm_time_min\n",
      "INFO:util.time_util:Total time for cm_time_min: 17.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traing time duration: 60 minutes\n",
      "+-----------+----------+--------------------+--------------------+\n",
      "|star_rating|prediction|       rawPrediction|         probability|\n",
      "+-----------+----------+--------------------+--------------------+\n",
      "|          1|       3.0|[-11.239410706546...|[2.41684991181446...|\n",
      "|          1|       1.0|[-11.239817063842...|[5.65291853279899...|\n",
      "|          1|       1.0|[-11.241254458185...|[2.87313233157420...|\n",
      "|          1|       4.0|[-11.240128983482...|[1.60808639258465...|\n",
      "|          1|       1.0|[-11.240004405371...|[7.80407951563997...|\n",
      "|          1|       4.0|[-11.241332823142...|[1.83731964750253...|\n",
      "|          1|       1.0|[-11.239817173648...|[5.52347692716429...|\n",
      "|          1|       2.0|[-11.245228723665...|[1.38307615963895...|\n",
      "|          1|       1.0|[-11.239690894214...|[2.94214689019417...|\n",
      "|          1|       1.0|[-11.239338246987...|[1.29448070883170...|\n",
      "+-----------+----------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import importlib\n",
    "import util.constants as c\n",
    "importlib.reload(pyu)\n",
    "importlib.reload(mw)\n",
    "importlib.reload(c)\n",
    "\n",
    "feature_count = train.select(\"features\").limit(1).toPandas().features.values[0].size\n",
    "\n",
    "train_timer = Timer(\"traing time\")\n",
    "lr = LogisticRegression(labelCol=\"star_rating\", \n",
    "                        featuresCol=\"features\", \n",
    "                        weightCol=\"class_weights\",\n",
    "                        maxIter=100)\n",
    "\n",
    "\n",
    "model = pyu.PysparkModel(model = lr,\n",
    "                    train_df = train,\n",
    "                    test_df = test,\n",
    "                    label_column = \"star_rating\",\n",
    "                    feature_column = \"features\",\n",
    "                    n_classes = 5,\n",
    "                         pipeline = pipeline,\n",
    "                         file = DATA_FILE,\n",
    "                         description=f'review_body-tfidf-df_none-ngram13-{df.count()}-{feature_count}-nolda-sampling_none{TEST_STR}',\n",
    "                        model_dir=\"../../models\")\n",
    "\n",
    "report_dict, predict_test = model.run()\n",
    "train_timer.stop()\n",
    "\n",
    "pyu.show_df(predict_test, [\"star_rating\", \"prediction\", \"rawPrediction\", \"probability\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- star_rating: integer (nullable = true)\n",
      " |-- helpful_votes: integer (nullable = true)\n",
      " |-- total_votes: integer (nullable = true)\n",
      " |-- review_headline: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      " |-- review_date: timestamp (nullable = true)\n",
      " |-- words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- 1_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- 2_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- 3_grams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- 1_counts: vector (nullable = true)\n",
      " |-- 2_counts: vector (nullable = true)\n",
      " |-- 3_counts: vector (nullable = true)\n",
      " |-- raw_features: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate our Model\n",
    "\n",
    "Reference:\n",
    "* https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html#multiclass-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'LogisticRegression',\n",
       " 'description': 'review_body-tfidf-df_none-ngram13-4000000-4062-nolda-sampling_none-LogisticRegression-star_rating',\n",
       " 'library': 'pyspark',\n",
       " 'file': '/home/jupyter/dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-4m-preprocessed.csv',\n",
       " 'model_file': '../../models/review_body-tfidf-df_none-ngram13-4000000-4062-nolda-sampling_none-LogisticRegression-star_rating.pyspark',\n",
       " 'pipeline_file': '../../models/review_body-tfidf-df_none-ngram13-4000000-4062-nolda-sampling_none-LogisticRegression-star_rating.pipeline',\n",
       " 'status': 'success',\n",
       " 'status_date': '2019-11-22 20:32:13',\n",
       " 'classification_report': '{\"1\": {\"precision\": 0.7077948197764914, \"recall\": 0.7190625943890695, \"f1-score\": 0.7133842167421692, \"support\": 56283}, \"2\": {\"precision\": 0.3029374502813706, \"recall\": 0.3895582329317269, \"f1-score\": 0.3408303638021049, \"support\": 26394}, \"3\": {\"precision\": 0.3267918984153636, \"recall\": 0.42920939464108504, \"f1-score\": 0.37106326187724176, \"support\": 36276}, \"4\": {\"precision\": 0.4066969290929476, \"recall\": 0.4434059299673539, \"f1-score\": 0.4242588485319603, \"support\": 67083}, \"5\": {\"precision\": 0.861420302760463, \"recall\": 0.7575548522125007, \"f1-score\": 0.8061558303054354, \"support\": 214531}, \"accuracy\": 0.6455524294312811, \"macro avg\": {\"precision\": 0.5211282800653272, \"recall\": 0.5477582008283473, \"f1-score\": 0.5311385042517823, \"support\": 400567}, \"weighted avg\": {\"precision\": 0.6784659217483456, \"recall\": 0.6455524294312811, \"f1-score\": 0.6591005852910398, \"support\": 400567}}',\n",
       " 'confusion_matrix': '[[40471, 10286, 3602, 790, 1134], [8058, 10282, 5915, 1242, 897], [3581, 7434, 15570, 6706, 2985], [1557, 2692, 11960, 29745, 21129], [3512, 3247, 10598, 34655, 162519]]',\n",
       " 'train_examples': 3599433,\n",
       " 'train_features': 4062,\n",
       " 'test_examples': 400567,\n",
       " 'test_features': 4062,\n",
       " 'train_time_min': 9.24,\n",
       " 'total_time_min': 48.72,\n",
       " 'model_save_time_min': 0.06,\n",
       " 'predict_time_min': 0.0,\n",
       " 'cr_time_min': 22.4,\n",
       " 'cm_time_min': 17.02}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'f1-score': 0.7133842167421692,\n",
      "       'precision': 0.7077948197764914,\n",
      "       'recall': 0.7190625943890695,\n",
      "       'support': 56283},\n",
      " '2': {'f1-score': 0.3408303638021049,\n",
      "       'precision': 0.3029374502813706,\n",
      "       'recall': 0.3895582329317269,\n",
      "       'support': 26394},\n",
      " '3': {'f1-score': 0.37106326187724176,\n",
      "       'precision': 0.3267918984153636,\n",
      "       'recall': 0.42920939464108504,\n",
      "       'support': 36276},\n",
      " '4': {'f1-score': 0.4242588485319603,\n",
      "       'precision': 0.4066969290929476,\n",
      "       'recall': 0.4434059299673539,\n",
      "       'support': 67083},\n",
      " '5': {'f1-score': 0.8061558303054354,\n",
      "       'precision': 0.861420302760463,\n",
      "       'recall': 0.7575548522125007,\n",
      "       'support': 214531},\n",
      " 'accuracy': 0.6455524294312811,\n",
      " 'macro avg': {'f1-score': 0.5311385042517823,\n",
      "               'precision': 0.5211282800653272,\n",
      "               'recall': 0.5477582008283473,\n",
      "               'support': 400567},\n",
      " 'weighted avg': {'f1-score': 0.6591005852910398,\n",
      "                  'precision': 0.6784659217483456,\n",
      "                  'recall': 0.6455524294312811,\n",
      "                  'support': 400567}}\n"
     ]
    }
   ],
   "source": [
    "pprint(json.loads(report_dict[\"classification_report\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 40471  10286   3602    790   1134]\n",
      " [  8058  10282   5915   1242    897]\n",
      " [  3581   7434  15570   6706   2985]\n",
      " [  1557   2692  11960  29745  21129]\n",
      " [  3512   3247  10598  34655 162519]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(json.loads(report_dict[\"confusion_matrix\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall score: 0.5152664037560394\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def calculate_score(cr: dict):\n",
    "    \n",
    "    values = []\n",
    "    values.append(cr[\"1\"][\"recall\"])\n",
    "    values.append(cr[\"2\"][\"recall\"])\n",
    "    values.append(cr[\"3\"][\"recall\"])\n",
    "    values.append(cr[\"4\"][\"recall\"])\n",
    "    values.append(cr[\"5\"][\"precision\"])\n",
    "    \n",
    "    mean = 0\n",
    "    for v in values:\n",
    "        if v == 0:\n",
    "            mean = 0\n",
    "            break\n",
    "        else:\n",
    "            mean += 1 / v\n",
    "    if mean > 0:\n",
    "        mean = len(values) / mean\n",
    "\n",
    "    return mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "score = calculate_score(json.loads(report_dict['classification_report']))\n",
    "print(f'Overall score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification_report</th>\n",
       "      <th>cm_time_min</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>cr_time_min</th>\n",
       "      <th>description</th>\n",
       "      <th>file</th>\n",
       "      <th>library</th>\n",
       "      <th>model_file</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_save_time_min</th>\n",
       "      <th>pipeline_file</th>\n",
       "      <th>predict_time_min</th>\n",
       "      <th>status</th>\n",
       "      <th>status_date</th>\n",
       "      <th>test_examples</th>\n",
       "      <th>test_features</th>\n",
       "      <th>total_time_min</th>\n",
       "      <th>train_examples</th>\n",
       "      <th>train_features</th>\n",
       "      <th>train_time_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>152</td>\n",
       "      <td>526.00</td>\n",
       "      <td>1885]]'</td>\n",
       "      <td>0.35</td>\n",
       "      <td>review_body-tfidf-df_none-ngram13-49784-4254-n...</td>\n",
       "      <td>/home/jupyter/dataset/amazon_reviews/amazon_re...</td>\n",
       "      <td>pyspark</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.06</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>success</td>\n",
       "      <td>2019-11-22 07:50:22</td>\n",
       "      <td>5058.0</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>44726.0</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"1\": {\"precision\": 0.6406469760900141, \"recal...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>[[911, 280, 132, 46, 36], [221, 214, 150, 61, ...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>review_body-tfidf-df_none-ngram13-99567-4159-n...</td>\n",
       "      <td>/home/jupyter/dataset/amazon_reviews/amazon_re...</td>\n",
       "      <td>pyspark</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.05</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>success</td>\n",
       "      <td>2019-11-22 07:53:26</td>\n",
       "      <td>10023.0</td>\n",
       "      <td>4159.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>89544.0</td>\n",
       "      <td>4159.0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"1\": {\"precision\": 0.6127167630057804, \"recal...</td>\n",
       "      <td>0.28</td>\n",
       "      <td>[[424, 173, 80, 31, 27], [90, 97, 73, 35, 19],...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>review_body-tfidf-df_none-ngram13-49784-4254-n...</td>\n",
       "      <td>/home/jupyter/dataset/amazon_reviews/amazon_re...</td>\n",
       "      <td>pyspark</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.04</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>success</td>\n",
       "      <td>2019-11-22 18:23:18</td>\n",
       "      <td>5058.0</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>44726.0</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"1\": {\"precision\": 0.6406469760900141, \"recal...</td>\n",
       "      <td>0.37</td>\n",
       "      <td>[[911, 280, 132, 46, 36], [221, 214, 150, 61, ...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>review_body-tfidf-df_none-ngram13-99567-4159-n...</td>\n",
       "      <td>/home/jupyter/dataset/amazon_reviews/amazon_re...</td>\n",
       "      <td>pyspark</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.04</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>success</td>\n",
       "      <td>2019-11-22 18:26:20</td>\n",
       "      <td>10023.0</td>\n",
       "      <td>4159.0</td>\n",
       "      <td>1.14</td>\n",
       "      <td>89544.0</td>\n",
       "      <td>4159.0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"1\": {\"precision\": 0.6762513312034079, \"recal...</td>\n",
       "      <td>0.55</td>\n",
       "      <td>[[1905, 566, 257, 48, 64], [408, 465, 326, 82,...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>review_body-tfidf-df_none-ngram13-199134-4082-...</td>\n",
       "      <td>/home/jupyter/dataset/amazon_reviews/amazon_re...</td>\n",
       "      <td>pyspark</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.04</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>success</td>\n",
       "      <td>2019-11-22 18:30:24</td>\n",
       "      <td>19966.0</td>\n",
       "      <td>4082.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>179168.0</td>\n",
       "      <td>4082.0</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{\"1\": {\"precision\": 0.6981843575418994, \"recal...</td>\n",
       "      <td>1.36</td>\n",
       "      <td>[[4999, 1352, 474, 114, 142], [1023, 1170, 774...</td>\n",
       "      <td>1.41</td>\n",
       "      <td>review_body-tfidf-df_none-ngram13-497835-4107-...</td>\n",
       "      <td>/home/jupyter/dataset/amazon_reviews/amazon_re...</td>\n",
       "      <td>pyspark</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.04</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>success</td>\n",
       "      <td>2019-11-22 18:38:59</td>\n",
       "      <td>49846.0</td>\n",
       "      <td>4107.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>447989.0</td>\n",
       "      <td>4107.0</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{\"1\": {\"precision\": 0.7026024905554779, \"recal...</td>\n",
       "      <td>2.63</td>\n",
       "      <td>[[10043, 2635, 928, 224, 272], [1991, 2504, 13...</td>\n",
       "      <td>2.60</td>\n",
       "      <td>review_body-tfidf-df_none-ngram13-995688-4073-...</td>\n",
       "      <td>/home/jupyter/dataset/amazon_reviews/amazon_re...</td>\n",
       "      <td>pyspark</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.04</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>success</td>\n",
       "      <td>2019-11-22 18:55:13</td>\n",
       "      <td>99684.0</td>\n",
       "      <td>4073.0</td>\n",
       "      <td>7.22</td>\n",
       "      <td>896004.0</td>\n",
       "      <td>4073.0</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{\"1\": {\"precision\": 0.7038692554826093, \"recal...</td>\n",
       "      <td>5.29</td>\n",
       "      <td>[[20156, 5132, 1794, 428, 592], [4081, 5217, 2...</td>\n",
       "      <td>5.26</td>\n",
       "      <td>review_body-tfidf-df_none-ngram13-2000000-4068...</td>\n",
       "      <td>/home/jupyter/dataset/amazon_reviews/amazon_re...</td>\n",
       "      <td>pyspark</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.04</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>success</td>\n",
       "      <td>2019-11-22 19:27:12</td>\n",
       "      <td>200264.0</td>\n",
       "      <td>4068.0</td>\n",
       "      <td>13.93</td>\n",
       "      <td>1799736.0</td>\n",
       "      <td>4068.0</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{\"1\": {\"precision\": 0.7077948197764914, \"recal...</td>\n",
       "      <td>17.02</td>\n",
       "      <td>[[40471, 10286, 3602, 790, 1134], [8058, 10282...</td>\n",
       "      <td>22.40</td>\n",
       "      <td>review_body-tfidf-df_none-ngram13-4000000-4062...</td>\n",
       "      <td>/home/jupyter/dataset/amazon_reviews/amazon_re...</td>\n",
       "      <td>pyspark</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.06</td>\n",
       "      <td>../../models/review_body-tfidf-df_none-ngram13...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>success</td>\n",
       "      <td>2019-11-22 20:32:13</td>\n",
       "      <td>400567.0</td>\n",
       "      <td>4062.0</td>\n",
       "      <td>48.72</td>\n",
       "      <td>3599433.0</td>\n",
       "      <td>4062.0</td>\n",
       "      <td>9.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               classification_report  cm_time_min  \\\n",
       "0                                                152       526.00   \n",
       "1  {\"1\": {\"precision\": 0.6406469760900141, \"recal...         0.32   \n",
       "2  {\"1\": {\"precision\": 0.6127167630057804, \"recal...         0.28   \n",
       "3  {\"1\": {\"precision\": 0.6406469760900141, \"recal...         0.37   \n",
       "4  {\"1\": {\"precision\": 0.6762513312034079, \"recal...         0.55   \n",
       "5  {\"1\": {\"precision\": 0.6981843575418994, \"recal...         1.36   \n",
       "6  {\"1\": {\"precision\": 0.7026024905554779, \"recal...         2.63   \n",
       "7  {\"1\": {\"precision\": 0.7038692554826093, \"recal...         5.29   \n",
       "8  {\"1\": {\"precision\": 0.7077948197764914, \"recal...        17.02   \n",
       "\n",
       "                                    confusion_matrix  cr_time_min  \\\n",
       "0                                            1885]]'         0.35   \n",
       "1  [[911, 280, 132, 46, 36], [221, 214, 150, 61, ...         0.45   \n",
       "2  [[424, 173, 80, 31, 27], [90, 97, 73, 35, 19],...         0.30   \n",
       "3  [[911, 280, 132, 46, 36], [221, 214, 150, 61, ...         0.41   \n",
       "4  [[1905, 566, 257, 48, 64], [408, 465, 326, 82,...         0.59   \n",
       "5  [[4999, 1352, 474, 114, 142], [1023, 1170, 774...         1.41   \n",
       "6  [[10043, 2635, 928, 224, 272], [1991, 2504, 13...         2.60   \n",
       "7  [[20156, 5132, 1794, 428, 592], [4081, 5217, 2...         5.26   \n",
       "8  [[40471, 10286, 3602, 790, 1134], [8058, 10282...        22.40   \n",
       "\n",
       "                                         description  \\\n",
       "0  review_body-tfidf-df_none-ngram13-49784-4254-n...   \n",
       "1  review_body-tfidf-df_none-ngram13-99567-4159-n...   \n",
       "2  review_body-tfidf-df_none-ngram13-49784-4254-n...   \n",
       "3  review_body-tfidf-df_none-ngram13-99567-4159-n...   \n",
       "4  review_body-tfidf-df_none-ngram13-199134-4082-...   \n",
       "5  review_body-tfidf-df_none-ngram13-497835-4107-...   \n",
       "6  review_body-tfidf-df_none-ngram13-995688-4073-...   \n",
       "7  review_body-tfidf-df_none-ngram13-2000000-4068...   \n",
       "8  review_body-tfidf-df_none-ngram13-4000000-4062...   \n",
       "\n",
       "                                                file  library  \\\n",
       "0  /home/jupyter/dataset/amazon_reviews/amazon_re...  pyspark   \n",
       "1  /home/jupyter/dataset/amazon_reviews/amazon_re...  pyspark   \n",
       "2  /home/jupyter/dataset/amazon_reviews/amazon_re...  pyspark   \n",
       "3  /home/jupyter/dataset/amazon_reviews/amazon_re...  pyspark   \n",
       "4  /home/jupyter/dataset/amazon_reviews/amazon_re...  pyspark   \n",
       "5  /home/jupyter/dataset/amazon_reviews/amazon_re...  pyspark   \n",
       "6  /home/jupyter/dataset/amazon_reviews/amazon_re...  pyspark   \n",
       "7  /home/jupyter/dataset/amazon_reviews/amazon_re...  pyspark   \n",
       "8  /home/jupyter/dataset/amazon_reviews/amazon_re...  pyspark   \n",
       "\n",
       "                                          model_file          model_name  \\\n",
       "0  ../../models/review_body-tfidf-df_none-ngram13...  LogisticRegression   \n",
       "1  ../../models/review_body-tfidf-df_none-ngram13...  LogisticRegression   \n",
       "2  ../../models/review_body-tfidf-df_none-ngram13...  LogisticRegression   \n",
       "3  ../../models/review_body-tfidf-df_none-ngram13...  LogisticRegression   \n",
       "4  ../../models/review_body-tfidf-df_none-ngram13...  LogisticRegression   \n",
       "5  ../../models/review_body-tfidf-df_none-ngram13...  LogisticRegression   \n",
       "6  ../../models/review_body-tfidf-df_none-ngram13...  LogisticRegression   \n",
       "7  ../../models/review_body-tfidf-df_none-ngram13...  LogisticRegression   \n",
       "8  ../../models/review_body-tfidf-df_none-ngram13...  LogisticRegression   \n",
       "\n",
       "   model_save_time_min                                      pipeline_file  \\\n",
       "0                 0.06  ../../models/review_body-tfidf-df_none-ngram13...   \n",
       "1                 0.05  ../../models/review_body-tfidf-df_none-ngram13...   \n",
       "2                 0.04  ../../models/review_body-tfidf-df_none-ngram13...   \n",
       "3                 0.04  ../../models/review_body-tfidf-df_none-ngram13...   \n",
       "4                 0.04  ../../models/review_body-tfidf-df_none-ngram13...   \n",
       "5                 0.04  ../../models/review_body-tfidf-df_none-ngram13...   \n",
       "6                 0.04  ../../models/review_body-tfidf-df_none-ngram13...   \n",
       "7                 0.04  ../../models/review_body-tfidf-df_none-ngram13...   \n",
       "8                 0.06  ../../models/review_body-tfidf-df_none-ngram13...   \n",
       "\n",
       "   predict_time_min   status          status_date  test_examples  \\\n",
       "0               0.0  success  2019-11-22 07:50:22         5058.0   \n",
       "1               0.0  success  2019-11-22 07:53:26        10023.0   \n",
       "2               0.0  success  2019-11-22 18:23:18         5058.0   \n",
       "3               0.0  success  2019-11-22 18:26:20        10023.0   \n",
       "4               0.0  success  2019-11-22 18:30:24        19966.0   \n",
       "5               0.0  success  2019-11-22 18:38:59        49846.0   \n",
       "6               0.0  success  2019-11-22 18:55:13        99684.0   \n",
       "7               0.0  success  2019-11-22 19:27:12       200264.0   \n",
       "8               0.0  success  2019-11-22 20:32:13       400567.0   \n",
       "\n",
       "   test_features  total_time_min  train_examples  train_features  \\\n",
       "0         4254.0            1.00         44726.0          4254.0   \n",
       "1         4159.0            1.15         89544.0          4159.0   \n",
       "2         4254.0            0.89         44726.0          4254.0   \n",
       "3         4159.0            1.14         89544.0          4159.0   \n",
       "4         4082.0            1.70        179168.0          4082.0   \n",
       "5         4107.0            3.86        447989.0          4107.0   \n",
       "6         4073.0            7.22        896004.0          4073.0   \n",
       "7         4068.0           13.93       1799736.0          4068.0   \n",
       "8         4062.0           48.72       3599433.0          4062.0   \n",
       "\n",
       "   train_time_min  \n",
       "0            0.30  \n",
       "1            0.33  \n",
       "2            0.27  \n",
       "3            0.32  \n",
       "4            0.52  \n",
       "5            1.05  \n",
       "6            1.95  \n",
       "7            3.34  \n",
       "8            9.24  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(REPORT_FILE):\n",
    "    report_df = pd.read_csv(REPORT_FILE, quotechar=\"'\")\n",
    "else:\n",
    "    report_df = pd.DataFrame()\n",
    "report_df = report_df.append(report_dict, ignore_index=True)\n",
    "report_df.to_csv(REPORT_FILE, index=False, quotechar=\"'\")\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
