accuracy,architecture,batch_size,class_weight,classification_report,confusion_matrix,description,embedding,epochs,evaluate_time_min,feature_column,feature_set_name,file,label_column,loss,max_sequence_length,model_file,model_json_file,model_name,network_history_file,predict_time_min,roc_auc,sampling_type,status,status_date,test_examples,test_features,tokenizer_file,train_examples,train_features,train_time_min,weights_file
0.6360217332839966,1x128,128.0,'{"0": 1.420321175365166, "1": 3.028541072187481, "2": 2.2028792863609263, "3": 1.2028574528881977, "4": 0.3730735143988602}','{"1": {"precision": 0.6696899388314701, "recall": 0.7284198451390881, "f1-score": 0.6978213687189209, "support": 17435}, "2": {"precision": 0.2733482642777156, "recall": 0.3002090763743697, "f1-score": 0.28614969814196123, "support": 8131}, "3": {"precision": 0.31510386778377136, "recall": 0.4879154078549849, "f1-score": 0.38291492329149235, "support": 11254}, "4": {"precision": 0.3791049414689734, "recall": 0.3515200998991403, "f1-score": 0.36479178607919854, "support": 20821}, "5": {"precision": 0.8549315934888985, "recall": 0.7658908255923181, "f1-score": 0.8079654578486658, "support": 67067}, "accuracy": 0.636021746800526, "macro avg": {"precision": 0.4984357211701658, "recall": 0.5267910509719803, "f1-score": 0.5079286468160478, "support": 124708}, "weighted avg": {"precision": 0.6629555354528401, "recall": 0.636021746800526, "f1-score": 0.6461948908283398, "support": 124708}}','[[12700, 2804, 1532, 170, 229], [2854, 2441, 2325, 279, 232], [1331, 1882, 5491, 1761, 789], [590, 798, 4648, 7319, 7466], [1489, 1005, 3430, 9777, 51366]]','1 Layer 128 LSTM Units, Dropout 0.2, Recurrent Dropout 0.2, Batch Size 128, Learning Rate 0.01',300.0,5.0,1.89,'{"1": {"precision": 0.6696899388314701, "recall": 0.7284198451390881, "f1-score": 0.6978213687189209, "support": 17435}, "2": {"precision": 0.2733482642777156, "recall": 0.3002090763743697, "f1-score": 0.28614969814196123, "support": 8131}, "3": {"precision": 0.31510386778377136, "recall": 0.4879154078549849, "f1-score": 0.38291492329149235, "support": 11254}, "4": {"precision": 0.3791049414689734, "recall": 0.3515200998991403, "f1-score": 0.36479178607919854, "support": 20821}, "5": {"precision": 0.8549315934888985, "recall": 0.7658908255923181, "f1-score": 0.8079654578486658, "support": 67067}, "accuracy": 0.636021746800526, "macro avg": {"precision": 0.4984357211701658, "recall": 0.5267910509719803, "f1-score": 0.5079286468160478, "support": 124708}, "weighted avg": {"precision": 0.6629555354528401, "recall": 0.636021746800526, "f1-score": 0.6461948908283398, "support": 124708}}',glove_with_stop_nonlemmatized,drive/My Drive/Springboard/capstone/data/amazon_reviews_us_Wireless_v1_00-500k-with_stop_nonlemmatized-preprocessed.csv,'{"1": {"precision": 0.6696899388314701, "recall": 0.7284198451390881, "f1-score": 0.6978213687189209, "support": 17435}, "2": {"precision": 0.2733482642777156, "recall": 0.3002090763743697, "f1-score": 0.28614969814196123, "support": 8131}, "3": {"precision": 0.31510386778377136, "recall": 0.4879154078549849, "f1-score": 0.38291492329149235, "support": 11254}, "4": {"precision": 0.3791049414689734, "recall": 0.3515200998991403, "f1-score": 0.36479178607919854, "support": 20821}, "5": {"precision": 0.8549315934888985, "recall": 0.7658908255923181, "f1-score": 0.8079654578486658, "support": 67067}, "accuracy": 0.636021746800526, "macro avg": {"precision": 0.4984357211701658, "recall": 0.5267910509719803, "f1-score": 0.5079286468160478, "support": 124708}, "weighted avg": {"precision": 0.6629555354528401, "recall": 0.636021746800526, "f1-score": 0.6461948908283398, "support": 124708}}',0.9067877531051636,100.0,drive/My Drive/Springboard/capstone/models/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-model.h5,drive/My Drive/Springboard/capstone/models/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-model.json,LSTMB128,drive/My Drive/Springboard/capstone/reports/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-history.pkl,1.71,'{"auc_1": 0.9533729060641778, "auc_2": 0.8732030700176265, "auc_3": 0.8355582862017805, "auc_4": 0.7356656342437538, "auc_5": 0.894298958871958, "auc_micro": 0.8952722673293081, "auc_macro": 0.85842445581565}',none,success,2020-05-05 09:08:59,124708.0,100.0,drive/My Drive/Springboard/capstone/models/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-tokenizer.pkl,374123.0,100.0,63.31,drive/My Drive/Springboard/capstone/models/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-weights.h5
