accuracy,architecture,batch_size,class_weight,classification_report,confusion_matrix,description,embedding,epochs,evaluate_time_min,feature_column,feature_set_name,file,label_column,loss,max_sequence_length,model_file,model_json_file,model_name,network_history_file,predict_time_min,roc_auc,sampling_type,status,status_date,test_examples,test_features,tokenizer_file,train_examples,train_features,train_time_min,weights_file
0.6683853268623352,1x128,32.0,'{"0": 1.420321175365166, "1": 3.028541072187481, "2": 2.2028792863609263, "3": 1.2028574528881977, "4": 0.3730735143988602}','{"1": {"precision": 0.7635782747603834, "recall": 0.6579868081445368, "f1-score": 0.7068609630610925, "support": 17435}, "2": {"precision": 0.3100726239343227, "recall": 0.4830894108965687, "f1-score": 0.37771046684936777, "support": 8131}, "3": {"precision": 0.383202867803058, "recall": 0.46543451217344944, "f1-score": 0.4203346306624403, "support": 11254}, "4": {"precision": 0.42672761495025546, "recall": 0.45732673742855773, "f1-score": 0.44149762373942275, "support": 20821}, "5": {"precision": 0.8715449019382957, "recall": 0.7931322408934349, "f1-score": 0.8304918032786884, "support": 67067}, "accuracy": 0.668385348173333, "macro avg": {"precision": 0.551025256677263, "recall": 0.5713939419073095, "f1-score": 0.5553790975182024, "support": 124708}, "weighted avg": {"precision": 0.701507123914166, "recall": 0.668385348173333, "f1-score": 0.6817264844658544, "support": 124708}}','[[11472, 4569, 1003, 155, 236], [1994, 3928, 1795, 261, 153], [763, 2648, 5238, 1929, 676], [264, 775, 3485, 9522, 6775], [531, 748, 2148, 10447, 53193]]','1 Layer 128 LSTM Units, Dropout 0.2, Recurrent Dropout 0.2, Batch Size 32, Learning Rate 0.001',300.0,9.0,2.53,'{"1": {"precision": 0.7635782747603834, "recall": 0.6579868081445368, "f1-score": 0.7068609630610925, "support": 17435}, "2": {"precision": 0.3100726239343227, "recall": 0.4830894108965687, "f1-score": 0.37771046684936777, "support": 8131}, "3": {"precision": 0.383202867803058, "recall": 0.46543451217344944, "f1-score": 0.4203346306624403, "support": 11254}, "4": {"precision": 0.42672761495025546, "recall": 0.45732673742855773, "f1-score": 0.44149762373942275, "support": 20821}, "5": {"precision": 0.8715449019382957, "recall": 0.7931322408934349, "f1-score": 0.8304918032786884, "support": 67067}, "accuracy": 0.668385348173333, "macro avg": {"precision": 0.551025256677263, "recall": 0.5713939419073095, "f1-score": 0.5553790975182024, "support": 124708}, "weighted avg": {"precision": 0.701507123914166, "recall": 0.668385348173333, "f1-score": 0.6817264844658544, "support": 124708}}',glove_with_stop_nonlemmatized,drive/My Drive/Springboard/capstone/data/amazon_reviews_us_Wireless_v1_00-500k-with_stop_nonlemmatized-preprocessed.csv,'{"1": {"precision": 0.7635782747603834, "recall": 0.6579868081445368, "f1-score": 0.7068609630610925, "support": 17435}, "2": {"precision": 0.3100726239343227, "recall": 0.4830894108965687, "f1-score": 0.37771046684936777, "support": 8131}, "3": {"precision": 0.383202867803058, "recall": 0.46543451217344944, "f1-score": 0.4203346306624403, "support": 11254}, "4": {"precision": 0.42672761495025546, "recall": 0.45732673742855773, "f1-score": 0.44149762373942275, "support": 20821}, "5": {"precision": 0.8715449019382957, "recall": 0.7931322408934349, "f1-score": 0.8304918032786884, "support": 67067}, "accuracy": 0.668385348173333, "macro avg": {"precision": 0.551025256677263, "recall": 0.5713939419073095, "f1-score": 0.5553790975182024, "support": 124708}, "weighted avg": {"precision": 0.701507123914166, "recall": 0.668385348173333, "f1-score": 0.6817264844658544, "support": 124708}}',0.8181531429290771,100.0,drive/My Drive/Springboard/capstone/models/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-model.h5,drive/My Drive/Springboard/capstone/models/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-model.json,LSTMB128,drive/My Drive/Springboard/capstone/reports/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-history.pkl,2.22,'{"auc_1": 0.9652974894457775, "auc_2": 0.8981932432458364, "auc_3": 0.8689426676415828, "auc_4": 0.7749218349587885, "auc_5": 0.9162726059571096, "auc_micro": 0.9149493027994886, "auc_macro": 0.8847300797483699}',none,success,2020-05-06 00:50:12,124708.0,100.0,drive/My Drive/Springboard/capstone/models/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-tokenizer.pkl,374123.0,100.0,667.52,drive/My Drive/Springboard/capstone/models/LSTMB128-1x128-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-weights.h5
