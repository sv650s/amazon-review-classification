accuracy,architecture,batch_size,class_weight,classification_report,confusion_matrix,description,embedding,epochs,evaluate_time_min,feature_column,feature_set_name,file,label_column,loss,max_sequence_length,model_file,model_json_file,model_name,network_history_file,predict_time_min,roc_auc,sampling_type,status,status_date,test_examples,test_features,tokenizer_file,train_examples,train_features,train_time_min,weights_file
0.6433268189430237,1x16,128.0,'{"0": 1.420321175365166, "1": 3.028541072187481, "2": 2.2028792863609263, "3": 1.2028574528881977, "4": 0.3730735143988602}','{"1": {"precision": 0.7418775914351136, "recall": 0.6875824490966447, "f1-score": 0.7136988747990713, "support": 17435}, "2": {"precision": 0.2985545335085414, "recall": 0.4191366375599557, "f1-score": 0.3487158497902384, "support": 8131}, "3": {"precision": 0.3666222074024675, "recall": 0.39079438421894436, "f1-score": 0.3783225806451613, "support": 11254}, "4": {"precision": 0.37450170326882654, "recall": 0.4963258248883339, "f1-score": 0.4268924919962821, "support": 20821}, "5": {"precision": 0.8706381203948284, "recall": 0.7470141798500007, "f1-score": 0.8041023665647495, "support": 67067}, "accuracy": 0.6433268114315039, "macro avg": {"precision": 0.5304388312019555, "recall": 0.5481706951227758, "f1-score": 0.5343464327591005, "support": 124708}, "weighted avg": {"precision": 0.6870187624291683, "recall": 0.6433268114315039, "f1-score": 0.6603702470859891, "support": 124708}}','[[11988, 3873, 1014, 300, 260], [2260, 3408, 1737, 535, 191], [921, 2569, 4398, 2732, 634], [305, 805, 3018, 10334, 6359], [685, 760, 1829, 13693, 50100]]','1 Layer 16 LSTM Units, Dropout 0.2, Recurrent Dropout 0.2, Batch Size 128, Learning Rate 0.001',300.0,15.0,2.55,'{"1": {"precision": 0.7418775914351136, "recall": 0.6875824490966447, "f1-score": 0.7136988747990713, "support": 17435}, "2": {"precision": 0.2985545335085414, "recall": 0.4191366375599557, "f1-score": 0.3487158497902384, "support": 8131}, "3": {"precision": 0.3666222074024675, "recall": 0.39079438421894436, "f1-score": 0.3783225806451613, "support": 11254}, "4": {"precision": 0.37450170326882654, "recall": 0.4963258248883339, "f1-score": 0.4268924919962821, "support": 20821}, "5": {"precision": 0.8706381203948284, "recall": 0.7470141798500007, "f1-score": 0.8041023665647495, "support": 67067}, "accuracy": 0.6433268114315039, "macro avg": {"precision": 0.5304388312019555, "recall": 0.5481706951227758, "f1-score": 0.5343464327591005, "support": 124708}, "weighted avg": {"precision": 0.6870187624291683, "recall": 0.6433268114315039, "f1-score": 0.6603702470859891, "support": 124708}}',glove_with_stop_nonlemmatized,drive/My Drive/Springboard/capstone/data/amazon_reviews_us_Wireless_v1_00-500k-with_stop_nonlemmatized-preprocessed.csv,'{"1": {"precision": 0.7418775914351136, "recall": 0.6875824490966447, "f1-score": 0.7136988747990713, "support": 17435}, "2": {"precision": 0.2985545335085414, "recall": 0.4191366375599557, "f1-score": 0.3487158497902384, "support": 8131}, "3": {"precision": 0.3666222074024675, "recall": 0.39079438421894436, "f1-score": 0.3783225806451613, "support": 11254}, "4": {"precision": 0.37450170326882654, "recall": 0.4963258248883339, "f1-score": 0.4268924919962821, "support": 20821}, "5": {"precision": 0.8706381203948284, "recall": 0.7470141798500007, "f1-score": 0.8041023665647495, "support": 67067}, "accuracy": 0.6433268114315039, "macro avg": {"precision": 0.5304388312019555, "recall": 0.5481706951227758, "f1-score": 0.5343464327591005, "support": 124708}, "weighted avg": {"precision": 0.6870187624291683, "recall": 0.6433268114315039, "f1-score": 0.6603702470859891, "support": 124708}}',0.8634378910064697,100.0,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-model.h5,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-model.json,LSTMB16,drive/My Drive/Springboard/capstone/reports/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-history.pkl,2.26,'{"auc_1": 0.9613161679632258, "auc_2": 0.8879097226747417, "auc_3": 0.8556074384760544, "auc_4": 0.7552572980029382, "auc_5": 0.9060731637341312, "auc_micro": 0.9052562816746014, "auc_macro": 0.8732373664854798}',none,success,2020-05-04 18:45:04,124708.0,100.0,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-tokenizer.pkl,374123.0,100.0,284.79,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-weights.h5
