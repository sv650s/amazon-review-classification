accuracy,architecture,batch_size,class_weight,classification_report,confusion_matrix,description,embedding,epochs,evaluate_time_min,feature_column,feature_set_name,file,label_column,loss,max_sequence_length,model_file,model_json_file,model_name,network_history_file,predict_time_min,roc_auc,sampling_type,status,status_date,test_examples,test_features,tokenizer_file,train_examples,train_features,train_time_min,weights_file
0.6516181826591492,1x16,32.0,'{"0": 1.420321175365166, "1": 3.028541072187481, "2": 2.2028792863609263, "3": 1.2028574528881977, "4": 0.3730735143988602}','{"1": {"precision": 0.69863161297274, "recall": 0.7437912245483224, "f1-score": 0.7205044864849849, "support": 17435}, "2": {"precision": 0.3012216730392614, "recall": 0.39724511130242285, "f1-score": 0.34263286305293306, "support": 8131}, "3": {"precision": 0.35895851039171756, "recall": 0.41283099342456014, "f1-score": 0.38401454725792455, "support": 11254}, "4": {"precision": 0.39374207188160676, "recall": 0.447240766533788, "f1-score": 0.4187897731105665, "support": 20821}, "5": {"precision": 0.868706442291348, "recall": 0.7620141052976874, "f1-score": 0.8118700207312327, "support": 67067}, "accuracy": 0.6516181800686404, "macro avg": {"precision": 0.5242520621153347, "recall": 0.5526244402213563, "f1-score": 0.5355623381275284, "support": 124708}, "weighted avg": {"precision": 0.6826284866681457, "recall": 0.6516181800686404, "f1-score": 0.6642633334870777, "support": 124708}}','[[12968, 3152, 895, 163, 257], [2787, 3230, 1605, 322, 187], [1243, 2621, 4646, 2061, 683], [494, 880, 3538, 9312, 6597], [1070, 840, 2259, 11792, 51106]]','1 Layer 16 LSTM Units, Dropout 0.0, Recurrent Dropout 0.2, Batch Size 32, Learning Rate 0.001',300.0,14.0,1.9,'{"1": {"precision": 0.69863161297274, "recall": 0.7437912245483224, "f1-score": 0.7205044864849849, "support": 17435}, "2": {"precision": 0.3012216730392614, "recall": 0.39724511130242285, "f1-score": 0.34263286305293306, "support": 8131}, "3": {"precision": 0.35895851039171756, "recall": 0.41283099342456014, "f1-score": 0.38401454725792455, "support": 11254}, "4": {"precision": 0.39374207188160676, "recall": 0.447240766533788, "f1-score": 0.4187897731105665, "support": 20821}, "5": {"precision": 0.868706442291348, "recall": 0.7620141052976874, "f1-score": 0.8118700207312327, "support": 67067}, "accuracy": 0.6516181800686404, "macro avg": {"precision": 0.5242520621153347, "recall": 0.5526244402213563, "f1-score": 0.5355623381275284, "support": 124708}, "weighted avg": {"precision": 0.6826284866681457, "recall": 0.6516181800686404, "f1-score": 0.6642633334870777, "support": 124708}}',glove_with_stop_nonlemmatized,drive/My Drive/Springboard/capstone/data/amazon_reviews_us_Wireless_v1_00-500k-with_stop_nonlemmatized-preprocessed.csv,'{"1": {"precision": 0.69863161297274, "recall": 0.7437912245483224, "f1-score": 0.7205044864849849, "support": 17435}, "2": {"precision": 0.3012216730392614, "recall": 0.39724511130242285, "f1-score": 0.34263286305293306, "support": 8131}, "3": {"precision": 0.35895851039171756, "recall": 0.41283099342456014, "f1-score": 0.38401454725792455, "support": 11254}, "4": {"precision": 0.39374207188160676, "recall": 0.447240766533788, "f1-score": 0.4187897731105665, "support": 20821}, "5": {"precision": 0.868706442291348, "recall": 0.7620141052976874, "f1-score": 0.8118700207312327, "support": 67067}, "accuracy": 0.6516181800686404, "macro avg": {"precision": 0.5242520621153347, "recall": 0.5526244402213563, "f1-score": 0.5355623381275284, "support": 124708}, "weighted avg": {"precision": 0.6826284866681457, "recall": 0.6516181800686404, "f1-score": 0.6642633334870777, "support": 124708}}',0.8688611388206482,100.0,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-model.h5,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-model.json,LSTMB16,drive/My Drive/Springboard/capstone/reports/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-history.pkl,1.76,'{"auc_1": 0.9612450434581716, "auc_2": 0.8910402958995601, "auc_3": 0.8485055782509998, "auc_4": 0.7475736125838186, "auc_5": 0.9063980886120082, "auc_micro": 0.9048136799586157, "auc_macro": 0.8709571769328003}',none,success,2020-05-03 17:50:42,124708.0,100.0,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-tokenizer.pkl,374123.0,100.0,605.72,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-498831-100-review_body-weights.h5
