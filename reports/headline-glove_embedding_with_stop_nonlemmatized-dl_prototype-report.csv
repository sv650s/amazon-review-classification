accuracy,architecture,batch_size,class_weight,classification_report,confusion_matrix,description,embedding,epochs,evaluate_time_min,feature_column,feature_set_name,file,label_column,loss,max_sequence_length,model_file,model_json_file,model_name,network_history_file,predict_time_min,roc_auc,sampling_type,status,status_date,test_examples,test_features,tokenizer_file,train_examples,train_features,train_time_min,weights_file
0.7373837828636169,1x16,128.0,'[1.424159933765381, 3.025659610602293, 2.2047955271212474, 1.2012148429974956, 0.3729564944337697]','{"1": {"precision": 0.6921344505255, "recall": 0.8181193645341348, "f1-score": 0.7498720959214996, "support": 34935}, "2": {"precision": 0.5812684365781711, "recall": 0.23934167375197377, "f1-score": 0.33906908715477935, "support": 16466}, "3": {"precision": 0.5376719576719576, "recall": 0.44938752045283686, "f1-score": 0.48958157685544285, "support": 22613}, "4": {"precision": 0.6616643929058663, "recall": 0.3381253455778061, "f1-score": 0.44754510452795365, "support": 41597}, "5": {"precision": 0.7889447236180904, "recall": 0.950377400792168, "f1-score": 0.8621694915254237, "support": 133810}, "accuracy": 0.7373837808364171, "macro avg": {"precision": 0.652336792259917, "recall": 0.5590702610217839, "f1-score": 0.5776474711970198, "support": 249421}, "weighted avg": {"precision": 0.7176669418520594, "recall": 0.7373837808364171, "f1-score": 0.7089789345388181, "support": 249421}}','[[28581, 1274, 1715, 294, 3071], [6754, 3941, 2950, 568, 2253], [3280, 1157, 10162, 2553, 5461], [1157, 261, 2879, 14065, 23235], [1522, 147, 1194, 3777, 127170]]','Headline - 1 Layer 16 LSTM Units, No Dropout, GloVe Embedding (with stop words, nonlemmatized), Balanced Weights',300.0,16.0,0.63,'{"1": {"precision": 0.6921344505255, "recall": 0.8181193645341348, "f1-score": 0.7498720959214996, "support": 34935}, "2": {"precision": 0.5812684365781711, "recall": 0.23934167375197377, "f1-score": 0.33906908715477935, "support": 16466}, "3": {"precision": 0.5376719576719576, "recall": 0.44938752045283686, "f1-score": 0.48958157685544285, "support": 22613}, "4": {"precision": 0.6616643929058663, "recall": 0.3381253455778061, "f1-score": 0.44754510452795365, "support": 41597}, "5": {"precision": 0.7889447236180904, "recall": 0.950377400792168, "f1-score": 0.8621694915254237, "support": 133810}, "accuracy": 0.7373837808364171, "macro avg": {"precision": 0.652336792259917, "recall": 0.5590702610217839, "f1-score": 0.5776474711970198, "support": 249421}, "weighted avg": {"precision": 0.7176669418520594, "recall": 0.7373837808364171, "f1-score": 0.7089789345388181, "support": 249421}}',glove_with_stop_nonlemmatized,drive/My Drive/Springboard/capstone/data/amazon_reviews_us_Wireless_v1_00-1m-with_stop_nonlemmatized-preprocessed.csv,'{"1": {"precision": 0.6921344505255, "recall": 0.8181193645341348, "f1-score": 0.7498720959214996, "support": 34935}, "2": {"precision": 0.5812684365781711, "recall": 0.23934167375197377, "f1-score": 0.33906908715477935, "support": 16466}, "3": {"precision": 0.5376719576719576, "recall": 0.44938752045283686, "f1-score": 0.48958157685544285, "support": 22613}, "4": {"precision": 0.6616643929058663, "recall": 0.3381253455778061, "f1-score": 0.44754510452795365, "support": 41597}, "5": {"precision": 0.7889447236180904, "recall": 0.950377400792168, "f1-score": 0.8621694915254237, "support": 133810}, "accuracy": 0.7373837808364171, "macro avg": {"precision": 0.652336792259917, "recall": 0.5590702610217839, "f1-score": 0.5776474711970198, "support": 249421}, "weighted avg": {"precision": 0.7176669418520594, "recall": 0.7373837808364171, "f1-score": 0.7089789345388181, "support": 249421}}',0.6755749676672832,30.0,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-997681-30-review_headline-model.h5,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-997681-30-review_headline-model.json,LSTMB16,drive/My Drive/Springboard/capstone/reports/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-997681-30-review_headline-history.pkl,0.44,'{"auc_1": 0.9640687513087846, "auc_2": 0.9096008689138704, "auc_3": 0.892720303897655, "auc_4": 0.8388365641061918, "auc_5": 0.9260828185822083, "auc_micro": 0.9418788943036559, "auc_macro": 0.9062629168337379}',none,success,2020-02-27 21:12:01,249421.0,30.0,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-997681-30-review_headline-tokenizer.pkl,748260.0,30.0,11.62,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-997681-30-review_headline-weights.h5
0.7388557195663452,1x16,128.0,'[1.4226719441741957, 3.012881619833158, 2.201438764251563, 1.1945716817408936, 0.3739966709820603]','{"1": {"precision": 0.6929478198106398, "recall": 0.8254289362885789, "f1-score": 0.7534087696116051, "support": 79091}, "2": {"precision": 0.5614067966016991, "recall": 0.24226331679965496, "f1-score": 0.33846791202169324, "support": 37096}, "3": {"precision": 0.5436058798666228, "recall": 0.45312194167156, "f1-score": 0.4942568000341603, "support": 51090}, "4": {"precision": 0.6799102428722281, "recall": 0.3289272030651341, "f1-score": 0.44336374591151656, "support": 93960}, "5": {"precision": 0.7888971862694579, "recall": 0.9545418172603727, "f1-score": 0.8638505302320529, "support": 299924}, "accuracy": 0.73885569382049, "macro avg": {"precision": 0.6533535850841296, "recall": 0.5608566430170601, "f1-score": 0.5786695515622057, "support": 561161}, "weighted avg": {"precision": 0.7197547104319814, "recall": 0.73885569382049, "f1-score": 0.7094990610014199, "support": 561161}}','[[65284, 3174, 3376, 510, 6747], [15638, 8987, 6515, 1000, 4956], [7653, 2815, 23150, 5438, 12034], [2470, 678, 7034, 30906, 52872], [3167, 354, 2511, 7602, 286290]]','Headline - 1 Layer 16 LSTM Units, No Dropout, GloVe Embedding (with stop words, nonlemmatized), Balanced Weights',300.0,21.0,1.34,'{"1": {"precision": 0.6929478198106398, "recall": 0.8254289362885789, "f1-score": 0.7534087696116051, "support": 79091}, "2": {"precision": 0.5614067966016991, "recall": 0.24226331679965496, "f1-score": 0.33846791202169324, "support": 37096}, "3": {"precision": 0.5436058798666228, "recall": 0.45312194167156, "f1-score": 0.4942568000341603, "support": 51090}, "4": {"precision": 0.6799102428722281, "recall": 0.3289272030651341, "f1-score": 0.44336374591151656, "support": 93960}, "5": {"precision": 0.7888971862694579, "recall": 0.9545418172603727, "f1-score": 0.8638505302320529, "support": 299924}, "accuracy": 0.73885569382049, "macro avg": {"precision": 0.6533535850841296, "recall": 0.5608566430170601, "f1-score": 0.5786695515622057, "support": 561161}, "weighted avg": {"precision": 0.7197547104319814, "recall": 0.73885569382049, "f1-score": 0.7094990610014199, "support": 561161}}',glove_with_stop_nonlemmatized,drive/My Drive/Springboard/capstone/data/amazon_reviews_us_Wireless_v1_00-2m-with_stop_nonlemmatized-preprocessed.csv,'{"1": {"precision": 0.6929478198106398, "recall": 0.8254289362885789, "f1-score": 0.7534087696116051, "support": 79091}, "2": {"precision": 0.5614067966016991, "recall": 0.24226331679965496, "f1-score": 0.33846791202169324, "support": 37096}, "3": {"precision": 0.5436058798666228, "recall": 0.45312194167156, "f1-score": 0.4942568000341603, "support": 51090}, "4": {"precision": 0.6799102428722281, "recall": 0.3289272030651341, "f1-score": 0.44336374591151656, "support": 93960}, "5": {"precision": 0.7888971862694579, "recall": 0.9545418172603727, "f1-score": 0.8638505302320529, "support": 299924}, "accuracy": 0.73885569382049, "macro avg": {"precision": 0.6533535850841296, "recall": 0.5608566430170601, "f1-score": 0.5786695515622057, "support": 561161}, "weighted avg": {"precision": 0.7197547104319814, "recall": 0.73885569382049, "f1-score": 0.7094990610014199, "support": 561161}}',0.6659185563838125,30.0,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-2244642-30-review_headline-model.h5,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-2244642-30-review_headline-model.json,LSTMB16,drive/My Drive/Springboard/capstone/reports/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-2244642-30-review_headline-history.pkl,0.95,'{"auc_1": 0.9660996580344435, "auc_2": 0.9116996970117648, "auc_3": 0.8965611403975657, "auc_4": 0.8426649528162176, "auc_5": 0.9284438719729017, "auc_micro": 0.9434738370436625, "auc_macro": 0.9090943136352811}',none,success,2020-02-28 01:38:17,561161.0,30.0,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-2244642-30-review_headline-tokenizer.pkl,1683481.0,30.0,33.63,drive/My Drive/Springboard/capstone/models/LSTMB16-1x16-glove_with_stop_nonlemmatized-sampling_none-2244642-30-review_headline-weights.h5
