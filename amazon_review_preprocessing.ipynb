{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook outlines pre-processing of Amazong Reviews\n",
    "\n",
    "Most of the work is done in clases that I wrote, but I'll outline what I did for pre-processing in this notebook. Running pre-processing in the notebook took a lot longer so running it via command line seems to be quicker so I can iterate\n",
    "\n",
    "Add code is checked into my github repo: https://github.com/sv650s/sb-capstone\n",
    "\n",
    "\n",
    "* preprocess_amazon.py - python program that calls TextProcessor with parameters set to handle the amazon review file\n",
    "* TextProcessor.py - processor class that uses various utilities to pre-process the file\n",
    "* text_util.py - has a bunch of text processing methods to clean the data\n",
    "* file_util.py - functiont to handle files (ie, covert tsv to csv)\n",
    "* df_util.py - utility to handle pandas DataFrames\n",
    "\n",
    "\n",
    "Unit Tests:\n",
    "* TestTextUtil.py - tests text_util.py\n",
    "\n",
    "To Be Implemented:\n",
    "* unit tests for file_util.py\n",
    "* unit tests for pd_util.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we pre-process, I had to convert tsv to CSV because Pandas was not reading the columns correctly and was putting multiple rows into a column resulting in headline columns that had over 30k words\n",
    "\n",
    "Original Amazon file had 9mil reviews. I added sampling parameter to reduce the size of the file. Currently, the sampling is pretty dumb. It just grabs every nth line in the file and put it in the final csv file. Will probably rewrite this so it's based on random.rand later\n",
    "\n",
    "I already ran this via command line because it was faster. So the commented out lines are how we would generate the other sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_util import convert_tsv_to_csv\n",
    "\n",
    "\n",
    "# full 9mil Wireless reviews - not enough memory locally to do this\n",
    "ORIG_FILE_WIRELESS=\"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00.tsv\"\n",
    "\n",
    "# about 22k reviews\n",
    "DATA_FILE_TEST = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-test.csv\"\n",
    "# about 100023 reviews\n",
    "DATA_FILE_TINY = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-tiny.csv\"\n",
    "# about 300068 reviews\n",
    "DATA_FILE_SMALL = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-small.csv\"\n",
    "# about 450101 reviews\n",
    "DATA_FILE_MEDIUM = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-medium.csv\"\n",
    "# about 900203 reviews\n",
    "DATA_FILE_LARGE = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-large.csv\"\n",
    "\n",
    "# already ran this\n",
    "convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_TEST, 400)\n",
    "# convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_TINY, 90)\n",
    "# convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_SMALL, 25)\n",
    "# convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_MEDIUM, 20)\n",
    "# convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_LARGE, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample run and output of preprocess_amazon.py\n",
    "\n",
    "I'm using a file that has only 25k entires so I can run it in the notebook quickly\n",
    "\n",
    "Notice final output is 19889 because after steming and removing stop words some of the review headlines are now blank\n",
    "\n",
    "Pre-processing entails the following (in order):\n",
    "* make everything lowercase\n",
    "* remove newlines\n",
    "* remove amazon tags - amazon embeds these [[VIDDEO:dsfljlsjf]] and [[ASIN:sdfjlsjdfl]] tags that need to be removed\n",
    "* remove html tags - line breaks, etc are represented in reviews as HTML tags\n",
    "* remove accent characters\n",
    "* expand contractions - THIS IS NOT YET IMPLEMENTED but needs to be done before special charaters because we want to expand don't into do not for our text processing\n",
    "* remove special characters - anything that is not alphanumeric or spaces\n",
    "* stem or lemmatize words - ONLY Porter stemming is implemented currently\n",
    "* remove stop words - see text_util.py for stop words that I removed from nltk stop words because I think they will be important for sentiment analysis\n",
    "\n",
    "Columns that it drops right off the bat: marketplace, vine, verified_purchase\n",
    "Columns that it is pre-processing: product_title, review_headline, review_body\n",
    "\n",
    "Also, for convenience, there is a flag to retain the original column so we can see the orignal text next to the pre-processed text so we can look for errors. Will not be using this flag for final data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-01 23:51:47,402 INFO    __main__.main [41] - loading data frame from dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testin.csv\n",
      "2019-05-01 23:51:47,573 INFO    __main__.main [43] - finished loading dataframe dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testin.csv\n",
      "2019-05-01 23:51:47,573 INFO    __main__.main [44] - original dataframe length: 22505\n",
      "2019-05-01 23:51:47,573 INFO    TextPreprocessor.preprocess_data [119] - start preprocessing data\n",
      "2019-05-01 23:51:47,573 INFO    TextPreprocessor.preprocess_data [121] - column count before dropping columns: 15\n",
      "2019-05-01 23:51:47,577 INFO    TextPreprocessor.preprocess_data [124] - column count after dropping columnes: 12\n",
      "2019-05-01 23:51:47,577 INFO    TextPreprocessor.preprocess_data [127] - original row count: 22505\n",
      "2019-05-01 23:51:47,591 INFO    TextPreprocessor.preprocess_data [129] - row count after dropping na: 22505\n",
      "2019-05-01 23:51:47,591 INFO    TextPreprocessor.preprocess_data [131] - column count before duplicating columns: 12\n",
      "2019-05-01 23:51:47,603 INFO    TextPreprocessor.preprocess_data [134] - column count after duplicating columns: 15\n",
      "/Users/vinceluk/anaconda3/envs/capstone/lib/python3.7/site-packages/bs4/__init__.py:272: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "2019-05-01 23:51:59,752 INFO    TextPreprocessor.normalize_text [76] - normalizing row: 5000\n",
      "2019-05-01 23:52:11,782 INFO    TextPreprocessor.normalize_text [76] - normalizing row: 10000\n",
      "2019-05-01 23:52:25,638 INFO    TextPreprocessor.normalize_text [76] - normalizing row: 15000\n",
      "2019-05-01 23:52:40,882 INFO    TextPreprocessor.normalize_text [76] - normalizing row: 20000\n",
      "2019-05-01 23:52:52,441 INFO    TextPreprocessor.preprocess_data [144] - row count before dropping empty values: 22505\n",
      "2019-05-01 23:52:52,469 INFO    TextPreprocessor.preprocess_data [146] - row count after dropping empty values: 22409\n",
      "2019-05-01 23:52:52,470 INFO    TextPreprocessor.preprocess_data [148] - finished preprocessing data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22409 entries, 0 to 22504\n",
      "Data columns (total 15 columns):\n",
      "customer_id             22409 non-null int64\n",
      "review_id               22409 non-null object\n",
      "product_id              22409 non-null object\n",
      "product_parent          22409 non-null int64\n",
      "product_title_orig      22409 non-null object\n",
      "product_title           22409 non-null object\n",
      "product_category        22409 non-null object\n",
      "star_rating             22409 non-null int64\n",
      "helpful_votes           22409 non-null int64\n",
      "total_votes             22409 non-null int64\n",
      "review_headline_orig    22409 non-null object\n",
      "review_headline         22409 non-null object\n",
      "review_body_orig        22409 non-null object\n",
      "review_body             22409 non-null object\n",
      "review_date             22409 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(9)\n",
      "memory usage: 2.7+ MB\n",
      "2019-05-01 23:52:52,490 INFO    TextPreprocessor.preprocess_data [149] - None\n",
      "2019-05-01 23:52:52,490 INFO    TextPreprocessor.preprocess_data [150] -    customer_id  ... review_date\n",
      "0     10866798  ...  2015-08-31\n",
      "1     12546647  ...  2015-08-31\n",
      "2     36673667  ...  2015-08-31\n",
      "3     22511501  ...  2015-08-31\n",
      "4     21152188  ...  2015-08-31\n",
      "\n",
      "[5 rows x 15 columns]\n",
      "2019-05-01 23:52:52,511 INFO    __main__.main [52] - new dataframe length: 22409\n",
      "2019-05-01 23:52:52,511 INFO    __main__.main [54] - writing dataframe to dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testout.csv\n"
     ]
    }
   ],
   "source": [
    "!python preprocess_amazon.py -l INFO -r \\\n",
    "    -o dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testout.csv \\\n",
    "    dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testin.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PREPROCESSED_CSV = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testout.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the output file back in to look at some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22409 entries, 0 to 22408\n",
      "Data columns (total 15 columns):\n",
      "customer_id             22409 non-null int64\n",
      "review_id               22409 non-null object\n",
      "product_id              22409 non-null object\n",
      "product_parent          22409 non-null int64\n",
      "product_title_orig      22409 non-null object\n",
      "product_title           22409 non-null object\n",
      "product_category        22409 non-null object\n",
      "star_rating             22409 non-null int64\n",
      "helpful_votes           22409 non-null int64\n",
      "total_votes             22409 non-null int64\n",
      "review_headline_orig    22409 non-null object\n",
      "review_headline         22409 non-null object\n",
      "review_body_orig        22409 non-null object\n",
      "review_body             22409 non-null object\n",
      "review_date             22409 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(9)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "review_df = pd.read_csv(PREPROCESSED_CSV, parse_dates=[\"review_date\"])\n",
    "review_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's sample the dataframe so we can look at some of the data\n",
    "sample_df = review_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_title_orig\t[HTC Desire 816 Black (Virgin mobile) - 5.5 inch S-LCD Display]\n",
      "product_title\t\t[htc desir 816 black virgin mobil 5 5 inch lcd display]\n",
      "product_title_orig\t[Samsung Galaxy Ace 4 G313M Unlocked GSM HSPA+ Android Smartphone]\n",
      "product_title\t\t[samsung galaxi ace 4 g313m unlock gsm hspa android smartphon]\n",
      "product_title_orig\t[Mini Adjustable Tripod+camera Holder for Iphone and Other Cellphone]\n",
      "product_title\t\t[mini adjust tripod camera holder iphon cellphon]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rows = len(sample_df)\n",
    "# first let's randomly look at a couple rows\n",
    "for i in np.arange(0,3,1):\n",
    "    row_index = round(np.random.rand() * rows)\n",
    "    row = sample_df.iloc[row_index]\n",
    "    print(f'product_title_orig\\t[{row[\"product_title_orig\"]}]')\n",
    "    print(f'product_title\\t\\t[{row[\"product_title\"]}]')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I did notice that in product titles - things like 5.5 get converted to 5 5 - will have to do something about this if we decide to use product title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_headline_orig\t[Not at all useful.]\n",
      "review_headline\t\t[not use]\n",
      "review_headline_orig\t[Everyone fits]\n",
      "review_headline\t\t[everyon fit]\n",
      "review_headline_orig\t[The case does not work because the smart chip has been removed]\n",
      "review_headline\t\t[case doe not work becau smart chip ha remov]\n",
      "review_headline_orig\t[No more annoying AUX cable in my car.]\n",
      "review_headline\t\t[no annoy aux cabl car]\n",
      "review_headline_orig\t[Bulky but protective]\n",
      "review_headline\t\t[bulki protect]\n"
     ]
    }
   ],
   "source": [
    "# let's now look at review_headline\n",
    "# first let's randomly look at a couple rows\n",
    "for i in np.arange(0,5,1):\n",
    "    row_index = round(np.random.rand() * rows)\n",
    "    row = sample_df.iloc[row_index]\n",
    "    print(f'review_headline_orig\\t[{row[\"review_headline_orig\"]}]')\n",
    "    print(f'review_headline\\t\\t[{row[\"review_headline\"]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_body_orig\t[This product eliminates the need for an AUX cable , and because it converts your radio into a blue tooth<br />receiver you get better sound as well. The charging is accurate and lasts about 6 hours. In about 30<br />minutes its fully charged again. Syncs easily to my phone and is more affordable than several other<br />models.]\n",
      "review_body\t\t[thi product elimin need aux cabl becau convert radio blue toothreceiv get better sound well charg accur last 6 hour 30minut fulli charg sync easili phone afford sever othermodel]\n",
      "review_body_orig\t[Does not have front-facing VGA camera as it says in the product specs.]\n",
      "review_body\t\t[doe not front face vga camera say product spec]\n",
      "review_body_orig\t[Great gift new baby everyone in picture now.]\n",
      "review_body\t\t[great gift new babi everyon pictur]\n",
      "review_body_orig\t[It was exactly what was advertised. Looks good. Holds good. For the price, you can't complain. I would recommend this to anyone.]\n",
      "review_body\t\t[wa exactli wa adverti look good hold good price complain would recommend thi anyon]\n",
      "review_body_orig\t[you have to bend the case in half almost in order to get the credit card slot open. Not at all useful.]\n",
      "review_body\t\t[bend case half almost order get credit card slot open not use]\n"
     ]
    }
   ],
   "source": [
    "# let's now look at review_body\n",
    "# first let's randomly look at a couple rows\n",
    "for i in np.arange(0,5,1):\n",
    "    row_index = round(np.random.rand() * rows)\n",
    "    row = sample_df.iloc[row_index]\n",
    "    print(f'review_body_orig\\t[{row[\"review_body_orig\"]}]')\n",
    "    print(f'review_body\\t\\t[{row[\"review_body\"]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
