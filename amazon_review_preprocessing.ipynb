{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook outlines pre-processing of Amazong Reviews\n",
    "\n",
    "Most of the work is done in clases that I wrote, but I'll outline what I did for pre-processing in this notebook. Running pre-processing in the notebook took a lot longer so running it via command line seems to be quicker so I can iterate\n",
    "\n",
    "Add code is checked into my github repo: https://github.com/sv650s/sb-capstone\n",
    "\n",
    "\n",
    "* preprocess_amazon.py - python program that calls TextProcessor with parameters set to handle the amazon review file\n",
    "* TextProcessor.py - processor class that uses various utilities to pre-process the file\n",
    "* text_util.py - has a bunch of text processing methods to clean the data\n",
    "* file_util.py - functiont to handle files (ie, covert tsv to csv)\n",
    "* df_util.py - utility to handle pandas DataFrames\n",
    "\n",
    "\n",
    "Unit Tests:\n",
    "* TestTextUtil.py - tests text_util.py\n",
    "\n",
    "To Be Implemented:\n",
    "* unit tests for file_util.py\n",
    "* unit tests for pd_util.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we pre-process, I had to convert tsv to CSV because Pandas was not reading the columns correctly and was putting multiple rows into a column resulting in headline columns that had over 30k words\n",
    "\n",
    "Original Amazon file had 9mil reviews. I added sampling parameter to reduce the size of the file. Currently, the sampling is pretty dumb. It just grabs every nth line in the file and put it in the final csv file. Will probably rewrite this so it's based on random.rand later\n",
    "\n",
    "I already ran this via command line because it was faster. So the commented out lines are how we would generate the other sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from file_util import convert_tsv_to_csv\n",
    "\n",
    "\n",
    "# full 9mil Wireless reviews - not enough memory locally to do this\n",
    "ORIG_FILE_WIRELESS=\"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00.tsv\"\n",
    "\n",
    "# about 22k reviews\n",
    "DATA_FILE_TEST = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-test.csv\"\n",
    "# about 100023 reviews\n",
    "DATA_FILE_TINY = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-tiny.csv\"\n",
    "# about 300068 reviews\n",
    "DATA_FILE_SMALL = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-small.csv\"\n",
    "# about 450101 reviews\n",
    "DATA_FILE_MEDIUM = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-medium.csv\"\n",
    "# about 900203 reviews\n",
    "DATA_FILE_LARGE = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-large.csv\"\n",
    "\n",
    "# already ran this\n",
    "convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_TEST, 400)\n",
    "# convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_TINY, 90)\n",
    "# convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_SMALL, 25)\n",
    "# convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_MEDIUM, 20)\n",
    "# convert_tsv_to_csv(ORIG_FILE_WIRELESS, DATA_FILE_LARGE, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample run and output of preprocess_amazon.py\n",
    "\n",
    "I'm using a file that has only 25k entires so I can run it in the notebook quickly\n",
    "\n",
    "Notice final output is 19889 because after steming and removing stop words some of the review headlines are now blank\n",
    "\n",
    "Pre-processing entails the following (in order):\n",
    "* make everything lowercase\n",
    "* remove newlines\n",
    "* remove amazon tags - amazon embeds these [[VIDDEO:dsfljlsjf]] and [[ASIN:sdfjlsjdfl]] tags that need to be removed\n",
    "* remove html tags - line breaks, etc are represented in reviews as HTML tags\n",
    "* remove accent characters\n",
    "* expand contractions - THIS IS NOT YET IMPLEMENTED but needs to be done before special charaters because we want to expand don't into do not for our text processing\n",
    "* remove special characters - anything that is not alphanumeric or spaces\n",
    "* stem or lemmatize words - ONLY Porter stemming is implemented currently\n",
    "* remove stop words - see text_util.py for stop words that I removed from nltk stop words because I think they will be important for sentiment analysis\n",
    "\n",
    "Columns that it drops right off the bat: marketplace, vine, verified_purchase\n",
    "Columns that it is pre-processing: product_title, review_headline, review_body\n",
    "\n",
    "Also, for convenience, there is a flag to retain the original column so we can see the orignal text next to the pre-processed text so we can look for errors. Will not be using this flag for final data files\n",
    "\n",
    "\n",
    "Here is the list of default stop words from nltk:\n",
    "\n",
    "\n",
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-02 00:28:39,725 INFO    __main__.main [41] - loading data frame from dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testin.csv\n",
      "2019-05-02 00:28:39,894 INFO    __main__.main [43] - finished loading dataframe dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testin.csv\n",
      "2019-05-02 00:28:39,894 INFO    __main__.main [44] - original dataframe length: 22505\n",
      "2019-05-02 00:28:39,894 INFO    TextPreprocessor.preprocess_data [119] - start preprocessing data\n",
      "2019-05-02 00:28:39,894 INFO    TextPreprocessor.preprocess_data [121] - column count before dropping columns: 15\n",
      "2019-05-02 00:28:39,897 INFO    TextPreprocessor.preprocess_data [124] - column count after dropping columnes: 12\n",
      "2019-05-02 00:28:39,897 INFO    TextPreprocessor.preprocess_data [127] - original row count: 22505\n",
      "2019-05-02 00:28:39,910 INFO    TextPreprocessor.preprocess_data [129] - row count after dropping na: 22505\n",
      "2019-05-02 00:28:39,911 INFO    TextPreprocessor.preprocess_data [131] - column count before duplicating columns: 12\n",
      "2019-05-02 00:28:39,921 INFO    TextPreprocessor.preprocess_data [134] - column count after duplicating columns: 15\n",
      "/Users/vinceluk/anaconda3/envs/capstone/lib/python3.7/site-packages/bs4/__init__.py:272: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "2019-05-02 00:28:52,274 INFO    TextPreprocessor.normalize_text [76] - normalizing row: 5000\n",
      "2019-05-02 00:29:03,585 INFO    TextPreprocessor.normalize_text [76] - normalizing row: 10000\n",
      "2019-05-02 00:29:16,583 INFO    TextPreprocessor.normalize_text [76] - normalizing row: 15000\n",
      "2019-05-02 00:29:32,169 INFO    TextPreprocessor.normalize_text [76] - normalizing row: 20000\n",
      "2019-05-02 00:29:42,741 INFO    TextPreprocessor.preprocess_data [144] - row count before dropping empty values: 22505\n",
      "2019-05-02 00:29:42,768 INFO    TextPreprocessor.preprocess_data [146] - row count after dropping empty values: 22409\n",
      "2019-05-02 00:29:42,768 INFO    TextPreprocessor.preprocess_data [148] - finished preprocessing data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22409 entries, 0 to 22504\n",
      "Data columns (total 15 columns):\n",
      "customer_id             22409 non-null int64\n",
      "review_id               22409 non-null object\n",
      "product_id              22409 non-null object\n",
      "product_parent          22409 non-null int64\n",
      "product_title_orig      22409 non-null object\n",
      "product_title           22409 non-null object\n",
      "product_category        22409 non-null object\n",
      "star_rating             22409 non-null int64\n",
      "helpful_votes           22409 non-null int64\n",
      "total_votes             22409 non-null int64\n",
      "review_headline_orig    22409 non-null object\n",
      "review_headline         22409 non-null object\n",
      "review_body_orig        22409 non-null object\n",
      "review_body             22409 non-null object\n",
      "review_date             22409 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(9)\n",
      "memory usage: 2.7+ MB\n",
      "2019-05-02 00:29:42,788 INFO    TextPreprocessor.preprocess_data [149] - None\n",
      "2019-05-02 00:29:42,788 INFO    TextPreprocessor.preprocess_data [150] -    customer_id  ... review_date\n",
      "0     10866798  ...  2015-08-31\n",
      "1     12546647  ...  2015-08-31\n",
      "2     36673667  ...  2015-08-31\n",
      "3     22511501  ...  2015-08-31\n",
      "4     21152188  ...  2015-08-31\n",
      "\n",
      "[5 rows x 15 columns]\n",
      "2019-05-02 00:29:42,808 INFO    __main__.main [52] - new dataframe length: 22409\n",
      "2019-05-02 00:29:42,808 INFO    __main__.main [54] - writing dataframe to dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testout.csv\n"
     ]
    }
   ],
   "source": [
    "!python preprocess_amazon.py -l INFO -r \\\n",
    "    -o dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testout.csv \\\n",
    "    dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testin.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PREPROCESSED_CSV = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-testout.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the output file back in to look at some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22409 entries, 0 to 22408\n",
      "Data columns (total 15 columns):\n",
      "customer_id             22409 non-null int64\n",
      "review_id               22409 non-null object\n",
      "product_id              22409 non-null object\n",
      "product_parent          22409 non-null int64\n",
      "product_title_orig      22409 non-null object\n",
      "product_title           22409 non-null object\n",
      "product_category        22409 non-null object\n",
      "star_rating             22409 non-null int64\n",
      "helpful_votes           22409 non-null int64\n",
      "total_votes             22409 non-null int64\n",
      "review_headline_orig    22409 non-null object\n",
      "review_headline         22409 non-null object\n",
      "review_body_orig        22409 non-null object\n",
      "review_body             22409 non-null object\n",
      "review_date             22409 non-null datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(5), object(9)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "review_df = pd.read_csv(PREPROCESSED_CSV, parse_dates=[\"review_date\"])\n",
    "review_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's sample the dataframe so we can look at some of the data\n",
    "sample_df = review_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title_orig_len</th>\n",
       "      <th>product_title_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22409.000000</td>\n",
       "      <td>22409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>104.411933</td>\n",
       "      <td>88.198313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.650591</td>\n",
       "      <td>51.114203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>77.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>136.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_title_orig_len  product_title_len\n",
       "count            22409.000000       22409.000000\n",
       "mean               104.411933          88.198313\n",
       "std                 61.650591          51.114203\n",
       "min                  3.000000           2.000000\n",
       "25%                 60.000000          51.000000\n",
       "50%                 90.000000          77.000000\n",
       "75%                136.000000         114.000000\n",
       "max                400.000000         393.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = review_df\n",
    "df[\"product_title_orig_len\"] = df[\"product_title_orig\"].apply(lambda x: len(x))\n",
    "df[\"product_title_len\"] = df[\"product_title\"].apply(lambda x: len(x))\n",
    "\n",
    "df[\"product_title_diff\"] = df[\"product_title_len\"] - df[\"product_title_orig_len\"]\n",
    "df[\"product_title_percent_diff\"] = df[\"product_title_diff\"] / df[\"product_title_orig_len\"]\n",
    "\n",
    "\n",
    "\n",
    "df[[\"product_title_orig_len\", \"product_title_len\", \"product_title_diff\", ]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_title_orig\t[Nokia Lumia 822 GSM  Verizon CDMA 4G LTE Windows Smartphone -Black]\n",
      "product_title\t\t[nokia lumia 822 gsm verizon cdma 4g lte window smartphon black]\n",
      "product_title_orig\t[TRENDE - Apple iPhone 5C Case Patchwork Owl Rhinestone (Bling) Design Snap-on Hard Cover + Free Gift Box (Compatible Models: ONLY for iPhone 5C - NOT 5 or 5S!)]\n",
      "product_title\t\t[trend appl iphon 5c case patchwork owl rhineston bling design snap hard cover free gift box compat model onli iphon 5c not 5 5s]\n",
      "product_title_orig\t[Designer Hard case for at&T iphone 4 bulk package--please see additonal comment of listing]\n",
      "product_title\t\t[design hard case iphon 4 bulk packag plea see additon comment list]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "rows = len(sample_df)\n",
    "# first let's randomly look at a couple rows\n",
    "for i in np.arange(0,3,1):\n",
    "    row_index = round(np.random.rand() * rows)\n",
    "    row = sample_df.iloc[row_index]\n",
    "    print(f'product_title_orig\\t[{row[\"product_title_orig\"]}]')\n",
    "    print(f'product_title\\t\\t[{row[\"product_title\"]}]')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I did notice that in product titles - things like 5.5 get converted to 5 5 - will have to do something about this if we decide to use product title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## review headlines\n",
    "\n",
    "average 22% reduction in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline_orig_len</th>\n",
       "      <th>review_headline_len</th>\n",
       "      <th>review_headline_diff</th>\n",
       "      <th>review_headline_percent_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22409.000000</td>\n",
       "      <td>22409.000000</td>\n",
       "      <td>22409.000000</td>\n",
       "      <td>22409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.042438</td>\n",
       "      <td>15.547726</td>\n",
       "      <td>-6.494712</td>\n",
       "      <td>-0.227335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.062178</td>\n",
       "      <td>11.171589</td>\n",
       "      <td>8.646664</td>\n",
       "      <td>0.188070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.000000</td>\n",
       "      <td>-0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-0.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-0.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>128.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_headline_orig_len  review_headline_len  review_headline_diff  \\\n",
       "count              22409.000000         22409.000000          22409.000000   \n",
       "mean                  22.042438            15.547726             -6.494712   \n",
       "std                   18.062178            11.171589              8.646664   \n",
       "min                    1.000000             1.000000            -73.000000   \n",
       "25%                   10.000000             9.000000             -9.000000   \n",
       "50%                   15.000000            11.000000             -3.000000   \n",
       "75%                   28.000000            20.000000             -1.000000   \n",
       "max                  128.000000           121.000000              0.000000   \n",
       "\n",
       "       review_headline_percent_diff  \n",
       "count                  22409.000000  \n",
       "mean                      -0.227335  \n",
       "std                        0.188070  \n",
       "min                       -0.896552  \n",
       "25%                       -0.366667  \n",
       "50%                       -0.175000  \n",
       "75%                       -0.100000  \n",
       "max                        0.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = review_df\n",
    "df[\"review_headline_orig_len\"] = df[\"review_headline_orig\"].apply(lambda x: len(x))\n",
    "df[\"review_headline_len\"] = df[\"review_headline\"].apply(lambda x: len(x))\n",
    "\n",
    "df[\"review_headline_diff\"] = df[\"review_headline_len\"] - df[\"review_headline_orig_len\"]\n",
    "df[\"review_headline_percent_diff\"] = df[\"review_headline_diff\"] / df[\"review_headline_orig_len\"]\n",
    "\n",
    "df[[\"review_headline_orig_len\", \"review_headline_len\", \"review_headline_diff\", \"review_headline_percent_diff\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_headline_orig\t[Love it]\n",
      "review_headline\t\t[love]\n",
      "review_headline_orig\t[Not good product]\n",
      "review_headline\t\t[not good product]\n",
      "review_headline_orig\t[Not good product]\n",
      "review_headline\t\t[not good product]\n",
      "review_headline_orig\t[Not good product]\n",
      "review_headline\t\t[not good product]\n",
      "review_headline_orig\t[Good Product - Protects my iPhone]\n",
      "review_headline\t\t[good product protect iphon]\n"
     ]
    }
   ],
   "source": [
    "# let's now look at review_headline\n",
    "# first let's randomly look at a couple rows\n",
    "for i in np.arange(0,5,1):\n",
    "    row_index = round(np.random.rand() * rows)\n",
    "    row = sample_df.iloc[row_index]\n",
    "    print(f'review_headline_orig\\t[{row[\"review_headline_orig\"]}]')\n",
    "    print(f'review_headline\\t\\t[{row[\"review_headline\"]}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## review body - pretty significant reduction in length\n",
    "\n",
    "Average 40% reduction in size of review body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body_orig_len</th>\n",
       "      <th>review_body_len</th>\n",
       "      <th>review_body_diff</th>\n",
       "      <th>review_body_percent_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22409.000000</td>\n",
       "      <td>22409.000000</td>\n",
       "      <td>22409.000000</td>\n",
       "      <td>22409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>256.354099</td>\n",
       "      <td>148.489446</td>\n",
       "      <td>-107.864653</td>\n",
       "      <td>-0.382181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>420.607621</td>\n",
       "      <td>238.309817</td>\n",
       "      <td>183.931886</td>\n",
       "      <td>0.119247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3916.000000</td>\n",
       "      <td>-0.891892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>-118.000000</td>\n",
       "      <td>-0.451477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>141.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>-57.000000</td>\n",
       "      <td>-0.404040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>281.000000</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>-0.339450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9888.000000</td>\n",
       "      <td>6029.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_body_orig_len  review_body_len  review_body_diff  \\\n",
       "count          22409.000000     22409.000000      22409.000000   \n",
       "mean             256.354099       148.489446       -107.864653   \n",
       "std              420.607621       238.309817        183.931886   \n",
       "min                1.000000         1.000000      -3916.000000   \n",
       "25%               70.000000        43.000000       -118.000000   \n",
       "50%              141.000000        85.000000        -57.000000   \n",
       "75%              281.000000       163.000000        -26.000000   \n",
       "max             9888.000000      6029.000000          0.000000   \n",
       "\n",
       "       review_body_percent_diff  \n",
       "count              22409.000000  \n",
       "mean                  -0.382181  \n",
       "std                    0.119247  \n",
       "min                   -0.891892  \n",
       "25%                   -0.451477  \n",
       "50%                   -0.404040  \n",
       "75%                   -0.339450  \n",
       "max                    0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = review_df\n",
    "df[\"review_body_orig_len\"] = df[\"review_body_orig\"].apply(lambda x: len(x))\n",
    "df[\"review_body_len\"] = df[\"review_body\"].apply(lambda x: len(x))\n",
    "df[\"review_body_diff\"] = df[\"review_body_len\"] - df[\"review_body_orig_len\"]\n",
    "df[\"review_body_percent_diff\"] = df[\"review_body_diff\"] / df[\"review_body_orig_len\"]\n",
    "df[[\"review_body_orig_len\", \"review_body_len\", \"review_body_diff\", \"review_body_percent_diff\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_body_orig\t[it very handed he keep his phone case  on his pantloop he alway know were it is.i like that becase it were it belong]\n",
      "review_body\t\t[veri hand keep hi phone case hi pantloop alway know like beca belong]\n",
      "review_body_orig\t[&#34;Plastic&#34; top, side and bottom gold &#34;paint&#34; is rubbing off. This is the third case I have bought, which aren't cheap, and although I like the sleek design I have not been happy with this defect.]\n",
      "review_body\t\t[plastic top side bottom gold paint rub thi third case bought cheap although like sleek design not happi thi defect]\n",
      "review_body_orig\t[All is useful, great value.]\n",
      "review_body\t\t[use great valu]\n",
      "review_body_orig\t[I have now purchased this product for both my iPad and my iPhone and it is a very good product and protects the screen from scratches. The clarity is so good that you can hardly even tell that anything has been applied to the screen. I do highly recommend you read the directions, clean your screen thoroughly, and take your time applying it to your screen to make sure it looks nice. Working the bubbles out are easy. The tricky part can be removing a speck a of dust, but there is a method that works well. To remove any dust under the film, do not pick at the corner of the film with your finger nails or touch the adhesive side, instead use a piece of Scotch tape to lift the corner of the film and use another piece of tape to dab and remove the piece of dust. Then press the film back into place.]\n",
      "review_body\t\t[purcha thi product ipad iphon veri good product protect screen scratch clariti good hardli even tell anyth ha appli screen do highli recommend read direct clean screen thoroughli take time appli screen make sure look nice work bubbl easi tricki part remov speck dust method work well remov ani dust film do not pick corner film finger nail touch adh side instead use piec scotch tape lift corner film use anoth piec tape dab remov piec dust press film back place]\n",
      "review_body_orig\t[it very handed he keep his phone case  on his pantloop he alway know were it is.i like that becase it were it belong]\n",
      "review_body\t\t[veri hand keep hi phone case hi pantloop alway know like beca belong]\n"
     ]
    }
   ],
   "source": [
    "# let's now look at review_body\n",
    "# first let's randomly look at a couple rows\n",
    "for i in np.arange(0,5,1):\n",
    "    row_index = round(np.random.rand() * rows)\n",
    "    row = sample_df.iloc[row_index]\n",
    "    print(f'review_body_orig\\t[{row[\"review_body_orig\"]}]')\n",
    "    print(f'review_body\\t\\t[{row[\"review_body\"]}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
