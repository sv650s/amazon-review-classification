{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019-07-23_CNN_Multi-layer_prototype.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sv650s/sb-capstone/blob/master/2019_07_23_CNN_Multi_layer_prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVO5edBBTj8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7E_UnW8TvEG",
        "colab_type": "text"
      },
      "source": [
        "# CNN Multi-Layer Prototype\n",
        "\n",
        "Based on the [single layer notebook](https://github.com/sv650s/sb-capstone/blob/master/2019-06-23-CNN_prototype.ipynb), we will add a couple convolution layers to see if we get better results\n",
        "\n",
        "Because the previous notebooks were rather large, I put some of the common code for gather metrics and plotting into utility modules that are loaded below\n",
        "\n",
        "Source code for the modules are here:\n",
        "* [dict_util](https://github.com/sv650s/sb-capstone/blob/master/util/dict_util.py)\n",
        "* [plot_util](https://github.com/sv650s/sb-capstone/blob/master/util/plot_util.py)\n",
        "* [keras_util](https://github.com/sv650s/sb-capstone/blob/master/util/keras_util.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfnlBpZnUE91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1f11e207-a16a-449c-c291-43af06dbf851"
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "# add this to sys patch so we can import utility functions\n",
        "sys.path.append('drive/My Drive/Springboard/capstone')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl8kAMc9UHsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ca949f01-73a3-4d83-e7ae-5e0fee528a8d"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "import pandas as pd\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "# custom utilities\n",
        "import util.dict_util as du\n",
        "import util.plot_util as pu\n",
        "import util.keras_util as ku\n",
        "\n",
        "\n",
        "sns.set()\n",
        "\n",
        "DRIVE_DIR = \"drive/My Drive/Springboard/capstone\"\n",
        "DATE_FORMAT = '%Y-%m-%d'\n",
        "TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
        "DATA_FILE = f\"{DRIVE_DIR}/data/amazon_reviews_us_Wireless_v1_00-preprocessed-110k.csv\"\n",
        "FEATURE_COLUMN = \"star_rating\"\n",
        "REVIEW_COLUMN = \"review_body\"\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zs9KidOUbpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data file\n",
        "df = pd.read_csv(f\"{DATA_FILE}\")\n",
        "\n",
        "# extract feature and label columns\n",
        "rating = df[FEATURE_COLUMN]\n",
        "reviews = df[REVIEW_COLUMN]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8CYiOg-Uqns",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Same as previous notebooks but consolidated to one cell to make thing easier to understand\n",
        "\n",
        "Features:\n",
        "* tokenize our review body - this gives us:\n",
        "  * vocab size: 40788 words\n",
        "* then we will pad the sequences to length 186 since this encapsulates 99% of the lenght of our training data\n",
        "\n",
        "Labels:\n",
        "* one hot encode our star rating labels (y)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjxZigkyUqAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "7d5d0a22-7eed-4a31-b6d8-7ac546e161e4"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "# pre-process our lables\n",
        "# one hot encode our star ratings since Keras/TF requires this for the labels\n",
        "y = OneHotEncoder().fit_transform(rating.values.reshape(len(rating), 1)).toarray()\n",
        "\n",
        "\n",
        "# split our data into train and test sets\n",
        "reviews_train, reviews_test, y_train, y_test = train_test_split(reviews, y, random_state=1)\n",
        "\n",
        "\n",
        "# Pre-process our features (review body)\n",
        "t = Tokenizer()\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(reviews_train)\n",
        "# tokenize both our training and test data\n",
        "train_sequences = t.texts_to_sequences(reviews_train)\n",
        "test_sequences = t.texts_to_sequences(reviews_test)\n",
        "\n",
        "print(\"Vocabulary size={}\".format(len(t.word_counts)))\n",
        "print(\"Number of Documents={}\".format(t.document_count))\n",
        "\n",
        "# figure out 99% percentile for our max sequence length\n",
        "df[\"review_length\"] = df.review_body.apply(lambda x: len(x.split()))\n",
        "MAX_SEQUENCE_LENGTH = int(df.review_length.quantile([0.99]).values[0])\n",
        "print(f'Max Sequence Length: {MAX_SEQUENCE_LENGTH}')\n",
        "\n",
        "# pad our reviews to the max sequence length\n",
        "X_train = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_test = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size=40788\n",
            "Number of Documents=84032\n",
            "Max Sequence Length: 186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHVLSF-zWoEO",
        "colab_type": "text"
      },
      "source": [
        "## Build Our 2 Layer Model\n",
        "\n",
        "* we will use embedding size of 300 since this gave us slight improvement from previous notebook for class 1 and 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEYVt_eaWZUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = \"CNN_2layer\"\n",
        "EMBED_SIZE = 300\n",
        "EPOCHS  = 50\n",
        "BATCH_SIZE = 128\n",
        "VOCAB_SIZE = len(t.word_counts)+1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkvU9bWPW1_h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "845f48a5-353f-4f12-b7be-7745698c81d1"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=100, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0724 05:55:15.958377 139643119421312 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0724 05:55:15.978696 139643119421312 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0724 05:55:15.982407 139643119421312 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0724 05:55:16.034923 139643119421312 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0724 05:55:16.074673 139643119421312 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0724 05:55:16.099158 139643119421312 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwPkJTY9XNMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "6a2718a2-2993-4203-dd24-99ea19be362a"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 186, 300)          12236700  \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 186, 100)          90100     \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 186, 100)          30100     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 93, 100)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9300)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               2325250   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 14,683,405\n",
            "Trainable params: 14,683,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoC69aVWXQqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "outputId": "b415a218-acd3-4e42-90cf-297f30a76409"
      },
      "source": [
        "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
        "                 rankdir='TB').create(prog='dot', format='svg'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"626pt\" viewBox=\"0.00 0.00 290.00 626.00\" width=\"290pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 622)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-622 286,-622 286,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139641958408600 -->\n<g class=\"node\" id=\"node1\">\n<title>139641958408600</title>\n<polygon fill=\"none\" points=\"11.5,-498.5 11.5,-544.5 270.5,-544.5 270.5,-498.5 11.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"53.5\" y=\"-517.8\">Embedding</text>\n<polyline fill=\"none\" points=\"95.5,-498.5 95.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"124.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"95.5,-521.5 153.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"124.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"153.5,-498.5 153.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212\" y=\"-529.3\">(None, 186)</text>\n<polyline fill=\"none\" points=\"153.5,-521.5 270.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"212\" y=\"-506.3\">(None, 186, 300)</text>\n</g>\n<!-- 139641958412240 -->\n<g class=\"node\" id=\"node2\">\n<title>139641958412240</title>\n<polygon fill=\"none\" points=\"20,-415.5 20,-461.5 262,-461.5 262,-415.5 20,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"53.5\" y=\"-434.8\">Conv1D</text>\n<polyline fill=\"none\" points=\"87,-415.5 87,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"116\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"87,-438.5 145,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"116\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"145,-415.5 145,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-446.3\">(None, 186, 300)</text>\n<polyline fill=\"none\" points=\"145,-438.5 262,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-423.3\">(None, 186, 100)</text>\n</g>\n<!-- 139641958408600&#45;&gt;139641958412240 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139641958408600-&gt;139641958412240</title>\n<path d=\"M141,-498.3799C141,-490.1745 141,-480.7679 141,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"144.5001,-471.784 141,-461.784 137.5001,-471.784 144.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139641954559536 -->\n<g class=\"node\" id=\"node3\">\n<title>139641954559536</title>\n<polygon fill=\"none\" points=\"20,-332.5 20,-378.5 262,-378.5 262,-332.5 20,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"53.5\" y=\"-351.8\">Conv1D</text>\n<polyline fill=\"none\" points=\"87,-332.5 87,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"116\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"87,-355.5 145,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"116\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"145,-332.5 145,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-363.3\">(None, 186, 100)</text>\n<polyline fill=\"none\" points=\"145,-355.5 262,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"203.5\" y=\"-340.3\">(None, 186, 100)</text>\n</g>\n<!-- 139641958412240&#45;&gt;139641954559536 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139641958412240-&gt;139641954559536</title>\n<path d=\"M141,-415.3799C141,-407.1745 141,-397.7679 141,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"144.5001,-388.784 141,-378.784 137.5001,-388.784 144.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139641954559872 -->\n<g class=\"node\" id=\"node4\">\n<title>139641954559872</title>\n<polygon fill=\"none\" points=\"0,-249.5 0,-295.5 282,-295.5 282,-249.5 0,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"53.5\" y=\"-268.8\">MaxPooling1D</text>\n<polyline fill=\"none\" points=\"107,-249.5 107,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"136\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"107,-272.5 165,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"136\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"165,-249.5 165,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223.5\" y=\"-280.3\">(None, 186, 100)</text>\n<polyline fill=\"none\" points=\"165,-272.5 282,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223.5\" y=\"-257.3\">(None, 93, 100)</text>\n</g>\n<!-- 139641954559536&#45;&gt;139641954559872 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139641954559536-&gt;139641954559872</title>\n<path d=\"M141,-332.3799C141,-324.1745 141,-314.7679 141,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"144.5001,-305.784 141,-295.784 137.5001,-305.784 144.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139641958993480 -->\n<g class=\"node\" id=\"node5\">\n<title>139641958993480</title>\n<polygon fill=\"none\" points=\"29,-166.5 29,-212.5 253,-212.5 253,-166.5 29,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"57\" y=\"-185.8\">Flatten</text>\n<polyline fill=\"none\" points=\"85,-166.5 85,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"85,-189.5 143,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"143,-166.5 143,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-197.3\">(None, 93, 100)</text>\n<polyline fill=\"none\" points=\"143,-189.5 253,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-174.3\">(None, 9300)</text>\n</g>\n<!-- 139641954559872&#45;&gt;139641958993480 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139641954559872-&gt;139641958993480</title>\n<path d=\"M141,-249.3799C141,-241.1745 141,-231.7679 141,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"144.5001,-222.784 141,-212.784 137.5001,-222.784 144.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139641958990456 -->\n<g class=\"node\" id=\"node6\">\n<title>139641958990456</title>\n<polygon fill=\"none\" points=\"38.5,-83.5 38.5,-129.5 243.5,-129.5 243.5,-83.5 38.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"64.5\" y=\"-102.8\">Dense</text>\n<polyline fill=\"none\" points=\"90.5,-83.5 90.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"119.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"90.5,-106.5 148.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"119.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"148.5,-83.5 148.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-114.3\">(None, 9300)</text>\n<polyline fill=\"none\" points=\"148.5,-106.5 243.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-91.3\">(None, 250)</text>\n</g>\n<!-- 139641958993480&#45;&gt;139641958990456 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139641958993480-&gt;139641958990456</title>\n<path d=\"M141,-166.3799C141,-158.1745 141,-148.7679 141,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"144.5001,-139.784 141,-129.784 137.5001,-139.784 144.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139641954569016 -->\n<g class=\"node\" id=\"node7\">\n<title>139641954569016</title>\n<polygon fill=\"none\" points=\"42.5,-.5 42.5,-46.5 239.5,-46.5 239.5,-.5 42.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68.5\" y=\"-19.8\">Dense</text>\n<polyline fill=\"none\" points=\"94.5,-.5 94.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"94.5,-23.5 152.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"123.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"152.5,-.5 152.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-31.3\">(None, 250)</text>\n<polyline fill=\"none\" points=\"152.5,-23.5 239.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-8.3\">(None, 5)</text>\n</g>\n<!-- 139641958990456&#45;&gt;139641954569016 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139641958990456-&gt;139641954569016</title>\n<path d=\"M141,-83.3799C141,-75.1745 141,-65.7679 141,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"144.5001,-56.784 141,-46.784 137.5001,-56.784 144.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139641954560320 -->\n<g class=\"node\" id=\"node8\">\n<title>139641954560320</title>\n<polygon fill=\"none\" points=\"76.5,-581.5 76.5,-617.5 205.5,-617.5 205.5,-581.5 76.5,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-595.8\">139641954560320</text>\n</g>\n<!-- 139641954560320&#45;&gt;139641958408600 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139641954560320-&gt;139641958408600</title>\n<path d=\"M141,-581.4092C141,-573.4308 141,-563.795 141,-554.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"144.5001,-554.5333 141,-544.5333 137.5001,-554.5334 144.5001,-554.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NLuh33SbNJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "6552c598-0b3d-468c-b0d0-c72bce18c563"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "network_history = model.fit(X_train, y_train,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      epochs=EPOCHS,\n",
        "                      verbose=1,\n",
        "                      validation_split=0.2,\n",
        "                      callbacks=[early_stop])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0724 05:55:16.372010 139643119421312 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0724 05:55:16.494192 139643119421312 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 67225 samples, validate on 16807 samples\n",
            "Epoch 1/50\n",
            "67225/67225 [==============================] - 386s 6ms/step - loss: 0.9331 - acc: 0.6428 - val_loss: 0.8556 - val_acc: 0.6706\n",
            "Epoch 2/50\n",
            "67225/67225 [==============================] - 386s 6ms/step - loss: 0.7369 - acc: 0.7108 - val_loss: 0.8466 - val_acc: 0.6728\n",
            "Epoch 3/50\n",
            "67225/67225 [==============================] - 386s 6ms/step - loss: 0.6149 - acc: 0.7613 - val_loss: 0.9180 - val_acc: 0.6708\n",
            "Epoch 4/50\n",
            "67225/67225 [==============================] - 386s 6ms/step - loss: 0.4917 - acc: 0.8106 - val_loss: 1.1412 - val_acc: 0.6349\n",
            "Epoch 00004: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYuGE_mGiEGI",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate our 2 Layer Model\n",
        "\n",
        "* look at accuracy scores\n",
        "* epoch vs loss and accuarcy\n",
        "* confusion matrix\n",
        "* ROC/AUC plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMad2JVtf9t8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "88d2a51c-d0fb-46ec-9750-773e9389f506"
      },
      "source": [
        "# get scores\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28011/28011 [==============================] - 39s 1ms/step\n",
            "Accuracy: 63.66%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq1bOuf0pXJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a4d5afd6-b2a5-42b9-9aa7-ef31ff37f6fe"
      },
      "source": [
        "from importlib import reload\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "# add this to sys patch so we can import utility functions\n",
        "sys.path.append('drive/My Drive/Springboard/capstone')\n",
        "\n",
        "import util.plot_util as pu\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tctd3ZchXMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "038a22e6-b55b-4c11-b2ad-b1a73f83faa6"
      },
      "source": [
        "pu.plot_network_history(network_history)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2a87e0288c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_network_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'util.plot_util' has no attribute 'plot_network_history'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O-Vhg5gcDo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict = model.predict(X_test)\n",
        "y_predict_unencoded = ku.unencode(y_predict)\n",
        "y_test_unencoded = ku.unencode(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqbkWjtagM0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_test_unencoded, y_predict_unencoded)\n",
        "cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHyjwE6fgNYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(y_test_unencoded, y_predict_unencoded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jauOO5sh_di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roc_auc, fpr, tpr = calculate_roc_auc(y_test, y_predict_df)\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "plot_roc_auc(MODEL_NAME, roc_auc, fpr, tpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMW_tcdTiRHC",
        "colab_type": "text"
      },
      "source": [
        "## Save off files for our 2 layer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ya2pSoGwh_px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory, INBASENAME = fu.get_dir_basename(DATA_FILE)\n",
        "DESCRIPTION = f\"{INBASENAME}-nosmote-{MODEL_NAME}-{MAX_SEQUENCE_LENGTH}-{FEATURE_COLUMN}\"\n",
        "MODEL_FILE = f\"{DRIVE_DIR}/models/{datetime.now().strftime(DATE_FORMAT)}-{DESCRIPTION}.h5\"\n",
        "NETWORK_HISTORY_FILE = f'{DRIVE_DIR}/models/{datetime.now().strftime(DATE_FORMAT)}-{DESCRIPTION}-history.pkl'\n",
        "REPORT_FILE = f\"{DRIVE_DIR}/reports/{datetime.now().strftime(DATE_FORMAT)}-DNN_protype-report.csv\"\n",
        "TOKENIZER_FILE = f'{DRIVE_DIR}/models/{datetime.now().strftime(DATE_FORMAT)}-{DESCRIPTION}-tokenizer.pkl'\n",
        "\n",
        "model.save(MODEL_FILE)\n",
        "pickle.dump(network_history, open(NETWORK_HISTORY_FILE, \"wb\"))\n",
        "pickle.dump(t, open(TOKENIZER_FILE, \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKJBfa9ih_s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xJ-thwEimAC",
        "colab_type": "text"
      },
      "source": [
        "## Generate and save our 2 layer report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGwUadPlgNbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate report dictionary\n",
        "report = {}\n",
        "report = du.add_dict_to_dict(report, classification_report(y_test_unencoded, y_predict_unencoded, output_dict=True))\n",
        "report = du.add_dict_to_dict(report, roc_auc)\n",
        "report[\"confusion_matrix\"] = cm\n",
        "report[\"tpr\"] = tpr\n",
        "report[\"fpr\"] = fpr\n",
        "report[\"loss\"] = scores[0]\n",
        "report[\"accuracy\"] = scores[1]\n",
        "report[\"description\"] = DESCRIPTION\n",
        "report[\"file\"] = DATA_FILE\n",
        "report[\"network_history_file\"] = NETWORK_HISTORY_FILE\n",
        "report[\"tokenizer_file\"] = TOKENIZER_FILE\n",
        "report[\"max_sequence_length\"] = MAX_SEQUENCE_LENGTH\n",
        "report[\"embedding\"] = EMBED_SIZE\n",
        "report[\"model_file\"] = MODEL_FILE\n",
        "report[\"model_name\"] = MODEL_NAME\n",
        "report[\"test_examples\"] = X_test.shape[0]\n",
        "report[\"test_features\"] = X_test.shape[1]\n",
        "report[\"train_examples\"] = X_train.shape[0]\n",
        "report[\"train_features\"] = X_train.shape[1]\n",
        "report[\"status\"] = \"success\"\n",
        "report[\"status_date\"] = datetime.now().strftime(TIME_FORMAT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxlcMIPRiwKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check to see if report file exisits, if so load it and append\n",
        "exists = os.path.isfile(REPORT_FILE)\n",
        "if exists:\n",
        "    report_df = pd.read_csv(REPORT_FILE)\n",
        "else:\n",
        "    report_df = pd.DataFrame()\n",
        "    \n",
        "report_df = report_df.append(report, ignore_index=True)\n",
        "report_df.head(20)\n",
        "# save report\n",
        "report_df.to_csv(REPORT_FILE, index=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}