{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "2019-06-23-DNN_384_384-word2vec5-prototype.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sv650s/sb-capstone/blob/master/2019-06-23-DNN_384_384-word2vec5-prototype.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blI1aPOGcoud",
        "colab_type": "text"
      },
      "source": [
        "# DNN Prototype\n",
        "\n",
        "Trying out a 2 layer network using word2vec embedding. Embedding was creating with word_context == 5\n",
        "\n",
        "Network Architecture:\n",
        "\n",
        "Was having trouble coming up with guidelines for architecture starting point but I did find the following article:\n",
        "\n",
        "From this doc:\n",
        "\n",
        "https://www.heatonresearch.com/2017/06/01/hidden-layers.html\n",
        "\n",
        "Number of hidden layers:\n",
        "\n",
        "* none    Only capable of representing linear separable functions or decisions.\n",
        "* 1   Can approximate any function that contains a continuous mapping from one finite space to another.\n",
        "* 2   Can represent an arbitrary decision boundary to arbitrary accuracy with rational activation functions and can approximate any smooth mapping to any accuracy.\n",
        "* 2+  Additional layers can learn complex representations (sort of automatic feature engineering) for layer layers.\n",
        "\n",
        "Number of hidden neurons:\n",
        "\n",
        "* The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
        "* The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
        "* The number of hidden neurons should be less than twice the size of the input layer.\n",
        "\n",
        "\n",
        "From this I chose 2 hidden layers - will be exper\n",
        "\n",
        "Also, I've been looking at Stanford's videos on NLP/Deep Learning\n",
        "\n",
        "* 2 hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxlGtOakcqf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da4f53ac-1fc7-4b2b-e6e1-81b87aaf8735"
      },
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "# add this to sys patch so we can import utility functions\n",
        "DRIVE_DIR = \"drive/My Drive/Springboard/capstone\"\n",
        "sys.path.append('drive/My Drive/Springboard/capstone')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxrODSAacouf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3888649-964a-487f-b72c-e874c63b4f4f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from util import dict_util as du\n",
        "from util import file_util as fu\n",
        "from util import plot_util as pu\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import util.file_util as fu\n",
        "import util.keras_util as ku\n",
        "import util.plot_util as pu\n",
        "import util.dict_util as du\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()\n",
        "\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk9GDviNcouj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATE_FORMAT = '%Y-%m-%d'\n",
        "TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
        "DATA_DIR = \"dataset/feature_files\"\n",
        "DATA_FILE = \"review_body-word2vec5-111909-512-nolda.csv\"\n",
        "MODEL_NAME = \"DNN_384_384_batchnorm\"\n",
        "LABEL_COLUMN = \"star_rating\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": false,
        "id": "MCobR5NUcoul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(f\"{DRIVE_DIR}/data/{DATA_FILE}\")\n",
        "rating = df[LABEL_COLUMN]\n",
        "df = df.drop(columns=[\"helpful_votes\", \"total_votes\", \"helpful_product\", \"star_rating\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_HJr85Tcoun",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "71f0ae26-3b4a-44a7-a7fe-f3cf6217cfeb"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>472</th>\n",
              "      <th>473</th>\n",
              "      <th>474</th>\n",
              "      <th>475</th>\n",
              "      <th>476</th>\n",
              "      <th>477</th>\n",
              "      <th>478</th>\n",
              "      <th>479</th>\n",
              "      <th>480</th>\n",
              "      <th>481</th>\n",
              "      <th>482</th>\n",
              "      <th>483</th>\n",
              "      <th>484</th>\n",
              "      <th>485</th>\n",
              "      <th>486</th>\n",
              "      <th>487</th>\n",
              "      <th>488</th>\n",
              "      <th>489</th>\n",
              "      <th>490</th>\n",
              "      <th>491</th>\n",
              "      <th>492</th>\n",
              "      <th>493</th>\n",
              "      <th>494</th>\n",
              "      <th>495</th>\n",
              "      <th>496</th>\n",
              "      <th>497</th>\n",
              "      <th>498</th>\n",
              "      <th>499</th>\n",
              "      <th>500</th>\n",
              "      <th>501</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.288502</td>\n",
              "      <td>-0.481055</td>\n",
              "      <td>0.258424</td>\n",
              "      <td>0.362731</td>\n",
              "      <td>0.475364</td>\n",
              "      <td>0.421039</td>\n",
              "      <td>0.014504</td>\n",
              "      <td>0.213545</td>\n",
              "      <td>-0.390066</td>\n",
              "      <td>0.103808</td>\n",
              "      <td>0.092057</td>\n",
              "      <td>-0.045284</td>\n",
              "      <td>0.178335</td>\n",
              "      <td>0.163173</td>\n",
              "      <td>-0.825025</td>\n",
              "      <td>-0.117711</td>\n",
              "      <td>0.193103</td>\n",
              "      <td>-0.039416</td>\n",
              "      <td>0.232813</td>\n",
              "      <td>-0.626957</td>\n",
              "      <td>0.255899</td>\n",
              "      <td>-0.086203</td>\n",
              "      <td>-0.112010</td>\n",
              "      <td>-0.049405</td>\n",
              "      <td>-0.168732</td>\n",
              "      <td>-0.066539</td>\n",
              "      <td>-0.313819</td>\n",
              "      <td>-0.177017</td>\n",
              "      <td>0.028803</td>\n",
              "      <td>-0.097103</td>\n",
              "      <td>0.623241</td>\n",
              "      <td>0.014126</td>\n",
              "      <td>0.023108</td>\n",
              "      <td>0.058664</td>\n",
              "      <td>-0.216553</td>\n",
              "      <td>0.400928</td>\n",
              "      <td>0.303050</td>\n",
              "      <td>-0.222227</td>\n",
              "      <td>-0.287176</td>\n",
              "      <td>0.037768</td>\n",
              "      <td>...</td>\n",
              "      <td>0.329862</td>\n",
              "      <td>0.034904</td>\n",
              "      <td>-0.214976</td>\n",
              "      <td>0.167887</td>\n",
              "      <td>-0.085614</td>\n",
              "      <td>-0.093523</td>\n",
              "      <td>-0.529687</td>\n",
              "      <td>0.326094</td>\n",
              "      <td>0.163124</td>\n",
              "      <td>-0.068303</td>\n",
              "      <td>-0.531376</td>\n",
              "      <td>-0.006876</td>\n",
              "      <td>-0.179367</td>\n",
              "      <td>0.017102</td>\n",
              "      <td>0.018383</td>\n",
              "      <td>-0.121967</td>\n",
              "      <td>0.012128</td>\n",
              "      <td>-0.409407</td>\n",
              "      <td>-0.597547</td>\n",
              "      <td>-0.159906</td>\n",
              "      <td>-0.358888</td>\n",
              "      <td>-0.042565</td>\n",
              "      <td>0.285005</td>\n",
              "      <td>0.432336</td>\n",
              "      <td>-0.005819</td>\n",
              "      <td>-0.093201</td>\n",
              "      <td>0.208513</td>\n",
              "      <td>-0.279186</td>\n",
              "      <td>-0.242795</td>\n",
              "      <td>0.565175</td>\n",
              "      <td>0.193389</td>\n",
              "      <td>-0.345230</td>\n",
              "      <td>-0.041291</td>\n",
              "      <td>0.063343</td>\n",
              "      <td>-0.230869</td>\n",
              "      <td>-0.018990</td>\n",
              "      <td>-0.462915</td>\n",
              "      <td>-0.762691</td>\n",
              "      <td>0.271782</td>\n",
              "      <td>-0.653218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.173821</td>\n",
              "      <td>-0.214929</td>\n",
              "      <td>-0.098004</td>\n",
              "      <td>0.432866</td>\n",
              "      <td>0.370673</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>-0.735449</td>\n",
              "      <td>0.162931</td>\n",
              "      <td>0.113988</td>\n",
              "      <td>0.468011</td>\n",
              "      <td>0.091182</td>\n",
              "      <td>-0.015925</td>\n",
              "      <td>-0.367213</td>\n",
              "      <td>-0.148326</td>\n",
              "      <td>-0.570235</td>\n",
              "      <td>0.235001</td>\n",
              "      <td>0.474639</td>\n",
              "      <td>0.056680</td>\n",
              "      <td>0.336305</td>\n",
              "      <td>-0.118116</td>\n",
              "      <td>0.086382</td>\n",
              "      <td>-0.023839</td>\n",
              "      <td>0.352665</td>\n",
              "      <td>0.201555</td>\n",
              "      <td>-0.232855</td>\n",
              "      <td>0.139960</td>\n",
              "      <td>-0.107633</td>\n",
              "      <td>-0.274393</td>\n",
              "      <td>-0.098784</td>\n",
              "      <td>0.033530</td>\n",
              "      <td>0.202761</td>\n",
              "      <td>-0.214515</td>\n",
              "      <td>-0.363571</td>\n",
              "      <td>0.180008</td>\n",
              "      <td>0.160661</td>\n",
              "      <td>0.698344</td>\n",
              "      <td>0.403793</td>\n",
              "      <td>-0.036676</td>\n",
              "      <td>-0.124082</td>\n",
              "      <td>-0.088976</td>\n",
              "      <td>...</td>\n",
              "      <td>0.558337</td>\n",
              "      <td>-0.285610</td>\n",
              "      <td>-0.147095</td>\n",
              "      <td>0.117567</td>\n",
              "      <td>0.064415</td>\n",
              "      <td>-0.074428</td>\n",
              "      <td>0.022359</td>\n",
              "      <td>0.361806</td>\n",
              "      <td>0.115827</td>\n",
              "      <td>-0.102381</td>\n",
              "      <td>-0.170256</td>\n",
              "      <td>0.033135</td>\n",
              "      <td>0.093055</td>\n",
              "      <td>0.162718</td>\n",
              "      <td>-0.243858</td>\n",
              "      <td>0.281852</td>\n",
              "      <td>0.290611</td>\n",
              "      <td>-0.160803</td>\n",
              "      <td>-0.242895</td>\n",
              "      <td>0.113361</td>\n",
              "      <td>-0.758359</td>\n",
              "      <td>0.122067</td>\n",
              "      <td>0.039228</td>\n",
              "      <td>0.199917</td>\n",
              "      <td>-0.438904</td>\n",
              "      <td>-0.207233</td>\n",
              "      <td>-0.046206</td>\n",
              "      <td>-0.307828</td>\n",
              "      <td>-0.336320</td>\n",
              "      <td>0.378690</td>\n",
              "      <td>0.133606</td>\n",
              "      <td>-0.374622</td>\n",
              "      <td>-0.360892</td>\n",
              "      <td>-0.394297</td>\n",
              "      <td>-0.168498</td>\n",
              "      <td>-0.262506</td>\n",
              "      <td>-0.958892</td>\n",
              "      <td>0.099089</td>\n",
              "      <td>0.487517</td>\n",
              "      <td>-0.307144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.257559</td>\n",
              "      <td>-0.065606</td>\n",
              "      <td>0.344815</td>\n",
              "      <td>0.411276</td>\n",
              "      <td>0.090839</td>\n",
              "      <td>0.738248</td>\n",
              "      <td>0.282006</td>\n",
              "      <td>0.331116</td>\n",
              "      <td>-0.213441</td>\n",
              "      <td>0.092032</td>\n",
              "      <td>-0.173409</td>\n",
              "      <td>-0.434767</td>\n",
              "      <td>0.065186</td>\n",
              "      <td>0.196101</td>\n",
              "      <td>-0.671928</td>\n",
              "      <td>-0.195213</td>\n",
              "      <td>0.074474</td>\n",
              "      <td>0.323334</td>\n",
              "      <td>0.292436</td>\n",
              "      <td>0.468960</td>\n",
              "      <td>-0.193369</td>\n",
              "      <td>0.157990</td>\n",
              "      <td>-0.180058</td>\n",
              "      <td>0.095284</td>\n",
              "      <td>-0.294818</td>\n",
              "      <td>-0.140939</td>\n",
              "      <td>-0.202958</td>\n",
              "      <td>-0.144758</td>\n",
              "      <td>-0.270722</td>\n",
              "      <td>0.155839</td>\n",
              "      <td>0.314211</td>\n",
              "      <td>-0.097944</td>\n",
              "      <td>0.396810</td>\n",
              "      <td>0.310496</td>\n",
              "      <td>-0.448204</td>\n",
              "      <td>0.575355</td>\n",
              "      <td>0.241816</td>\n",
              "      <td>-0.428021</td>\n",
              "      <td>-0.066452</td>\n",
              "      <td>0.207896</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.253060</td>\n",
              "      <td>-0.023285</td>\n",
              "      <td>0.387593</td>\n",
              "      <td>-0.257498</td>\n",
              "      <td>-0.219196</td>\n",
              "      <td>0.463819</td>\n",
              "      <td>-0.047877</td>\n",
              "      <td>-0.002297</td>\n",
              "      <td>-0.023295</td>\n",
              "      <td>0.096966</td>\n",
              "      <td>0.185142</td>\n",
              "      <td>-0.053014</td>\n",
              "      <td>0.580751</td>\n",
              "      <td>0.230906</td>\n",
              "      <td>-0.090283</td>\n",
              "      <td>-0.549747</td>\n",
              "      <td>0.448878</td>\n",
              "      <td>-0.358442</td>\n",
              "      <td>-0.267432</td>\n",
              "      <td>0.062992</td>\n",
              "      <td>-0.650513</td>\n",
              "      <td>0.471424</td>\n",
              "      <td>-0.207576</td>\n",
              "      <td>0.421068</td>\n",
              "      <td>-0.340663</td>\n",
              "      <td>-0.287685</td>\n",
              "      <td>0.239766</td>\n",
              "      <td>-0.012972</td>\n",
              "      <td>-0.408097</td>\n",
              "      <td>0.380892</td>\n",
              "      <td>0.273857</td>\n",
              "      <td>-0.094201</td>\n",
              "      <td>0.245259</td>\n",
              "      <td>0.438028</td>\n",
              "      <td>-0.413395</td>\n",
              "      <td>0.425271</td>\n",
              "      <td>-0.417884</td>\n",
              "      <td>-0.886485</td>\n",
              "      <td>0.458968</td>\n",
              "      <td>-0.380352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.023537</td>\n",
              "      <td>0.186004</td>\n",
              "      <td>-0.018319</td>\n",
              "      <td>0.046002</td>\n",
              "      <td>0.285380</td>\n",
              "      <td>0.824158</td>\n",
              "      <td>0.240865</td>\n",
              "      <td>0.177934</td>\n",
              "      <td>-0.293685</td>\n",
              "      <td>0.369762</td>\n",
              "      <td>-0.286876</td>\n",
              "      <td>-0.115853</td>\n",
              "      <td>0.074393</td>\n",
              "      <td>-0.267145</td>\n",
              "      <td>-0.400384</td>\n",
              "      <td>0.067620</td>\n",
              "      <td>0.081379</td>\n",
              "      <td>0.260510</td>\n",
              "      <td>-0.002243</td>\n",
              "      <td>0.159411</td>\n",
              "      <td>0.212635</td>\n",
              "      <td>-0.261783</td>\n",
              "      <td>0.071453</td>\n",
              "      <td>-0.525530</td>\n",
              "      <td>0.149235</td>\n",
              "      <td>-0.563100</td>\n",
              "      <td>-0.378368</td>\n",
              "      <td>-0.396288</td>\n",
              "      <td>-0.265716</td>\n",
              "      <td>-0.028256</td>\n",
              "      <td>0.035099</td>\n",
              "      <td>-0.282228</td>\n",
              "      <td>0.121753</td>\n",
              "      <td>-0.244408</td>\n",
              "      <td>-0.323249</td>\n",
              "      <td>0.133777</td>\n",
              "      <td>0.099915</td>\n",
              "      <td>-0.073891</td>\n",
              "      <td>0.044732</td>\n",
              "      <td>0.229217</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.164505</td>\n",
              "      <td>-0.436309</td>\n",
              "      <td>-0.089114</td>\n",
              "      <td>-0.515013</td>\n",
              "      <td>-0.356831</td>\n",
              "      <td>0.644965</td>\n",
              "      <td>0.151415</td>\n",
              "      <td>-0.040290</td>\n",
              "      <td>0.202163</td>\n",
              "      <td>0.065799</td>\n",
              "      <td>-0.013578</td>\n",
              "      <td>0.264860</td>\n",
              "      <td>0.562417</td>\n",
              "      <td>-0.322598</td>\n",
              "      <td>0.117282</td>\n",
              "      <td>-0.137634</td>\n",
              "      <td>0.454603</td>\n",
              "      <td>0.114935</td>\n",
              "      <td>-0.076333</td>\n",
              "      <td>0.362280</td>\n",
              "      <td>-0.349352</td>\n",
              "      <td>0.368029</td>\n",
              "      <td>0.062586</td>\n",
              "      <td>0.346775</td>\n",
              "      <td>-0.227782</td>\n",
              "      <td>-0.668857</td>\n",
              "      <td>0.477370</td>\n",
              "      <td>-0.349774</td>\n",
              "      <td>-0.566387</td>\n",
              "      <td>0.270867</td>\n",
              "      <td>0.076834</td>\n",
              "      <td>0.171872</td>\n",
              "      <td>0.258420</td>\n",
              "      <td>0.169574</td>\n",
              "      <td>-0.280809</td>\n",
              "      <td>0.322120</td>\n",
              "      <td>-0.102916</td>\n",
              "      <td>-0.606135</td>\n",
              "      <td>0.186568</td>\n",
              "      <td>-0.477317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.832218</td>\n",
              "      <td>0.451893</td>\n",
              "      <td>0.474038</td>\n",
              "      <td>-0.018249</td>\n",
              "      <td>-0.478648</td>\n",
              "      <td>0.178108</td>\n",
              "      <td>-0.472869</td>\n",
              "      <td>-0.532138</td>\n",
              "      <td>-0.491469</td>\n",
              "      <td>-0.466011</td>\n",
              "      <td>0.395096</td>\n",
              "      <td>-0.386877</td>\n",
              "      <td>-0.798011</td>\n",
              "      <td>-0.271923</td>\n",
              "      <td>-0.168703</td>\n",
              "      <td>0.567564</td>\n",
              "      <td>0.918460</td>\n",
              "      <td>-0.283334</td>\n",
              "      <td>0.052681</td>\n",
              "      <td>0.335400</td>\n",
              "      <td>0.102989</td>\n",
              "      <td>-0.569144</td>\n",
              "      <td>-0.027434</td>\n",
              "      <td>-0.390786</td>\n",
              "      <td>-0.411513</td>\n",
              "      <td>-0.004615</td>\n",
              "      <td>0.059425</td>\n",
              "      <td>0.129107</td>\n",
              "      <td>0.058133</td>\n",
              "      <td>0.178414</td>\n",
              "      <td>-0.222867</td>\n",
              "      <td>0.336164</td>\n",
              "      <td>0.079755</td>\n",
              "      <td>0.220411</td>\n",
              "      <td>0.184255</td>\n",
              "      <td>0.723972</td>\n",
              "      <td>0.306105</td>\n",
              "      <td>0.653465</td>\n",
              "      <td>-0.934595</td>\n",
              "      <td>-0.013150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.484666</td>\n",
              "      <td>-0.181744</td>\n",
              "      <td>0.296147</td>\n",
              "      <td>0.775699</td>\n",
              "      <td>0.239380</td>\n",
              "      <td>-0.016156</td>\n",
              "      <td>0.329073</td>\n",
              "      <td>-0.023605</td>\n",
              "      <td>-0.197673</td>\n",
              "      <td>-1.308118</td>\n",
              "      <td>0.593427</td>\n",
              "      <td>0.109318</td>\n",
              "      <td>-0.387851</td>\n",
              "      <td>0.090579</td>\n",
              "      <td>-0.265281</td>\n",
              "      <td>-0.083823</td>\n",
              "      <td>0.498955</td>\n",
              "      <td>-0.115021</td>\n",
              "      <td>0.705434</td>\n",
              "      <td>0.536024</td>\n",
              "      <td>0.319468</td>\n",
              "      <td>0.083369</td>\n",
              "      <td>-0.067807</td>\n",
              "      <td>-0.206901</td>\n",
              "      <td>0.215812</td>\n",
              "      <td>0.166634</td>\n",
              "      <td>0.071825</td>\n",
              "      <td>0.669192</td>\n",
              "      <td>0.043907</td>\n",
              "      <td>0.346249</td>\n",
              "      <td>0.594541</td>\n",
              "      <td>-0.302686</td>\n",
              "      <td>-0.511276</td>\n",
              "      <td>-0.590193</td>\n",
              "      <td>0.299716</td>\n",
              "      <td>-0.181081</td>\n",
              "      <td>-0.436865</td>\n",
              "      <td>0.996631</td>\n",
              "      <td>0.330113</td>\n",
              "      <td>-0.327735</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 512 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...       509       510       511\n",
              "0 -0.288502 -0.481055  0.258424  ... -0.762691  0.271782 -0.653218\n",
              "1  0.173821 -0.214929 -0.098004  ...  0.099089  0.487517 -0.307144\n",
              "2 -0.257559 -0.065606  0.344815  ... -0.886485  0.458968 -0.380352\n",
              "3 -0.023537  0.186004 -0.018319  ... -0.606135  0.186568 -0.477317\n",
              "4 -0.832218  0.451893  0.474038  ...  0.996631  0.330113 -0.327735\n",
              "\n",
              "[5 rows x 512 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE8LwMImcouq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "efd0ac74-8763-47e4-972e-1efde67e5950"
      },
      "source": [
        "rating.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5\n",
              "1    5\n",
              "2    5\n",
              "3    5\n",
              "4    3\n",
              "Name: star_rating, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlkTC3zpcout",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "4a61eaf8-24df-4a51-f705-762f0aa0e5b7"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(384, input_shape=(df.shape[1],), kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(384, kernel_initializer='glorot_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(optimizer=SGD(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 01:34:25.115150 140626923181952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0730 01:34:25.142191 140626923181952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0730 01:34:25.147720 140626923181952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0730 01:34:25.253195 140626923181952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0730 01:34:25.285217 140626923181952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0730 01:34:25.471031 140626923181952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0730 01:34:25.486073 140626923181952 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcalWS6rcouv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "fc791e7d-f8a6-488f-f0d2-b06c1d492e1e"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 384)               196992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 384)               1536      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 384)               147840    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 384)               1536      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 1925      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 5)                 0         \n",
            "=================================================================\n",
            "Total params: 349,829\n",
            "Trainable params: 348,293\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsaqSch9couy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87227dbe-c9b7-4214-8abe-fadac4933e4b"
      },
      "source": [
        "SVG(model_to_dot(model, show_shapes=True, show_layer_names=False, \n",
        "                 rankdir='TB').create(prog='dot', format='svg'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"875pt\" viewBox=\"0.00 0.00 284.00 875.00\" width=\"284pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 871)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-871 280,-871 280,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140625799690000 -->\n<g class=\"node\" id=\"node1\">\n<title>140625799690000</title>\n<polygon fill=\"none\" points=\"39.5,-747.5 39.5,-793.5 236.5,-793.5 236.5,-747.5 39.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-766.8\">Dense</text>\n<polyline fill=\"none\" points=\"91.5,-747.5 91.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"91.5,-770.5 149.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"149.5,-747.5 149.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-778.3\">(None, 512)</text>\n<polyline fill=\"none\" points=\"149.5,-770.5 236.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-755.3\">(None, 384)</text>\n</g>\n<!-- 140625799690336 -->\n<g class=\"node\" id=\"node2\">\n<title>140625799690336</title>\n<polygon fill=\"none\" points=\"0,-664.5 0,-710.5 276,-710.5 276,-664.5 0,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-683.8\">BatchNormalization</text>\n<polyline fill=\"none\" points=\"131,-664.5 131,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"131,-687.5 189,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"189,-664.5 189,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-695.3\">(None, 384)</text>\n<polyline fill=\"none\" points=\"189,-687.5 276,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-672.3\">(None, 384)</text>\n</g>\n<!-- 140625799690000&#45;&gt;140625799690336 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140625799690000-&gt;140625799690336</title>\n<path d=\"M138,-747.3799C138,-739.1745 138,-729.7679 138,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-720.784 138,-710.784 134.5001,-720.784 141.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140625801882648 -->\n<g class=\"node\" id=\"node3\">\n<title>140625801882648</title>\n<polygon fill=\"none\" points=\"27,-581.5 27,-627.5 249,-627.5 249,-581.5 27,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-600.8\">Activation</text>\n<polyline fill=\"none\" points=\"104,-581.5 104,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"104,-604.5 162,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"162,-581.5 162,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-612.3\">(None, 384)</text>\n<polyline fill=\"none\" points=\"162,-604.5 249,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-589.3\">(None, 384)</text>\n</g>\n<!-- 140625799690336&#45;&gt;140625801882648 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140625799690336-&gt;140625801882648</title>\n<path d=\"M138,-664.3799C138,-656.1745 138,-646.7679 138,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-637.784 138,-627.784 134.5001,-637.784 141.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140625801882200 -->\n<g class=\"node\" id=\"node4\">\n<title>140625801882200</title>\n<polygon fill=\"none\" points=\"33,-498.5 33,-544.5 243,-544.5 243,-498.5 33,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-517.8\">Dropout</text>\n<polyline fill=\"none\" points=\"98,-498.5 98,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"98,-521.5 156,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"156,-498.5 156,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-529.3\">(None, 384)</text>\n<polyline fill=\"none\" points=\"156,-521.5 243,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-506.3\">(None, 384)</text>\n</g>\n<!-- 140625801882648&#45;&gt;140625801882200 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140625801882648-&gt;140625801882200</title>\n<path d=\"M138,-581.3799C138,-573.1745 138,-563.7679 138,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-554.784 138,-544.784 134.5001,-554.784 141.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140625799690840 -->\n<g class=\"node\" id=\"node5\">\n<title>140625799690840</title>\n<polygon fill=\"none\" points=\"39.5,-415.5 39.5,-461.5 236.5,-461.5 236.5,-415.5 39.5,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-434.8\">Dense</text>\n<polyline fill=\"none\" points=\"91.5,-415.5 91.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"91.5,-438.5 149.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"149.5,-415.5 149.5,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-446.3\">(None, 384)</text>\n<polyline fill=\"none\" points=\"149.5,-438.5 236.5,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-423.3\">(None, 384)</text>\n</g>\n<!-- 140625801882200&#45;&gt;140625799690840 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140625801882200-&gt;140625799690840</title>\n<path d=\"M138,-498.3799C138,-490.1745 138,-480.7679 138,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-471.784 138,-461.784 134.5001,-471.784 141.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140625799691176 -->\n<g class=\"node\" id=\"node6\">\n<title>140625799691176</title>\n<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 276,-378.5 276,-332.5 0,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-351.8\">BatchNormalization</text>\n<polyline fill=\"none\" points=\"131,-332.5 131,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"131,-355.5 189,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"189,-332.5 189,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-363.3\">(None, 384)</text>\n<polyline fill=\"none\" points=\"189,-355.5 276,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.5\" y=\"-340.3\">(None, 384)</text>\n</g>\n<!-- 140625799690840&#45;&gt;140625799691176 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140625799690840-&gt;140625799691176</title>\n<path d=\"M138,-415.3799C138,-407.1745 138,-397.7679 138,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-388.784 138,-378.784 134.5001,-388.784 141.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140625804952800 -->\n<g class=\"node\" id=\"node7\">\n<title>140625804952800</title>\n<polygon fill=\"none\" points=\"27,-249.5 27,-295.5 249,-295.5 249,-249.5 27,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-268.8\">Activation</text>\n<polyline fill=\"none\" points=\"104,-249.5 104,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"104,-272.5 162,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"162,-249.5 162,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-280.3\">(None, 384)</text>\n<polyline fill=\"none\" points=\"162,-272.5 249,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-257.3\">(None, 384)</text>\n</g>\n<!-- 140625799691176&#45;&gt;140625804952800 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140625799691176-&gt;140625804952800</title>\n<path d=\"M138,-332.3799C138,-324.1745 138,-314.7679 138,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-305.784 138,-295.784 134.5001,-305.784 141.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140625804420992 -->\n<g class=\"node\" id=\"node8\">\n<title>140625804420992</title>\n<polygon fill=\"none\" points=\"33,-166.5 33,-212.5 243,-212.5 243,-166.5 33,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-185.8\">Dropout</text>\n<polyline fill=\"none\" points=\"98,-166.5 98,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"98,-189.5 156,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"127\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"156,-166.5 156,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-197.3\">(None, 384)</text>\n<polyline fill=\"none\" points=\"156,-189.5 243,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"199.5\" y=\"-174.3\">(None, 384)</text>\n</g>\n<!-- 140625804952800&#45;&gt;140625804420992 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140625804952800-&gt;140625804420992</title>\n<path d=\"M138,-249.3799C138,-241.1745 138,-231.7679 138,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-222.784 138,-212.784 134.5001,-222.784 141.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140625804954760 -->\n<g class=\"node\" id=\"node9\">\n<title>140625804954760</title>\n<polygon fill=\"none\" points=\"39.5,-83.5 39.5,-129.5 236.5,-129.5 236.5,-83.5 39.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65.5\" y=\"-102.8\">Dense</text>\n<polyline fill=\"none\" points=\"91.5,-83.5 91.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"91.5,-106.5 149.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"149.5,-83.5 149.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-114.3\">(None, 384)</text>\n<polyline fill=\"none\" points=\"149.5,-106.5 236.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-91.3\">(None, 5)</text>\n</g>\n<!-- 140625804420992&#45;&gt;140625804954760 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140625804420992-&gt;140625804954760</title>\n<path d=\"M138,-166.3799C138,-158.1745 138,-148.7679 138,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-139.784 138,-129.784 134.5001,-139.784 141.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140625803761256 -->\n<g class=\"node\" id=\"node10\">\n<title>140625803761256</title>\n<polygon fill=\"none\" points=\"34.5,-.5 34.5,-46.5 241.5,-46.5 241.5,-.5 34.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"73\" y=\"-19.8\">Activation</text>\n<polyline fill=\"none\" points=\"111.5,-.5 111.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"140.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"111.5,-23.5 169.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"140.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"169.5,-.5 169.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-31.3\">(None, 5)</text>\n<polyline fill=\"none\" points=\"169.5,-23.5 241.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-8.3\">(None, 5)</text>\n</g>\n<!-- 140625804954760&#45;&gt;140625803761256 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140625804954760-&gt;140625803761256</title>\n<path d=\"M138,-83.3799C138,-75.1745 138,-65.7679 138,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-56.784 138,-46.784 134.5001,-56.784 141.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140625799690616 -->\n<g class=\"node\" id=\"node11\">\n<title>140625799690616</title>\n<polygon fill=\"none\" points=\"73.5,-830.5 73.5,-866.5 202.5,-866.5 202.5,-830.5 73.5,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"138\" y=\"-844.8\">140625799690616</text>\n</g>\n<!-- 140625799690616&#45;&gt;140625799690000 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140625799690616-&gt;140625799690000</title>\n<path d=\"M138,-830.4092C138,-822.4308 138,-812.795 138,-803.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"141.5001,-803.5333 138,-793.5333 134.5001,-803.5334 141.5001,-803.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUxyjmG-cou1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "ae1b253d-bd89-40cb-89a1-102dca55d174"
      },
      "source": [
        "# one hot encode rating\n",
        "print(rating.shape)\n",
        "print(type(rating))\n",
        "y = OneHotEncoder().fit_transform(rating.values.reshape(len(rating), 1)).toarray()\n",
        "y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(111909,)\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xv0pnRjcou4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df, y, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "X8wF7QlUcou7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "6e2dde53-c8ee-49a5-d89f-215075699f8a"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
        "\n",
        "# use our model wrapper the wrap the model so we can save things for later\n",
        "mw = ku.ModelWrapper(model=model, \n",
        "                     name=MODEL_NAME, \n",
        "                     label_name=LABEL_COLUMN, \n",
        "                     data_file=DATA_FILE, \n",
        "                     embedding=\"word2vec\")\n",
        "\n",
        "network_history = mw.fit(x_train, y_train,\n",
        "                      batch_size=128,\n",
        "                      epochs=50,\n",
        "                      verbose=1,\n",
        "                      validation_split=0.2,\n",
        "                      callbacks=[early_stop])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0730 01:34:26.528317 140626923181952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 67144 samples, validate on 16787 samples\n",
            "Epoch 1/50\n",
            "67144/67144 [==============================] - 11s 169us/step - loss: 1.1254 - acc: 0.5856 - val_loss: 0.9888 - val_acc: 0.6382\n",
            "Epoch 2/50\n",
            "67144/67144 [==============================] - 13s 190us/step - loss: 1.0011 - acc: 0.6257 - val_loss: 0.9502 - val_acc: 0.6438\n",
            "Epoch 3/50\n",
            "67144/67144 [==============================] - 14s 209us/step - loss: 0.9694 - acc: 0.6349 - val_loss: 0.9311 - val_acc: 0.6490\n",
            "Epoch 4/50\n",
            "67144/67144 [==============================] - 14s 205us/step - loss: 0.9529 - acc: 0.6387 - val_loss: 0.9171 - val_acc: 0.6544\n",
            "Epoch 5/50\n",
            "67144/67144 [==============================] - 14s 207us/step - loss: 0.9352 - acc: 0.6449 - val_loss: 0.9062 - val_acc: 0.6590\n",
            "Epoch 6/50\n",
            "67144/67144 [==============================] - 14s 205us/step - loss: 0.9254 - acc: 0.6483 - val_loss: 0.8983 - val_acc: 0.6613\n",
            "Epoch 7/50\n",
            "67144/67144 [==============================] - 14s 205us/step - loss: 0.9162 - acc: 0.6509 - val_loss: 0.8948 - val_acc: 0.6630\n",
            "Epoch 8/50\n",
            "67144/67144 [==============================] - 18s 271us/step - loss: 0.9092 - acc: 0.6544 - val_loss: 0.8901 - val_acc: 0.6641\n",
            "Epoch 9/50\n",
            "67144/67144 [==============================] - 24s 359us/step - loss: 0.9019 - acc: 0.6555 - val_loss: 0.8926 - val_acc: 0.6621\n",
            "Epoch 10/50\n",
            "67144/67144 [==============================] - 23s 338us/step - loss: 0.8956 - acc: 0.6582 - val_loss: 0.8841 - val_acc: 0.6654\n",
            "Epoch 11/50\n",
            "67144/67144 [==============================] - 23s 346us/step - loss: 0.8932 - acc: 0.6584 - val_loss: 0.8839 - val_acc: 0.6669\n",
            "Epoch 12/50\n",
            "67144/67144 [==============================] - 23s 345us/step - loss: 0.8894 - acc: 0.6604 - val_loss: 0.8791 - val_acc: 0.6663\n",
            "Epoch 13/50\n",
            "67144/67144 [==============================] - 23s 347us/step - loss: 0.8858 - acc: 0.6625 - val_loss: 0.8788 - val_acc: 0.6669\n",
            "Epoch 14/50\n",
            "67144/67144 [==============================] - 23s 345us/step - loss: 0.8839 - acc: 0.6628 - val_loss: 0.8779 - val_acc: 0.6671\n",
            "Epoch 15/50\n",
            "67144/67144 [==============================] - 24s 351us/step - loss: 0.8822 - acc: 0.6633 - val_loss: 0.8759 - val_acc: 0.6682\n",
            "Epoch 16/50\n",
            "67144/67144 [==============================] - 23s 347us/step - loss: 0.8779 - acc: 0.6641 - val_loss: 0.8758 - val_acc: 0.6677\n",
            "Epoch 17/50\n",
            "67144/67144 [==============================] - 23s 348us/step - loss: 0.8730 - acc: 0.6678 - val_loss: 0.8757 - val_acc: 0.6670\n",
            "Epoch 18/50\n",
            "67144/67144 [==============================] - 26s 387us/step - loss: 0.8727 - acc: 0.6652 - val_loss: 0.8719 - val_acc: 0.6699\n",
            "Epoch 19/50\n",
            "67144/67144 [==============================] - 30s 446us/step - loss: 0.8687 - acc: 0.6678 - val_loss: 0.8745 - val_acc: 0.6685\n",
            "Epoch 20/50\n",
            "67144/67144 [==============================] - 29s 425us/step - loss: 0.8675 - acc: 0.6689 - val_loss: 0.8756 - val_acc: 0.6684\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtO0zG31cou9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "44babbaa-1e80-4343-f752-75f2a22d88c6"
      },
      "source": [
        "mw.evaluate(x_test, y_test)\n",
        "print(\"Accuracy: %.2f%%\" % (mw.scores[1]*100))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running model.evaluate...\n",
            "27978/27978 [==============================] - 7s 254us/step\n",
            "Running model.predict...\n",
            "Unencode predictions...\n",
            "Generating confusion matrix...\n",
            "Calculating ROC AUC...\n",
            "Getting classification report...\n",
            "Accuracy: 66.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpP2te11covA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "be81cbf3-a033-4f50-b4b7-e29c97c3b533"
      },
      "source": [
        "\n",
        "pu.plot_network_history(mw.network_history)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAFICAYAAAA2+wi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKvT1z4qcovN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "f5742c62-c438-4433-f9eb-a48a388855cb"
      },
      "source": [
        "mw.confusion_matrix"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3304,     0,   214,   109,   248],\n",
              "       [ 1089,     0,   328,   204,   266],\n",
              "       [  722,     1,   539,   685,   613],\n",
              "       [  367,     0,   317,  1277,  2676],\n",
              "       [  457,     1,   197,   925, 13439]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwwokuelcovR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a63c5aeb-1a8d-4d53-b169-97f6f0384347"
      },
      "source": [
        "print(mw.classification_report)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.56      0.85      0.67      3875\n",
            "           2       0.00      0.00      0.00      1887\n",
            "           3       0.34      0.21      0.26      2560\n",
            "           4       0.40      0.28      0.33      4637\n",
            "           5       0.78      0.89      0.83     15019\n",
            "\n",
            "    accuracy                           0.66     27978\n",
            "   macro avg       0.41      0.45      0.42     27978\n",
            "weighted avg       0.59      0.66      0.62     27978\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC0Q7vWFcovV",
        "colab_type": "text"
      },
      "source": [
        "# Save off various files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU3L4JTmcovW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "c067192f-f7d8-4528-9062-6f1e258c2ae3"
      },
      "source": [
        "mw.save(DRIVE_DIR, append_report=True)\n",
        "mw.get_report().to_df()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "description: review_body-word2vec5-111909-512-nolda-DNN_384_384_batchnorm-512-star_rating\n",
            "Saving model file: drive/My Drive/Springboard/capstone/models/review_body-word2vec5-111909-512-nolda-DNN_384_384_batchnorm-512-star_rating-model.h5\n",
            "Saving network history file: drive/My Drive/Springboard/capstone/models/review_body-word2vec5-111909-512-nolda-DNN_384_384_batchnorm-512-star_rating-history.pkl\n",
            "Saving to report file: drive/My Drive/Springboard/capstone/reports/2019-07-30-dl_protype-report.csv\n",
            "Saving report file...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>classification_report</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>description</th>\n",
              "      <th>embedding</th>\n",
              "      <th>evaluate_time_min</th>\n",
              "      <th>file</th>\n",
              "      <th>fpr</th>\n",
              "      <th>loss</th>\n",
              "      <th>max_sequence_length</th>\n",
              "      <th>model_file</th>\n",
              "      <th>model_name</th>\n",
              "      <th>network_history_file</th>\n",
              "      <th>predict_time_min</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>status</th>\n",
              "      <th>status_date</th>\n",
              "      <th>test_examples</th>\n",
              "      <th>test_features</th>\n",
              "      <th>tokenizer_file</th>\n",
              "      <th>tpr</th>\n",
              "      <th>train_examples</th>\n",
              "      <th>train_features</th>\n",
              "      <th>train_time_min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.663343</td>\n",
              "      <td>{\"1\": {\"precision\": 0.5563226132345512, \"recal...</td>\n",
              "      <td>[[3304, 0, 214, 109, 248], [1089, 0, 328, 204,...</td>\n",
              "      <td>review_body-word2vec5-111909-512-nolda-DNN_384...</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>8.14</td>\n",
              "      <td>review_body-word2vec5-111909-512-nolda.csv</td>\n",
              "      <td>{\"0\": [0.0, 0.0, 0.0, 0.0, 0.0, 4.148861137617...</td>\n",
              "      <td>0.879841</td>\n",
              "      <td>512.0</td>\n",
              "      <td>drive/My Drive/Springboard/capstone/models/rev...</td>\n",
              "      <td>DNN_384_384_batchnorm</td>\n",
              "      <td>&lt;keras.callbacks.History object at 0x7fe5fee4f...</td>\n",
              "      <td>8.14</td>\n",
              "      <td>{\"auc_1\": 0.9473514821471828, \"auc_2\": 0.83687...</td>\n",
              "      <td>success</td>\n",
              "      <td>2019-07-30 01:43:05</td>\n",
              "      <td>27978.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>None</td>\n",
              "      <td>{\"0\": [0.0, 0.00025806451612903227, 0.00129032...</td>\n",
              "      <td>83931.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>8.14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  ... train_time_min\n",
              "0  0.663343  ...           8.14\n",
              "\n",
              "[1 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaNBOWPycovi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "e3d64cfb-efe5-49ad-9c14-bab8d187f318"
      },
      "source": [
        "# test saved report\n",
        "loaded = pd.read_csv(mw.report_file, quotechar=\"'\")\n",
        "loaded.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>classification_report</th>\n",
              "      <th>confusion_matrix</th>\n",
              "      <th>description</th>\n",
              "      <th>embedding</th>\n",
              "      <th>evaluate_time_min</th>\n",
              "      <th>file</th>\n",
              "      <th>fpr</th>\n",
              "      <th>loss</th>\n",
              "      <th>max_sequence_length</th>\n",
              "      <th>model_file</th>\n",
              "      <th>model_name</th>\n",
              "      <th>network_history_file</th>\n",
              "      <th>predict_time_min</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>status</th>\n",
              "      <th>status_date</th>\n",
              "      <th>test_examples</th>\n",
              "      <th>test_features</th>\n",
              "      <th>tokenizer_file</th>\n",
              "      <th>tpr</th>\n",
              "      <th>train_examples</th>\n",
              "      <th>train_features</th>\n",
              "      <th>train_time_min</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.663343</td>\n",
              "      <td>{\"1\": {\"precision\": 0.5563226132345512, \"recal...</td>\n",
              "      <td>[[3304, 0, 214, 109, 248], [1089, 0, 328, 204,...</td>\n",
              "      <td>review_body-word2vec5-111909-512-nolda-DNN_384...</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>8.14</td>\n",
              "      <td>review_body-word2vec5-111909-512-nolda.csv</td>\n",
              "      <td>{\"0\": [0.0, 0.0, 0.0, 0.0, 0.0, 4.148861137617...</td>\n",
              "      <td>0.879841</td>\n",
              "      <td>512.0</td>\n",
              "      <td>drive/My Drive/Springboard/capstone/models/rev...</td>\n",
              "      <td>DNN_384_384_batchnorm</td>\n",
              "      <td>&lt;keras.callbacks.History object at 0x7fe5fee4f...</td>\n",
              "      <td>8.14</td>\n",
              "      <td>{\"auc_1\": 0.9473514821471828, \"auc_2\": 0.83687...</td>\n",
              "      <td>success</td>\n",
              "      <td>2019-07-30 01:43:02</td>\n",
              "      <td>27978.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{\"0\": [0.0, 0.00025806451612903227, 0.00129032...</td>\n",
              "      <td>83931.0</td>\n",
              "      <td>512.0</td>\n",
              "      <td>8.14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  ... train_time_min\n",
              "0  0.663343  ...           8.14\n",
              "\n",
              "[1 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HID17uuUcovj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "065b7998-fe21-4105-eab9-9acbabd1d748"
      },
      "source": [
        "print(datetime.now())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-07-30 01:43:15.933191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp7OIj_YhOD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}