{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use simple techniques for feature Engineering and to do multi-class classification to predict review ratings based on the Amazon Reviews dataset\n",
    "\n",
    "<b>Objective for this exercise:</b>\n",
    "    * Establish NLP prediction accuracy baseline using simple ML models\n",
    "    * Explore different permutation of feature engineering techniques, data, and classification algorithms\n",
    "    * Compare accuracy of preduction using the following information:\n",
    "        * Product Title\n",
    "        * Review Headline\n",
    "        * Review Body\n",
    "    * (If time allows) see if using only helpful reviews to train improves our accuracy for our predictions - this reduces our 110k dataset to 35k\n",
    "\n",
    "\n",
    "<b>Feature Engineering Techniques:</b>\n",
    "    * bag of words\n",
    "    * TF-IDF\n",
    "    * Topic Modeling\n",
    "    \n",
    "    \n",
    "<b>Classification:</b>\n",
    "    * Logistic Regression Classification\n",
    "    * K-nearest Neighbors Classification\n",
    "    * Radius Neighbors Classification - document suggests the Radius Neighbors might be a better fit if our data is no uniform. From our exploratory data analysis, we see that most reviews skew towards 4 or 5 stars\n",
    "    \n",
    "    \n",
    "    \n",
    "<b>Data:</b>\n",
    "\n",
    "Data used in this notebooks came from Amazon reviews dataset - Wirless category. First it was converted from tsv to csv. Then it was pre-processed in the previous notebook using various text processing techniques. For details, please see: [amazon_review_preprocessing.ipynb](amazon_review_preprocessing.ipynb)\n",
    "\n",
    "\n",
    "Example of how to do this:\n",
    "```\n",
    "python preprocess_amazon.py -l INFO -r -o dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-smallout.csv dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-smallin.csv\n",
    "```\n",
    "\n",
    "\n",
    "<b>Memory Requirement:</b>\n",
    "\n",
    "| File | Python Memory |\n",
    "|------|---------------|\n",
    "| amazon_reviews_us_Wireless_v1_00-tinyout.csv | 20 - 26 GB |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import timedelta, datetime\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "\n",
    "# I'm finding that running these models on my laptop takes forever and they are not finishing so I'm going to start\n",
    "# with a really small file just to validate my code\n",
    "#\n",
    "# datafile was generated from amazon_review_preprocessing.ipynb - this file has 1k reviews randomly chosen\n",
    "# from original file\n",
    "KEEP_COLUMNS = [\"product_title\", \"helpful_votes\", \"review_headline\", \"review_body\", \"star_rating\"]\n",
    "TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "OUTCOME_COLUMN = \"star_rating\"\n",
    "\n",
    "\n",
    "# Configuration\n",
    "DATA_FILE = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-tinyout.csv\"\n",
    "NEIGHBORS = [5] # default\n",
    "# NEIGHBORS = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "# Radius for RadiusNeighbor\n",
    "RADII = [5.0] # this is the lowest number I tried that was able to find a neighbor\n",
    "# RADII = [5.0, 7.0, 9.0, 11.0, 13.0]\n",
    "\n",
    "# logistic regression settings\n",
    "C= [1.0] # default\n",
    "# C = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "\n",
    "FEATURE_COLUMN = \"review_body\"\n",
    "ENABLE_KNN = True\n",
    "ENABLE_RN = True\n",
    "ENABLE_LR = True\n",
    "ENABLE_BOW = True\n",
    "ENABLE_TFIDF = True\n",
    "WRITE_TO_CSV = True\n",
    "OUTFILE = \"amazon_review_classifier_simple.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22414 entries, 0 to 22413\n",
      "Data columns (total 5 columns):\n",
      "product_title      22414 non-null object\n",
      "helpful_votes      22414 non-null int64\n",
      "review_headline    22414 non-null object\n",
      "review_body        22414 non-null object\n",
      "star_rating        22414 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 875.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfy universal car headrest mount holder portab...</td>\n",
       "      <td>0</td>\n",
       "      <td>good enough</td>\n",
       "      <td>serves purpose loud whoever sitting seat attached</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iccker art nylon hair paint brush tools set bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>five stars</td>\n",
       "      <td>works really well samsung s6 otterbox defender...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jbl gx series coaxial car loudspeakers certifi...</td>\n",
       "      <td>1</td>\n",
       "      <td>speakers did not sound well thought</td>\n",
       "      <td>speakers did not sound well thought would jbls...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>otium screen protectors</td>\n",
       "      <td>0</td>\n",
       "      <td>really easy install included guide</td>\n",
       "      <td>absoultely perfect included install guide make...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple watch stand vtin aluminum alloy build ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>love</td>\n",
       "      <td>heres lot like stand apple watch very modern s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       product_title  helpful_votes  \\\n",
       "0  tfy universal car headrest mount holder portab...              0   \n",
       "1  iccker art nylon hair paint brush tools set bl...              0   \n",
       "2  jbl gx series coaxial car loudspeakers certifi...              1   \n",
       "3                            otium screen protectors              0   \n",
       "4  apple watch stand vtin aluminum alloy build ho...              0   \n",
       "\n",
       "                       review_headline  \\\n",
       "0                          good enough   \n",
       "1                           five stars   \n",
       "2  speakers did not sound well thought   \n",
       "3   really easy install included guide   \n",
       "4                                 love   \n",
       "\n",
       "                                         review_body  star_rating  \n",
       "0  serves purpose loud whoever sitting seat attached            3  \n",
       "1  works really well samsung s6 otterbox defender...            5  \n",
       "2  speakers did not sound well thought would jbls...            2  \n",
       "3  absoultely perfect included install guide make...            5  \n",
       "4  heres lot like stand apple watch very modern s...            5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in DF\n",
    "df = pd.read_csv(DATA_FILE)[KEEP_COLUMNS]\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Should I include add these along with the word vectors as part of the feature set?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>pt_wc</th>\n",
       "      <th>rh_wc</th>\n",
       "      <th>rb_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22414.000000</td>\n",
       "      <td>22414.000000</td>\n",
       "      <td>22414.000000</td>\n",
       "      <td>22414.000000</td>\n",
       "      <td>22414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.904792</td>\n",
       "      <td>3.895333</td>\n",
       "      <td>15.907335</td>\n",
       "      <td>2.956322</td>\n",
       "      <td>25.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.709008</td>\n",
       "      <td>1.465474</td>\n",
       "      <td>9.716846</td>\n",
       "      <td>1.915684</td>\n",
       "      <td>41.441713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>868.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1133.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       helpful_votes   star_rating         pt_wc         rh_wc         rb_wc\n",
       "count   22414.000000  22414.000000  22414.000000  22414.000000  22414.000000\n",
       "mean        0.904792      3.895333     15.907335      2.956322     25.979700\n",
       "std         8.709008      1.465474      9.716846      1.915684     41.441713\n",
       "min         0.000000      1.000000      1.000000      1.000000      1.000000\n",
       "25%         0.000000      3.000000      9.000000      2.000000      8.000000\n",
       "50%         0.000000      5.000000     14.000000      2.000000     15.000000\n",
       "75%         0.000000      5.000000     20.000000      4.000000     28.000000\n",
       "max       868.000000      5.000000     92.000000     21.000000   1133.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get some data on our text\n",
    "\n",
    "def wc(x:str):\n",
    "    return len(str(x).split())\n",
    "\n",
    "df[\"pt_wc\"] = df.product_title.apply(wc)\n",
    "df[\"rh_wc\"] = df.review_headline.apply(wc)\n",
    "df[\"rb_wc\"] = df.review_body.apply(wc)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up different dataframes for training\n",
    "\n",
    "# outcome\n",
    "Y = df[\"star_rating\"]\n",
    "X = df[FEATURE_COLUMN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to help us run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand classification report into dictionary\n",
    "# classifcation report is a 2 level dictionary. from documentation, it looks something like this\n",
    "# {'label 1': {'precision':0.5,\n",
    "#              'recall':1.0,\n",
    "#              'f1-score':0.67,\n",
    "#              'support':1},\n",
    "#  'label 2': { ... },\n",
    "#   ...\n",
    "# }\n",
    "def add_dict_to_dict(target, source):\n",
    "    \"\"\"\n",
    "    target: dictionary to add to\n",
    "    source: dictionary to add from\n",
    "    ------\n",
    "    return: dictionary with source added to target\n",
    "    \"\"\"\n",
    "    for key, value in source.items():\n",
    "        if isinstance(value, dict):\n",
    "            # append key to dictionary keys\n",
    "            for subkey, subvalue in value.items():\n",
    "                target[f'{key}_{subkey}'] = subvalue\n",
    "        else:\n",
    "            target[key] = value\n",
    "            \n",
    "    return target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_fscore_support, classification_report, accuracy_score\n",
    "\n",
    "def interpret_predictions(Y_test, Y_predict, report=None):\n",
    "    \"\"\"\n",
    "    Run metrics on predictions\n",
    "    \n",
    "    Y_test: true results\n",
    "    Y_predict: predictions from model\n",
    "    results: dictionary to append results to\n",
    "    ------\n",
    "    return dictionary with report\n",
    "    \"\"\"\n",
    "\n",
    "    # calculation metrics\n",
    "#     precision, recall, fbeta_score, support = precision_recall_fscore_support(Y_test, Y_predict)\n",
    "#     f1 = f1_score(Y_test, Y_predict, average='micro')\n",
    "#     a_score = accuracy_score(Y_test, Y_predict)\n",
    "\n",
    "    if not report:\n",
    "        report = {}\n",
    "        \n",
    "#     report[\"accuracy_score\"] = a_score\n",
    "#     report[\"precision\"] = precision\n",
    "#     report[\"recall\"] = recall\n",
    "#     report[\"F1\"] = f1\n",
    "#     report[\"Fbeta\"] = fbeta_score\n",
    "    \n",
    "    c_report = classification_report(Y_test, Y_predict, output_dict = True)\n",
    "\n",
    "    report = add_dict_to_dict(report, c_report)\n",
    "    \n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_fit_predict(model, X_train, Y_train, X_test, Y_test):\n",
    "        \"\"\"\n",
    "        Fit the model then run predict on it\n",
    "        \n",
    "        model: model to train with\n",
    "        X_test: training input\n",
    "        Y_train: training classes\n",
    "        X_test: test input\n",
    "        Y_test: result\n",
    "        -----\n",
    "        return tuple of predictions and dictionary with train time, predict_time total time\n",
    "        \"\"\"\n",
    "\n",
    "        train_time_start = datetime.now()\n",
    "        print(f'Start training: {train_time_start.strftime(TIME_FORMAT)}')\n",
    "        result = model.fit(bag_X_train, bag_Y_train)\n",
    "\n",
    "        train_time_end = datetime.now()\n",
    "        print(f'End training: {train_time_end.strftime(TIME_FORMAT)}')\n",
    "\n",
    "#         score = result.score(bag_X_test, bag_Y_test)\n",
    "\n",
    "        # calculate mean error score\n",
    "        score_time_end = datetime.now()\n",
    "        print(f'End Scoring: {score_time_end.strftime(TIME_FORMAT)}')\n",
    "        \n",
    "        # predictions\n",
    "        Y_predict = model.predict(X_test)\n",
    "        predict_time_end = datetime.now()\n",
    "        print(f'End predict: {predict_time_end.strftime(TIME_FORMAT)}')\n",
    "\n",
    "        # calculate times\n",
    "        train_time = train_time_end - train_time_start\n",
    "        train_time_min = round(train_time.total_seconds() / 60)\n",
    "        print(f'Training time (min): {train_time_min}')\n",
    "\n",
    "\n",
    "        score_time = score_time_end - train_time_end\n",
    "        score_time_min = round(score_time.total_seconds() / 60)\n",
    "        print(f'Scoring time (min): {score_time_min}')\n",
    "\n",
    "        predict_time = predict_time_end - score_time_end\n",
    "        predict_time_min = round(predict_time.total_seconds() / 60)\n",
    "        print(f'Predict time (min): {predict_time_min}')\n",
    "\n",
    "        train_examples, train_features = X_train.shape\n",
    "        test_examples, test_features = X_test.shape\n",
    "        \n",
    "\n",
    "        report = {\n",
    "                \"train_examples\": train_examples,\n",
    "                \"train_features\": train_features,\n",
    "                \"test_examples\": test_examples,\n",
    "                \"test_features\": test_features,\n",
    "                \"train_time_min\": train_time_min,\n",
    "                \"score_time_min\": score_time_min,\n",
    "                \"predict_time_min\": predict_time_min,\n",
    "                \"total_time_min\": train_time_min + score_time_min + predict_time_min\n",
    "               }\n",
    "        \n",
    "        report = interpret_predictions(Y_test, Y_predict, report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        return (Y_predict, report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words - Generate Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: try different parameters for CountVectorizers?\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(X.array)\n",
    "vocab = cv.get_feature_names()\n",
    "# print(f\"vocab: {vocab}\")\n",
    "bag_pd = pd.DataFrame(cv_matrix.toarray(), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20541\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000hz</th>\n",
       "      <th>000hzsensitivity</th>\n",
       "      <th>000mah</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>003</th>\n",
       "      <th>004</th>\n",
       "      <th>...</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zperia</th>\n",
       "      <th>zr</th>\n",
       "      <th>zte</th>\n",
       "      <th>zumo</th>\n",
       "      <th>zune</th>\n",
       "      <th>zuzo</th>\n",
       "      <th>zx4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  000hz  000hzsensitivity  000mah  001  002  003  004  ...  \\\n",
       "0   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "1   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "2   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "3   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "4   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "\n",
       "   zoomed  zooming  zooms  zperia  zr  zte  zumo  zune  zuzo  zx4  \n",
       "0       0        0      0       0   0    0     0     0     0    0  \n",
       "1       0        0      0       0   0    0     0     0     0    0  \n",
       "2       0        0      0       0   0    0     0     0     0    0  \n",
       "3       0        0      0       0   0    0     0     0     0    0  \n",
       "4       0        0      0       0   0    0     0     0     0    0  \n",
       "\n",
       "[5 rows x 20541 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the data\n",
    "print(len(vocab))\n",
    "bag_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size 16810\n",
      "test set size 5604\n"
     ]
    }
   ],
   "source": [
    "# split results into training and test set\n",
    "bag_X_train, bag_X_test, bag_Y_train, bag_Y_test = train_test_split(bag_pd, Y, random_state=1)\n",
    "\n",
    "print(f\"training set size {len(bag_X_train)}\")\n",
    "print(f\"test set size {len(bag_X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - Generate Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: play with min_df and max_df\n",
    "# # TODO: play with variations of ngram\n",
    "# tv = TfidfVectorizer(min_df=0., max_df=1., ngram_range=(1,3), use_idf=True)\n",
    "# tv_matrix = tv.fit_transform(X.array)\n",
    "# vocab = tv.get_feature_names()\n",
    "# tv_pd = pd.DataFrame(np.round(tv_matrix.toarray(), 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split results into training and test set\n",
    "# tv_X_train, tv_X_test, tv_Y_train, tv_Y_test = train_test_split(tv_pd, Y, random_state=1)\n",
    "\n",
    "# print(f\"training set size {len(tv_X_train)}\")\n",
    "# print(f\"test set size {len(tv_X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Let's Run Some Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pd = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 neighbors\n",
      "-----------------------\n",
      "Start training: 2019-05-17 00:58:52\n",
      "End training: 2019-05-17 00:59:21\n",
      "End Scoring: 2019-05-17 00:59:21\n",
      "End predict: 2019-05-17 01:09:53\n",
      "Training time (min): 0\n",
      "Scoring time (min): 0\n",
      "Predict time (min): 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_support</th>\n",
       "      <th>2_f1-score</th>\n",
       "      <th>2_precision</th>\n",
       "      <th>2_recall</th>\n",
       "      <th>2_support</th>\n",
       "      <th>3_f1-score</th>\n",
       "      <th>3_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>test_examples</th>\n",
       "      <th>test_features</th>\n",
       "      <th>total_time_min</th>\n",
       "      <th>train_examples</th>\n",
       "      <th>train_features</th>\n",
       "      <th>train_time_min</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.456848</td>\n",
       "      <td>0.352643</td>\n",
       "      <td>0.648469</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.08998</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.059299</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>0.213235</td>\n",
       "      <td>...</td>\n",
       "      <td>5604.0</td>\n",
       "      <td>20541.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16810.0</td>\n",
       "      <td>20541.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499946</td>\n",
       "      <td>0.489384</td>\n",
       "      <td>0.546752</td>\n",
       "      <td>5604.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1_f1-score  1_precision  1_recall  1_support  2_f1-score  2_precision  \\\n",
       "0    0.456848     0.352643  0.648469      751.0     0.08998     0.186441   \n",
       "\n",
       "   2_recall  2_support  3_f1-score  3_precision  ...  test_examples  \\\n",
       "0  0.059299      371.0    0.086053     0.213235  ...         5604.0   \n",
       "\n",
       "   test_features  total_time_min  train_examples  train_features  \\\n",
       "0        20541.0            11.0         16810.0         20541.0   \n",
       "\n",
       "   train_time_min  weighted avg_f1-score  weighted avg_precision  \\\n",
       "0             0.0               0.499946                0.489384   \n",
       "\n",
       "   weighted avg_recall  weighted avg_support  \n",
       "0             0.546752                5604.0  \n",
       "\n",
       "[1 rows x 48 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use K-nearest neighbors to train\n",
    "if ENABLE_KNN and ENABLE_BOW:\n",
    "    for neighbor in NEIGHBORS:\n",
    "        print(f'\\n{neighbor} neighbors\\n-----------------------')\n",
    "        neigh = KNeighborsClassifier(n_neighbors=neighbor, n_jobs=-1)\n",
    "        Y_predict, report = model_fit_predict(neigh, bag_X_train, bag_Y_train, bag_X_test, bag_Y_test)\n",
    "        \n",
    "        report[\"model\"] = \"KNN\"\n",
    "        report[\"feature_type\"] = \"BoW\"\n",
    "        report[\"parameters\"] = {\"neighbors\": neighbor}\n",
    "        \n",
    "\n",
    "        results_pd = results_pd.append(report, ignore_index=True)\n",
    "\n",
    "results_pd.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_f1-score</th>\n",
       "      <td>0.456848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_precision</th>\n",
       "      <td>0.352643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_recall</th>\n",
       "      <td>0.648469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_support</th>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_f1-score</th>\n",
       "      <td>0.0899796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_precision</th>\n",
       "      <td>0.186441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_recall</th>\n",
       "      <td>0.0592992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_support</th>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_f1-score</th>\n",
       "      <td>0.0860534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_precision</th>\n",
       "      <td>0.213235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_recall</th>\n",
       "      <td>0.0539033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_support</th>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_f1-score</th>\n",
       "      <td>0.146084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_precision</th>\n",
       "      <td>0.225058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_recall</th>\n",
       "      <td>0.108138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_support</th>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_f1-score</th>\n",
       "      <td>0.737737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_precision</th>\n",
       "      <td>0.686546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_recall</th>\n",
       "      <td>0.797178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_support</th>\n",
       "      <td>3047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.546752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fbeta</th>\n",
       "      <td>[0.45684803001876173, 0.08997955010224948, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_score</th>\n",
       "      <td>0.546752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_type</th>\n",
       "      <td>BoW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg_f1-score</th>\n",
       "      <td>0.303341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg_precision</th>\n",
       "      <td>0.332785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg_recall</th>\n",
       "      <td>0.333397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg_support</th>\n",
       "      <td>5604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg_f1-score</th>\n",
       "      <td>0.546752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg_precision</th>\n",
       "      <td>0.546752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg_recall</th>\n",
       "      <td>0.546752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg_support</th>\n",
       "      <td>5604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parameters</th>\n",
       "      <td>{'neighbors': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>[0.35264301230992035, 0.1864406779661017, 0.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_time_min</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>[0.6484687083888149, 0.05929919137466307, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time_min</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_examples</th>\n",
       "      <td>5604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_features</th>\n",
       "      <td>20541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_time_min</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_examples</th>\n",
       "      <td>16810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_features</th>\n",
       "      <td>20541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_time_min</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <td>0.499946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <td>0.489384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <td>0.546752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg_support</th>\n",
       "      <td>5604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        0\n",
       "1_f1-score                                                       0.456848\n",
       "1_precision                                                      0.352643\n",
       "1_recall                                                         0.648469\n",
       "1_support                                                             751\n",
       "2_f1-score                                                      0.0899796\n",
       "2_precision                                                      0.186441\n",
       "2_recall                                                        0.0592992\n",
       "2_support                                                             371\n",
       "3_f1-score                                                      0.0860534\n",
       "3_precision                                                      0.213235\n",
       "3_recall                                                        0.0539033\n",
       "3_support                                                             538\n",
       "4_f1-score                                                       0.146084\n",
       "4_precision                                                      0.225058\n",
       "4_recall                                                         0.108138\n",
       "4_support                                                             897\n",
       "5_f1-score                                                       0.737737\n",
       "5_precision                                                      0.686546\n",
       "5_recall                                                         0.797178\n",
       "5_support                                                            3047\n",
       "F1                                                               0.546752\n",
       "Fbeta                   [0.45684803001876173, 0.08997955010224948, 0.0...\n",
       "accuracy_score                                                   0.546752\n",
       "feature_type                                                          BoW\n",
       "macro avg_f1-score                                               0.303341\n",
       "macro avg_precision                                              0.332785\n",
       "macro avg_recall                                                 0.333397\n",
       "macro avg_support                                                    5604\n",
       "micro avg_f1-score                                               0.546752\n",
       "micro avg_precision                                              0.546752\n",
       "micro avg_recall                                                 0.546752\n",
       "micro avg_support                                                    5604\n",
       "model                                                                 KNN\n",
       "parameters                                               {'neighbors': 5}\n",
       "precision               [0.35264301230992035, 0.1864406779661017, 0.21...\n",
       "predict_time_min                                                       11\n",
       "recall                  [0.6484687083888149, 0.05929919137466307, 0.05...\n",
       "score_time_min                                                          0\n",
       "test_examples                                                        5604\n",
       "test_features                                                       20541\n",
       "total_time_min                                                         11\n",
       "train_examples                                                      16810\n",
       "train_features                                                      20541\n",
       "train_time_min                                                          0\n",
       "weighted avg_f1-score                                            0.499946\n",
       "weighted avg_precision                                           0.489384\n",
       "weighted avg_recall                                              0.546752\n",
       "weighted avg_support                                                 5604"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd.T.head(48)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words using Radius Neighbors Classifier\n",
    "\n",
    "Documentation says if the data is not evenly distributed Radius Neighbors might be a better algorithm so trying that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_RN and ENABLE_BOW:\n",
    "    for radius in RADII:\n",
    "        rnc = RadiusNeighborsClassifier(radius=radius, n_jobs=-1)\n",
    "        print(f'\\nRadius: {radius}\\n-----------------------')\n",
    "        results = model_fit_predict(rnc, bag_X_train, bag_Y_train, bag_X_test, bag_Y_test)\n",
    "        results[\"model\"] = \"RN\"\n",
    "        results[\"feature_type\"] = \"BoW\"\n",
    "        results[\"parameters\"] = {\"radius\": radius}\n",
    "        results_pd = results_pd.append(results, ignore_index=True)\n",
    "\n",
    "results_pd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Word using Logistic Regression - what parameters should I play with here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_LR and ENABLE_BOW:\n",
    "    for c in C:\n",
    "        lr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                                  multi_class='auto',\n",
    "                                max_iter=1000, n_jobs=-1)\n",
    "        print(f'\\nRadius: {radius}\\n-----------------------')\n",
    "        results = model_fit_predict(lr, bag_X_train, bag_Y_train, bag_X_test, bag_Y_test)\n",
    "        results[\"model\"] = \"LR\"\n",
    "        results[\"feature_type\"] = \"BoW\"\n",
    "        results[\"parameters\"] = {\"c\": c}\n",
    "        results_pd = results_pd.append(results, ignore_index=True)\n",
    "\n",
    "results_pd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: play with min_df and max_df\n",
    "# TODO: play with variations of ngram\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., ngram_range=(1,3), use_idf=True)\n",
    "tv_matrix = tv.fit_transform(X.array)\n",
    "vocab = tv.get_feature_names()\n",
    "tv_pd = pd.DataFrame(np.round(tv_matrix.toarray(), 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split results into training and test set\n",
    "tv_X_train, tv_X_test, tv_Y_train, tv_Y_test = train_test_split(tv_pd, Y, random_state=1)\n",
    "\n",
    "print(f\"training set size {len(tv_X_train)}\")\n",
    "print(f\"test set size {len(tv_X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use K-nearest neighbors to train\n",
    "\n",
    "if ENABLE_KNN and ENABLE_TFIDF:\n",
    "\n",
    "    for neighbor in NEIGHBORS:\n",
    "        print(f'\\n{neighbor} neighbors\\n-----------------------')\n",
    "        neigh = KNeighborsClassifier(n_neighbors=neighbor, n_jobs=-1)\n",
    "        results = model_fit_predict(neigh, tv_X_train, tv_Y_train, tv_X_test, tv_Y_test)\n",
    "        results[\"model\"] = \"KNN\"\n",
    "        results[\"feature_type\"] = \"TFIDF\"\n",
    "        results[\"parameters\"] = {\"neighbors\": neighbor}\n",
    "        results_pd = results_pd.append(results, ignore_index=True)\n",
    "\n",
    "results_pd.head()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radius Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_RN and ENABLE_TFIDF:\n",
    "    for radius in RADII:\n",
    "        rnc = RadiusNeighborsClassifier(radius=radius, n_jobs=-1)\n",
    "        print(f'\\nRadius: {radius}\\n-----------------------')\n",
    "        results = model_fit_predict(rnc, tv_X_train, tv_Y_train, tv_X_test, tv_Y_test)\n",
    "        results[\"model\"] = \"RN\"\n",
    "        results[\"feature_type\"] = \"TFIDF\"\n",
    "        results[\"parameters\"] = {\"radius\": radius}\n",
    "        results_pd = results_pd.append(results, ignore_index=True)\n",
    "\n",
    "results_pd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_LR and ENABLE_TFIDF:\n",
    "    for c in C:\n",
    "        lr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                                  multi_class='auto',\n",
    "                                max_iter=1000, n_jobs=-1)\n",
    "        print(f'\\nRegularization: {c}\\n-----------------------')\n",
    "        results = model_fit_predict(lr, tv_X_train, tv_Y_train, tv_X_test, tv_Y_test)\n",
    "        results[\"model\"] = \"LR\"\n",
    "        results[\"feature_type\"] = \"TFIDF\"\n",
    "        results[\"parameters\"] = {\"c\": c}\n",
    "        results_pd = results_pd.append(results, ignore_index=True)\n",
    "\n",
    "results_pd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write data to an output file so we can load it back in later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if WRITE_TO_CSV:\n",
    "    results_pd.to_csv(f'{datetime.now().strftime(DATE_FORMAT)}-{FEATURE_COLUMN}-{OUTFILE}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization For Our Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # visualize some data\n",
    "# sns.set(font_scale=2)\n",
    "# sns.set_context(font_scale=3)\n",
    "# f, ax = plt.subplots(6, 2, figsize=(20,50))\n",
    "# plt.tight_layout(pad=2, h_pad=5)\n",
    "\n",
    "# # KNN Graphs\n",
    "\n",
    "\n",
    "# # total time by neighbor\n",
    "# sns.lineplot(x=\"neighbors\", y=\"total_time_min\", data=knn_results_pd, marker='o', color='b', ax=ax[0, 0])\n",
    "# ax[0, 0].set_title(\"KNN BoW Total Time (minutes)\")\n",
    "\n",
    "# # score by neighbor\n",
    "# sns.lineplot(x=\"neighbors\", y=\"score\", data=knn_results_pd, marker='o', color='b', ax=ax[0, 1])\n",
    "# ax[0, 1].set_title(\"KNN BoW Score\")\n",
    "\n",
    "# # total time by neighbor\n",
    "# sns.lineplot(x=\"neighbors\", y=\"total_time_min\", data=knn_tv_results_pd, marker='o', color='b', ax=ax[1, 0])\n",
    "# ax[1, 0].set_title(\"KNN TFIDF Total Time (minutes)\")\n",
    "\n",
    "# # score by neighbor\n",
    "# sns.lineplot(x=\"neighbors\", y=\"score\", data=knn_tv_results_pd, marker='o', color='b', ax=ax[1, 1])\n",
    "# ax[1, 1].set_title(\"KNN TFIDF Score\")\n",
    "\n",
    "\n",
    "# # Radius Neighbor Graphs\n",
    "\n",
    "# # total time by radius\n",
    "# sns.lineplot(x=\"radius\", y=\"total_time_min\", data=rn_results_pd, marker='o', color='g', ax=ax[2, 0])\n",
    "# ax[2, 0].set_title(\"Radius BoW Total Time (minutes)\")\n",
    "\n",
    "# # score by radius\n",
    "# sns.lineplot(x=\"radius\", y=\"score\", data=rn_results_pd, marker='o', color='g', ax=ax[2, 1])\n",
    "# ax[2, 1].set_title(\"Radius BoW Score\")\n",
    "\n",
    "# # total time by radius\n",
    "# sns.lineplot(x=\"radius\", y=\"total_time_min\", data=rn_tv_results_pd, marker='o', color='g', ax=ax[3, 0])\n",
    "# ax[3, 0].set_title(\"Radius TFIDF Total Time (minutes)\")\n",
    "\n",
    "# # score by radius\n",
    "# sns.lineplot(x=\"radius\", y=\"score\", data=rn_tv_results_pd, marker='o', color='g', ax=ax[3, 1])\n",
    "# ax[3, 1].set_title(\"Radius TFIDF Score\")\n",
    "\n",
    "\n",
    "# # Logistic Regression Graphs\n",
    "\n",
    "# # total time by c\n",
    "# sns.lineplot(x=\"c\", y=\"total_time_min\", data=lr_results_pd, marker='o', color='c', ax=ax[4, 0])\n",
    "# ax[4, 0].set_title(\"Logistic Regression BoW Total Time (minutes)\")\n",
    "\n",
    "# # score by c\n",
    "# sns.lineplot(x=\"c\", y=\"score\", data=lr_results_pd, marker='o', color='c', ax=ax[4, 1])\n",
    "# ax[4, 1].set_title(\"Logistic BoW Regression Score\")\n",
    "\n",
    "\n",
    "# # total time by c\n",
    "# sns.lineplot(x=\"c\", y=\"total_time_min\", data=lr_tv_results_pd, marker='o', color='c', ax=ax[5, 0])\n",
    "# ax[5, 0].set_title(\"Logistic Regression TFIDF Total Time (minutes)\")\n",
    "\n",
    "# # score by c\n",
    "# sns.lineplot(x=\"c\", y=\"score\", data=lr_tv_results_pd, marker='o', color='c', ax=ax[5, 1])\n",
    "# ax[5, 1].set_title(\"Logistic TFIDF Regression Score\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
