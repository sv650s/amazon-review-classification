{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use simple techniques for feature Engineering and to do multi-class classification to predict review ratings based on the Amazon Reviews dataset\n",
    "\n",
    "<b>Objective for this exercise:</b>\n",
    "    * Establish NLP prediction accuracy baseline using simple ML models\n",
    "    * Explore different permutation of feature engineering techniques, data, and classification algorithms\n",
    "    * Compare accuracy of preduction using the following information:\n",
    "        * Product Title\n",
    "        * Review Headline\n",
    "        * Review Body\n",
    "    * (If time allows) see if using only helpful reviews to train improves our accuracy for our predictions - this reduces our 110k dataset to 35k\n",
    "\n",
    "\n",
    "<b>Feature Engineering Techniques:</b>\n",
    "    * bag of words\n",
    "    * TF-IDF\n",
    "    * Topic Modeling\n",
    "    \n",
    "    \n",
    "<b>Classification:</b>\n",
    "    * Logistic Regression Classification\n",
    "    * K-nearest Neighbors Classification\n",
    "    * Radius Neighbors Classification - document suggests the Radius Neighbors might be a better fit if our data is no uniform. From our exploratory data analysis, we see that most reviews skew towards 4 or 5 stars\n",
    "    \n",
    "    \n",
    "    \n",
    "<b>Data:</b>\n",
    "\n",
    "Data used in this notebooks came from Amazon reviews dataset - Wirless category. First it was converted from tsv to csv. Then it was pre-processed in the previous notebook using various text processing techniques. For details, please see: [amazon_review_preprocessing.ipynb](amazon_review_preprocessing.ipynb)\n",
    "\n",
    "\n",
    "Example of how to do this:\n",
    "```\n",
    "python preprocess_amazon.py -l INFO -r -o dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-smallout.csv dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-smallin.csv\n",
    "```\n",
    "\n",
    "\n",
    "<b>Memory Requirement:</b>\n",
    "\n",
    "| File | Python Memory |\n",
    "|------|---------------|\n",
    "| amazon_reviews_us_Wireless_v1_00-tinyout.csv | 20 - 26 GB |\n",
    "\n",
    "\n",
    "\n",
    "<b>Code:</b>\n",
    "\n",
    "I found that this notebook was getting way too big and hard to manage so I moved most of the code that runs the models along with utility functions have been moved to a python class [ClassifierRunner.py](models/ClassifierRunner.py). Unit tests for this is in [test_classifier_runner.py](models/test_classifier_runnyer.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.ClassifierRunner import ClassifierRunner\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(name)s.%(funcName)s %(levelname)s - %(message)s', level=logging.INFO)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global variables\n",
    "\n",
    "# I'm finding that running these models on my laptop takes forever and they are not finishing so I'm going to start\n",
    "# with a really small file just to validate my code\n",
    "#\n",
    "# datafile was generated from amazon_review_preprocessing.ipynb - this file has 1k reviews randomly chosen\n",
    "# from original file\n",
    "KEEP_COLUMNS = [\"product_title\", \"helpful_votes\", \"review_headline\", \"review_body\", \"star_rating\"]\n",
    "TIME_FORMAT = '%Y-%m-%d %H:%M:%S'\n",
    "DATE_FORMAT = '%Y-%m-%d'\n",
    "OUTCOME_COLUMN = \"star_rating\"\n",
    "\n",
    "\n",
    "# Configuration\n",
    "DATA_FILE = \"dataset/amazon_reviews/amazon_reviews_us_Wireless_v1_00-tinyout.csv\"\n",
    "NEIGHBORS = [5] # default\n",
    "# NEIGHBORS = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "# Radius for RadiusNeighbor\n",
    "# RADII = [5.0] # this is the lowest number I tried that was able to find a neighbor for review_headline\n",
    "RADII = [30.0] # this is the lowest number I tried that was able to find a neighbor for review_headline\n",
    "# RADII = [5.0, 7.0, 9.0, 11.0, 13.0]\n",
    "\n",
    "# logistic regression settings\n",
    "C= [1.0] # default\n",
    "# C = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "N_JOBS=6\n",
    "LR_ITER=500\n",
    "FEATURE_COLUMN = \"review_headline\"\n",
    "ENABLE_KNN = True\n",
    "ENABLE_TFIDF = True\n",
    "\n",
    "# model flags\n",
    "ENABLE_RN = True\n",
    "ENABLE_LR = True\n",
    "ENABLE_BOW = True\n",
    "\n",
    "\n",
    "WRITE_TO_CSV = True\n",
    "OUTFILE = \"amazon_review_classifier_simple.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22414 entries, 0 to 22413\n",
      "Data columns (total 5 columns):\n",
      "product_title      22414 non-null object\n",
      "helpful_votes      22414 non-null int64\n",
      "review_headline    22414 non-null object\n",
      "review_body        22414 non-null object\n",
      "star_rating        22414 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 875.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_title</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfy universal car headrest mount holder portab...</td>\n",
       "      <td>0</td>\n",
       "      <td>good enough</td>\n",
       "      <td>serves purpose loud whoever sitting seat attached</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iccker art nylon hair paint brush tools set bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>five stars</td>\n",
       "      <td>works really well samsung s6 otterbox defender...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jbl gx series coaxial car loudspeakers certifi...</td>\n",
       "      <td>1</td>\n",
       "      <td>speakers did not sound well thought</td>\n",
       "      <td>speakers did not sound well thought would jbls...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>otium screen protectors</td>\n",
       "      <td>0</td>\n",
       "      <td>really easy install included guide</td>\n",
       "      <td>absoultely perfect included install guide make...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple watch stand vtin aluminum alloy build ho...</td>\n",
       "      <td>0</td>\n",
       "      <td>love</td>\n",
       "      <td>heres lot like stand apple watch very modern s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       product_title  helpful_votes  \\\n",
       "0  tfy universal car headrest mount holder portab...              0   \n",
       "1  iccker art nylon hair paint brush tools set bl...              0   \n",
       "2  jbl gx series coaxial car loudspeakers certifi...              1   \n",
       "3                            otium screen protectors              0   \n",
       "4  apple watch stand vtin aluminum alloy build ho...              0   \n",
       "\n",
       "                       review_headline  \\\n",
       "0                          good enough   \n",
       "1                           five stars   \n",
       "2  speakers did not sound well thought   \n",
       "3   really easy install included guide   \n",
       "4                                 love   \n",
       "\n",
       "                                         review_body  star_rating  \n",
       "0  serves purpose loud whoever sitting seat attached            3  \n",
       "1  works really well samsung s6 otterbox defender...            5  \n",
       "2  speakers did not sound well thought would jbls...            2  \n",
       "3  absoultely perfect included install guide make...            5  \n",
       "4  heres lot like stand apple watch very modern s...            5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in DF\n",
    "df = pd.read_csv(DATA_FILE)[KEEP_COLUMNS]\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">Should I include add these along with the word vectors as part of the feature set?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>pt_wc</th>\n",
       "      <th>rh_wc</th>\n",
       "      <th>rb_wc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22414.000000</td>\n",
       "      <td>22414.000000</td>\n",
       "      <td>22414.000000</td>\n",
       "      <td>22414.000000</td>\n",
       "      <td>22414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.904792</td>\n",
       "      <td>3.895333</td>\n",
       "      <td>15.907335</td>\n",
       "      <td>2.956322</td>\n",
       "      <td>25.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.709008</td>\n",
       "      <td>1.465474</td>\n",
       "      <td>9.716846</td>\n",
       "      <td>1.915684</td>\n",
       "      <td>41.441713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>868.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1133.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       helpful_votes   star_rating         pt_wc         rh_wc         rb_wc\n",
       "count   22414.000000  22414.000000  22414.000000  22414.000000  22414.000000\n",
       "mean        0.904792      3.895333     15.907335      2.956322     25.979700\n",
       "std         8.709008      1.465474      9.716846      1.915684     41.441713\n",
       "min         0.000000      1.000000      1.000000      1.000000      1.000000\n",
       "25%         0.000000      3.000000      9.000000      2.000000      8.000000\n",
       "50%         0.000000      5.000000     14.000000      2.000000     15.000000\n",
       "75%         0.000000      5.000000     20.000000      4.000000     28.000000\n",
       "max       868.000000      5.000000     92.000000     21.000000   1133.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get some data on our text\n",
    "\n",
    "def wc(x:str):\n",
    "    return len(str(x).split())\n",
    "\n",
    "df[\"pt_wc\"] = df.product_title.apply(wc)\n",
    "df[\"rh_wc\"] = df.review_headline.apply(wc)\n",
    "df[\"rb_wc\"] = df.review_body.apply(wc)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up different dataframes for training\n",
    "\n",
    "# outcome\n",
    "Y = df[\"star_rating\"]\n",
    "X = df[FEATURE_COLUMN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words - Generate Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size 16810\n",
      "test set size 5604\n"
     ]
    }
   ],
   "source": [
    "# TODO: try different parameters for CountVectorizers?\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(X.array)\n",
    "vocab = cv.get_feature_names()\n",
    "# print(f\"vocab: {vocab}\")\n",
    "bag_pd = pd.DataFrame(cv_matrix.toarray(), columns=vocab)\n",
    "\n",
    "# split results into training and test set\n",
    "bag_X_train, bag_X_test, bag_Y_train, bag_Y_test = train_test_split(bag_pd, Y, random_state=1)\n",
    "\n",
    "print(f\"training set size {len(bag_X_train)}\")\n",
    "print(f\"test set size {len(bag_X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20541\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0000</th>\n",
       "      <th>000hz</th>\n",
       "      <th>000hzsensitivity</th>\n",
       "      <th>000mah</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>003</th>\n",
       "      <th>004</th>\n",
       "      <th>...</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zperia</th>\n",
       "      <th>zr</th>\n",
       "      <th>zte</th>\n",
       "      <th>zumo</th>\n",
       "      <th>zune</th>\n",
       "      <th>zuzo</th>\n",
       "      <th>zx4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20541 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0000  000hz  000hzsensitivity  000mah  001  002  003  004  ...  \\\n",
       "0   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "1   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "2   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "3   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "4   0    0     0      0                 0       0    0    0    0    0  ...   \n",
       "\n",
       "   zoomed  zooming  zooms  zperia  zr  zte  zumo  zune  zuzo  zx4  \n",
       "0       0        0      0       0   0    0     0     0     0    0  \n",
       "1       0        0      0       0   0    0     0     0     0    0  \n",
       "2       0        0      0       0   0    0     0     0     0    0  \n",
       "3       0        0      0       0   0    0     0     0     0    0  \n",
       "4       0        0      0       0   0    0     0     0     0    0  \n",
       "\n",
       "[5 rows x 20541 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the data\n",
    "print(len(vocab))\n",
    "bag_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up BoW models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 13:49:45,311 models.ClassifierRunner.$(funcName)s INFO - Initializing models.ClassifierRunner\n",
      "2019-05-18 13:49:45,313 models.ClassifierRunner.$(funcName)s INFO - write to csv: True\n",
      "2019-05-18 13:49:45,314 models.ClassifierRunner.$(funcName)s INFO - outfile: 2019-05-18-models.ClassifierRunner-report.csv\n"
     ]
    }
   ],
   "source": [
    "cr_bow = ClassifierRunner(write_to_csv=WRITE_TO_CSV)\n",
    "\n",
    "if ENABLE_BOW:\n",
    "    if ENABLE_KNN:\n",
    "        for neighbor in NEIGHBORS:\n",
    "            neigh = KNeighborsClassifier(n_neighbors=neighbor, n_jobs=N_JOBS)\n",
    "            cr_bow.addModel(neigh, \n",
    "                        bag_X_train, \n",
    "                        bag_Y_train, \n",
    "                        bag_X_test, \n",
    "                        bag_Y_test, \n",
    "                        name=\"KNN\", \n",
    "                        dataset=\"BoW\", \n",
    "                        parameters={\"n_jobs\": N_JOBS,\n",
    "                                   \"n_neighbors\": neighbor})\n",
    "\n",
    "    if ENABLE_RN:\n",
    "        for radius in RADII:\n",
    "            rnc = RadiusNeighborsClassifier(radius=radius, n_jobs=N_JOBS)\n",
    "            cr_bow.addModel(neigh, \n",
    "                        bag_X_train, \n",
    "                        bag_Y_train, \n",
    "                        bag_X_test, \n",
    "                        bag_Y_test, \n",
    "                        name=\"RN\", \n",
    "                        dataset=\"BoW\", \n",
    "                        parameters={\"n_jobs\": N_JOBS,\n",
    "                                   \"radius\": radius})\n",
    "            \n",
    "    if ENABLE_LR:\n",
    "        for c in C:\n",
    "            lr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                                    multi_class='auto',\n",
    "                                    max_iter=LR_ITER, n_jobs=N_JOBS, C=c)\n",
    "            cr_bow.addModel(lr, \n",
    "                        bag_X_train, \n",
    "                        bag_Y_train, \n",
    "                        bag_X_test, \n",
    "                        bag_Y_test, \n",
    "                        name=\"LR\", \n",
    "                        dataset=\"BoW\", \n",
    "                        parameters={\"n_jobs\": N_JOBS,\n",
    "                                   \"c\": c,\n",
    "                                   \"max_iter\": LR_ITER})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 13:39:11,860 models.ClassifierRunner.$(funcName)s INFO - Running model: KNN\n",
      "\twith data: BoW\n",
      "\tand parameters: {'n_jobs': 6, 'n_neighbors': 5}\n",
      "2019-05-18 13:39:11,861 models.ClassifierRunner.$(funcName)s INFO - Start training: 2019-05-18 13:39:11\n",
      "2019-05-18 13:39:18,786 models.ClassifierRunner.$(funcName)s INFO - End training: 2019-05-18 13:39:18\n",
      "2019-05-18 13:39:18,787 models.ClassifierRunner.$(funcName)s INFO - End Scoring: 2019-05-18 13:39:18\n",
      "2019-05-18 13:42:01,063 models.ClassifierRunner.$(funcName)s INFO - End predict: 2019-05-18 13:42:01\n",
      "2019-05-18 13:42:01,064 models.ClassifierRunner.$(funcName)s INFO - Training time (min): 0.1\n",
      "2019-05-18 13:42:01,064 models.ClassifierRunner.$(funcName)s INFO - Scoring time (min): 0.0\n",
      "2019-05-18 13:42:01,065 models.ClassifierRunner.$(funcName)s INFO - Predict time (min): 2.7\n",
      "2019-05-18 13:42:01,089 models.ClassifierRunner.$(funcName)s INFO - Finished running model: KNN\n",
      "\twith data: BoW\n",
      "\tand parameters: {'n_jobs': 6, 'n_neighbors': 5}\tstatus: success\n",
      "2019-05-18 13:42:01,089 models.ClassifierRunner.$(funcName)s INFO - Running model: RN\n",
      "\twith data: BoW\n",
      "\tand parameters: {'n_jobs': 6, 'radius': 30.0}\n",
      "2019-05-18 13:42:01,090 models.ClassifierRunner.$(funcName)s INFO - Start training: 2019-05-18 13:42:01\n",
      "2019-05-18 13:42:07,865 models.ClassifierRunner.$(funcName)s INFO - End training: 2019-05-18 13:42:07\n",
      "2019-05-18 13:42:07,865 models.ClassifierRunner.$(funcName)s INFO - End Scoring: 2019-05-18 13:42:07\n",
      "2019-05-18 13:44:43,307 models.ClassifierRunner.$(funcName)s INFO - End predict: 2019-05-18 13:44:43\n",
      "2019-05-18 13:44:43,307 models.ClassifierRunner.$(funcName)s INFO - Training time (min): 0.1\n",
      "2019-05-18 13:44:43,308 models.ClassifierRunner.$(funcName)s INFO - Scoring time (min): 0.0\n",
      "2019-05-18 13:44:43,309 models.ClassifierRunner.$(funcName)s INFO - Predict time (min): 2.6\n",
      "2019-05-18 13:44:43,335 models.ClassifierRunner.$(funcName)s INFO - Finished running model: RN\n",
      "\twith data: BoW\n",
      "\tand parameters: {'n_jobs': 6, 'radius': 30.0}\tstatus: success\n",
      "2019-05-18 13:44:43,336 models.ClassifierRunner.$(funcName)s INFO - Running model: LR\n",
      "\twith data: BoW\n",
      "\tand parameters: {'n_jobs': 6, 'c': 1.0, 'max_iter': 500}\n",
      "2019-05-18 13:44:43,336 models.ClassifierRunner.$(funcName)s INFO - Start training: 2019-05-18 13:44:43\n",
      "2019-05-18 13:49:08,224 models.ClassifierRunner.$(funcName)s INFO - End training: 2019-05-18 13:49:08\n",
      "2019-05-18 13:49:08,230 models.ClassifierRunner.$(funcName)s INFO - End Scoring: 2019-05-18 13:49:08\n",
      "2019-05-18 13:49:08,426 models.ClassifierRunner.$(funcName)s INFO - End predict: 2019-05-18 13:49:08\n",
      "2019-05-18 13:49:08,426 models.ClassifierRunner.$(funcName)s INFO - Training time (min): 4.4\n",
      "2019-05-18 13:49:08,427 models.ClassifierRunner.$(funcName)s INFO - Scoring time (min): 0.0\n",
      "2019-05-18 13:49:08,428 models.ClassifierRunner.$(funcName)s INFO - Predict time (min): 0.0\n",
      "2019-05-18 13:49:08,464 models.ClassifierRunner.$(funcName)s INFO - Finished running model: LR\n",
      "\twith data: BoW\n",
      "\tand parameters: {'n_jobs': 6, 'c': 1.0, 'max_iter': 500}\tstatus: success\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1_f1-score</th>\n",
       "      <th>1_precision</th>\n",
       "      <th>1_recall</th>\n",
       "      <th>1_support</th>\n",
       "      <th>2_f1-score</th>\n",
       "      <th>2_precision</th>\n",
       "      <th>2_recall</th>\n",
       "      <th>2_support</th>\n",
       "      <th>3_f1-score</th>\n",
       "      <th>3_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>test_examples</th>\n",
       "      <th>test_features</th>\n",
       "      <th>total_time_min</th>\n",
       "      <th>train_examples</th>\n",
       "      <th>train_features</th>\n",
       "      <th>train_time_min</th>\n",
       "      <th>weighted avg_f1-score</th>\n",
       "      <th>weighted avg_precision</th>\n",
       "      <th>weighted avg_recall</th>\n",
       "      <th>weighted avg_support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656018</td>\n",
       "      <td>0.573852</td>\n",
       "      <td>0.765646</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.337308</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.266846</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>...</td>\n",
       "      <td>5604.0</td>\n",
       "      <td>5646.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>16810.0</td>\n",
       "      <td>5646.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.647042</td>\n",
       "      <td>0.648710</td>\n",
       "      <td>0.659886</td>\n",
       "      <td>5604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.656018</td>\n",
       "      <td>0.573852</td>\n",
       "      <td>0.765646</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.337308</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.266846</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>...</td>\n",
       "      <td>5604.0</td>\n",
       "      <td>5646.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>16810.0</td>\n",
       "      <td>5646.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.647042</td>\n",
       "      <td>0.648710</td>\n",
       "      <td>0.659886</td>\n",
       "      <td>5604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.707731</td>\n",
       "      <td>0.670238</td>\n",
       "      <td>0.749667</td>\n",
       "      <td>751.0</td>\n",
       "      <td>0.363964</td>\n",
       "      <td>0.548913</td>\n",
       "      <td>0.272237</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.603896</td>\n",
       "      <td>...</td>\n",
       "      <td>5604.0</td>\n",
       "      <td>5646.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>16810.0</td>\n",
       "      <td>5646.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.674834</td>\n",
       "      <td>0.679572</td>\n",
       "      <td>0.705924</td>\n",
       "      <td>5604.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1_f1-score  1_precision  1_recall  1_support  2_f1-score  2_precision  \\\n",
       "0    0.656018     0.573852  0.765646      751.0    0.337308     0.458333   \n",
       "1    0.656018     0.573852  0.765646      751.0    0.337308     0.458333   \n",
       "2    0.707731     0.670238  0.749667      751.0    0.363964     0.548913   \n",
       "\n",
       "   2_recall  2_support  3_f1-score  3_precision  ...  test_examples  \\\n",
       "0  0.266846      371.0    0.425532     0.584416  ...         5604.0   \n",
       "1  0.266846      371.0    0.425532     0.584416  ...         5604.0   \n",
       "2  0.272237      371.0    0.439716     0.603896  ...         5604.0   \n",
       "\n",
       "   test_features  total_time_min  train_examples  train_features  \\\n",
       "0         5646.0             2.8         16810.0          5646.0   \n",
       "1         5646.0             2.7         16810.0          5646.0   \n",
       "2         5646.0             4.4         16810.0          5646.0   \n",
       "\n",
       "   train_time_min  weighted avg_f1-score  weighted avg_precision  \\\n",
       "0             0.1               0.647042                0.648710   \n",
       "1             0.1               0.647042                0.648710   \n",
       "2             4.4               0.674834                0.679572   \n",
       "\n",
       "   weighted avg_recall  weighted avg_support  \n",
       "0             0.659886                5604.0  \n",
       "1             0.659886                5604.0  \n",
       "2             0.705924                5604.0  \n",
       "\n",
       "[3 rows x 44 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_bow = cr_bow.runModels()\n",
    "reprot_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - default settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size 16810\n",
      "test set size 5604\n"
     ]
    }
   ],
   "source": [
    "# TODO: play with min_df and max_df\n",
    "# TODO: play with variations of ngram\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., ngram_range=(1,3), use_idf=True)\n",
    "tv_matrix = tv.fit_transform(X.array)\n",
    "vocab = tv.get_feature_names()\n",
    "tv_pd = pd.DataFrame(np.round(tv_matrix.toarray(), 2), columns=vocab)\n",
    "\n",
    "# split results into training and test set\n",
    "tv_X_train, tv_X_test, tv_Y_train, tv_Y_test = train_test_split(tv_pd, Y, random_state=1)\n",
    "\n",
    "print(f\"training set size {len(tv_X_train)}\")\n",
    "print(f\"test set size {len(tv_X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 13:55:34,079 models.ClassifierRunner.$(funcName)s INFO - Initializing models.ClassifierRunner\n",
      "2019-05-18 13:55:34,080 models.ClassifierRunner.$(funcName)s INFO - write to csv: True\n",
      "2019-05-18 13:55:34,081 models.ClassifierRunner.$(funcName)s INFO - outfile: 2019-05-18-models.ClassifierRunner-report.csv\n"
     ]
    }
   ],
   "source": [
    "cr_tfidf = ClassifierRunner(write_to_csv=WRITE_TO_CSV)\n",
    "\n",
    "\n",
    "if ENABLE_TFIDF:\n",
    "    if ENABLE_KNN:\n",
    "        for neighbor in NEIGHBORS:\n",
    "            neigh = KNeighborsClassifier(n_neighbors=neighbor, n_jobs=N_JOBS)\n",
    "            cr_tfidf.addModel(neigh, \n",
    "                        tv_X_train, \n",
    "                        tv_Y_train, \n",
    "                        tv_X_test, \n",
    "                        tv_Y_test, \n",
    "                        name=\"KNN\", \n",
    "                        dataset=\"TFIDF\", \n",
    "                        parameters={\"n_jobs\": N_JOBS,\n",
    "                                   \"n_neighbors\": neighbor})\n",
    "\n",
    "    if ENABLE_RN:\n",
    "        for radius in RADII:\n",
    "            rnc = RadiusNeighborsClassifier(radius=radius, n_jobs=N_JOBS)\n",
    "            cr_tfidf.addModel(neigh, \n",
    "                        tv_X_train, \n",
    "                        tv_Y_train, \n",
    "                        tv_X_test, \n",
    "                        tv_Y_test, \n",
    "                        name=\"RN\", \n",
    "                        dataset=\"TFIDF\", \n",
    "                        parameters={\"n_jobs\": N_JOBS,\n",
    "                                   \"radius\": radius})\n",
    "            \n",
    "    if ENABLE_LR:\n",
    "        for c in C:\n",
    "            lr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                                    multi_class='auto',\n",
    "                                    max_iter=LR_ITER, n_jobs=N_JOBS, C=c)\n",
    "            cr_tfidf.addModel(lr, \n",
    "                        tv_X_train, \n",
    "                        tv_Y_train, \n",
    "                        tv_X_test, \n",
    "                        tv_Y_test, \n",
    "                        name=\"LR\", \n",
    "                        dataset=\"TFIDF\", \n",
    "                        parameters={\"n_jobs\": N_JOBS,\n",
    "                                   \"c\": c,\n",
    "                                   \"max_iter\": LR_ITER})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 13:55:35,906 models.ClassifierRunner.$(funcName)s INFO - Running model: KNN\n",
      "\twith data: TFIDF\n",
      "\tand parameters: {'n_jobs': 6, 'n_neighbors': 5}\n",
      "2019-05-18 13:55:35,909 models.ClassifierRunner.$(funcName)s INFO - Start training: 2019-05-18 13:55:35\n",
      "2019-05-18 13:56:33,224 models.ClassifierRunner.$(funcName)s INFO - End training: 2019-05-18 13:56:33\n",
      "2019-05-18 13:56:33,239 models.ClassifierRunner.$(funcName)s INFO - End Scoring: 2019-05-18 13:56:33\n"
     ]
    }
   ],
   "source": [
    "report_tfidf = cr_tfidf.runModels()\n",
    "report_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: play with min_df and max_df\n",
    "# # TODO: play with variations of ngram\n",
    "# tv = TfidfVectorizer(min_df=0., max_df=1., ngram_range=(1,3), use_idf=True)\n",
    "# tv_matrix = tv.fit_transform(X.array)\n",
    "# vocab = tv.get_feature_names()\n",
    "# tv_pd = pd.DataFrame(np.round(tv_matrix.toarray(), 2), columns=vocab)\n",
    "\n",
    "# # split results into training and test set\n",
    "# tv_X_train, tv_X_test, tv_Y_train, tv_Y_test = train_test_split(tv_pd, Y, random_state=1)\n",
    "\n",
    "# print(f\"training set size {len(tv_X_train)}\")\n",
    "# print(f\"test set size {len(tv_X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization For Our Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # visualize some data\n",
    "# sns.set(font_scale=2)\n",
    "# sns.set_context(font_scale=3)\n",
    "# f, ax = plt.subplots(6, 2, figsize=(20,50))\n",
    "# plt.tight_layout(pad=2, h_pad=5)\n",
    "\n",
    "# # KNN Graphs\n",
    "\n",
    "\n",
    "# # total time by neighbor\n",
    "# sns.lineplot(x=\"neighbors\", y=\"total_time_min\", data=knn_results_pd, marker='o', color='b', ax=ax[0, 0])\n",
    "# ax[0, 0].set_title(\"KNN BoW Total Time (minutes)\")\n",
    "\n",
    "# # score by neighbor\n",
    "# sns.lineplot(x=\"neighbors\", y=\"score\", data=knn_results_pd, marker='o', color='b', ax=ax[0, 1])\n",
    "# ax[0, 1].set_title(\"KNN BoW Score\")\n",
    "\n",
    "# # total time by neighbor\n",
    "# sns.lineplot(x=\"neighbors\", y=\"total_time_min\", data=knn_tv_results_pd, marker='o', color='b', ax=ax[1, 0])\n",
    "# ax[1, 0].set_title(\"KNN TFIDF Total Time (minutes)\")\n",
    "\n",
    "# # score by neighbor\n",
    "# sns.lineplot(x=\"neighbors\", y=\"score\", data=knn_tv_results_pd, marker='o', color='b', ax=ax[1, 1])\n",
    "# ax[1, 1].set_title(\"KNN TFIDF Score\")\n",
    "\n",
    "\n",
    "# # Radius Neighbor Graphs\n",
    "\n",
    "# # total time by radius\n",
    "# sns.lineplot(x=\"radius\", y=\"total_time_min\", data=rn_results_pd, marker='o', color='g', ax=ax[2, 0])\n",
    "# ax[2, 0].set_title(\"Radius BoW Total Time (minutes)\")\n",
    "\n",
    "# # score by radius\n",
    "# sns.lineplot(x=\"radius\", y=\"score\", data=rn_results_pd, marker='o', color='g', ax=ax[2, 1])\n",
    "# ax[2, 1].set_title(\"Radius BoW Score\")\n",
    "\n",
    "# # total time by radius\n",
    "# sns.lineplot(x=\"radius\", y=\"total_time_min\", data=rn_tv_results_pd, marker='o', color='g', ax=ax[3, 0])\n",
    "# ax[3, 0].set_title(\"Radius TFIDF Total Time (minutes)\")\n",
    "\n",
    "# # score by radius\n",
    "# sns.lineplot(x=\"radius\", y=\"score\", data=rn_tv_results_pd, marker='o', color='g', ax=ax[3, 1])\n",
    "# ax[3, 1].set_title(\"Radius TFIDF Score\")\n",
    "\n",
    "\n",
    "# # Logistic Regression Graphs\n",
    "\n",
    "# # total time by c\n",
    "# sns.lineplot(x=\"c\", y=\"total_time_min\", data=lr_results_pd, marker='o', color='c', ax=ax[4, 0])\n",
    "# ax[4, 0].set_title(\"Logistic Regression BoW Total Time (minutes)\")\n",
    "\n",
    "# # score by c\n",
    "# sns.lineplot(x=\"c\", y=\"score\", data=lr_results_pd, marker='o', color='c', ax=ax[4, 1])\n",
    "# ax[4, 1].set_title(\"Logistic BoW Regression Score\")\n",
    "\n",
    "\n",
    "# # total time by c\n",
    "# sns.lineplot(x=\"c\", y=\"total_time_min\", data=lr_tv_results_pd, marker='o', color='c', ax=ax[5, 0])\n",
    "# ax[5, 0].set_title(\"Logistic Regression TFIDF Total Time (minutes)\")\n",
    "\n",
    "# # score by c\n",
    "# sns.lineplot(x=\"c\", y=\"score\", data=lr_tv_results_pd, marker='o', color='c', ax=ax[5, 1])\n",
    "# ax[5, 1].set_title(\"Logistic TFIDF Regression Score\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
