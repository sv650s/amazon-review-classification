#
# Extend docker image from pyspark-notebook so we can run pyspark LR training on a docker container
# Reference: https://hub.docker.com/r/jupyter/pyspark-notebook/dockerfile
# This will start jupyter lab by default
#
FROM jupyter/pyspark-notebook

ARG user
ARG old_user

USER root
RUN deluser $old_user && \
    useradd -m -s /bin/bash -N -u $NB_UID $user && \
    fix-permissions /home/$user && \
    conda install --quiet -y pyspark traceback2 && \
    conda clean --all -f -y


ENV HOME=/home/$user \
    NB_USER=$user \
    JUPYTER_ENABLE_LAB=true \
    PATH=$PATH:/usr/local/spark/bin

COPY config/spark-defaults.conf /usr/local/spark/conf/

USER $user
WORKDIR $HOME


